{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Code Final Portfolio - Component 2\n",
    "\n",
    "This notebook gives a more detailed exposition of the analyses performed in Courellis et al. (2024)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Required packages\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.io import loadmat\n",
    "import itertools\n",
    "\n",
    "from scipy.stats import binom\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import helper_functions as F\n",
    "\n",
    "# Paths to files\n",
    "FOLDER_PATH = \"2024courellis/\"\n",
    "neu_mat_path = os.path.join(FOLDER_PATH, \"data/neu.mat\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and inspect datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Session-level behavior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sessionID</th>\n",
       "      <th>events</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P61CS_1</td>\n",
       "      <td>[[1551091404901085.0, 55], [1551091406087648.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>P62CS_1</td>\n",
       "      <td>[[1555760333243868.0, 55], [1555760334376711.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>P62CS_2</td>\n",
       "      <td>[[1555761804593152.0, 55], [1555761805744683.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>P62CS_3</td>\n",
       "      <td>[[1556200582588169.0, 55], [1556200583950356.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>P62CS_4</td>\n",
       "      <td>[[1556641173506903.0, 55], [1556641174833121.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>P63CS_1</td>\n",
       "      <td>[[1566756422494843.0, 55], [1566756423712092.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>P63CS_2</td>\n",
       "      <td>[[1566816971749967.0, 55], [1566816972930498.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>P63CS_3</td>\n",
       "      <td>[[1566836657844104.0, 55], [1566836659043604.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>P65CS_1</td>\n",
       "      <td>[[1580644232055429.0, 55], [1580644233132866.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>P65CS_2</td>\n",
       "      <td>[[1580645831803162.0, 55], [1580645832879380.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>P65CS_3</td>\n",
       "      <td>[[1580818040691951.0, 55], [1580818041911138.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>P67CS_1</td>\n",
       "      <td>[[1600354805510287.0, 55], [1600354806671255.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>P67CS_2</td>\n",
       "      <td>[[1600356327987332.0, 55], [1600356329153269.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>P67CS_3</td>\n",
       "      <td>[[1600509467307934.0, 55], [1600509468477839.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>P67CS_4</td>\n",
       "      <td>[[1600510645057867.0, 55], [1600510646241866.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>P70CS_1</td>\n",
       "      <td>[[1604940882110851.0, 55], [1604940884162475.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>P71CS_1</td>\n",
       "      <td>[[1605804816825920.0, 55], [1605804818155857.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>P71CS_2</td>\n",
       "      <td>[[1605805946555623.0, 55], [1605805947630685.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>P73CS_1</td>\n",
       "      <td>[[1616683382181933.0, 55], [1616683384497994.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>P73CS_2</td>\n",
       "      <td>[[1616684649401987.0, 55], [1616684651443205.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>P73CS_3</td>\n",
       "      <td>[[1616856279218848.0, 55], [1616856281334378.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>P74CS_1</td>\n",
       "      <td>[[1629452190002550.0, 55], [1629452192142362.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>P74CS_2</td>\n",
       "      <td>[[1629453419031838.0, 55], [1629453421065275.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>P76CS_1</td>\n",
       "      <td>[[1632220425233033.0, 55], [1632220426498002.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>P78CS_1</td>\n",
       "      <td>[[1646904867704623.0, 55], [1646904869722685.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>P78CS_2</td>\n",
       "      <td>[[1646906374725174.0, 55], [1646906376739923.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>P79CS_1</td>\n",
       "      <td>[[1648718723521068.0, 55], [1648718725646974.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>P79CS_2</td>\n",
       "      <td>[[1648719986097999.0, 55], [1648719987142467.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>P79CS_3</td>\n",
       "      <td>[[1648976482623670.0, 55], [1648976483701201.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>TWH162_1</td>\n",
       "      <td>[[1627061025657588.0, 55], [1627061026880525.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>TWH163_1</td>\n",
       "      <td>[[55, 55], [1628022240068374.0, 1], [162802224...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>TWH163_2</td>\n",
       "      <td>[[1628023652142589.0, 55], [1628023653176744.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>TWH165_1</td>\n",
       "      <td>[[1632772420238951.0, 55], [1632772421277107.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>TWH165_2</td>\n",
       "      <td>[[1632773821161514.0, 55], [1632773822408857.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>TWH172_1</td>\n",
       "      <td>[[0, 55], [1269993.6, 1], [2377987.2, 31], [62...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>TWH172_2</td>\n",
       "      <td>[[0, 55], [1053993.6, 1], [3943987.2, 31], [70...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sessionID                                             events\n",
       "0    P61CS_1  [[1551091404901085.0, 55], [1551091406087648.0...\n",
       "1    P62CS_1  [[1555760333243868.0, 55], [1555760334376711.0...\n",
       "2    P62CS_2  [[1555761804593152.0, 55], [1555761805744683.0...\n",
       "3    P62CS_3  [[1556200582588169.0, 55], [1556200583950356.0...\n",
       "4    P62CS_4  [[1556641173506903.0, 55], [1556641174833121.0...\n",
       "5    P63CS_1  [[1566756422494843.0, 55], [1566756423712092.0...\n",
       "6    P63CS_2  [[1566816971749967.0, 55], [1566816972930498.0...\n",
       "7    P63CS_3  [[1566836657844104.0, 55], [1566836659043604.0...\n",
       "8    P65CS_1  [[1580644232055429.0, 55], [1580644233132866.0...\n",
       "9    P65CS_2  [[1580645831803162.0, 55], [1580645832879380.0...\n",
       "10   P65CS_3  [[1580818040691951.0, 55], [1580818041911138.0...\n",
       "11   P67CS_1  [[1600354805510287.0, 55], [1600354806671255.0...\n",
       "12   P67CS_2  [[1600356327987332.0, 55], [1600356329153269.0...\n",
       "13   P67CS_3  [[1600509467307934.0, 55], [1600509468477839.0...\n",
       "14   P67CS_4  [[1600510645057867.0, 55], [1600510646241866.0...\n",
       "15   P70CS_1  [[1604940882110851.0, 55], [1604940884162475.0...\n",
       "16   P71CS_1  [[1605804816825920.0, 55], [1605804818155857.0...\n",
       "17   P71CS_2  [[1605805946555623.0, 55], [1605805947630685.0...\n",
       "18   P73CS_1  [[1616683382181933.0, 55], [1616683384497994.0...\n",
       "19   P73CS_2  [[1616684649401987.0, 55], [1616684651443205.0...\n",
       "20   P73CS_3  [[1616856279218848.0, 55], [1616856281334378.0...\n",
       "21   P74CS_1  [[1629452190002550.0, 55], [1629452192142362.0...\n",
       "22   P74CS_2  [[1629453419031838.0, 55], [1629453421065275.0...\n",
       "23   P76CS_1  [[1632220425233033.0, 55], [1632220426498002.0...\n",
       "24   P78CS_1  [[1646904867704623.0, 55], [1646904869722685.0...\n",
       "25   P78CS_2  [[1646906374725174.0, 55], [1646906376739923.0...\n",
       "26   P79CS_1  [[1648718723521068.0, 55], [1648718725646974.0...\n",
       "27   P79CS_2  [[1648719986097999.0, 55], [1648719987142467.0...\n",
       "28   P79CS_3  [[1648976482623670.0, 55], [1648976483701201.0...\n",
       "29  TWH162_1  [[1627061025657588.0, 55], [1627061026880525.0...\n",
       "30  TWH163_1  [[55, 55], [1628022240068374.0, 1], [162802224...\n",
       "31  TWH163_2  [[1628023652142589.0, 55], [1628023653176744.0...\n",
       "32  TWH165_1  [[1632772420238951.0, 55], [1632772421277107.0...\n",
       "33  TWH165_2  [[1632773821161514.0, 55], [1632773822408857.0...\n",
       "34  TWH172_1  [[0, 55], [1269993.6, 1], [2377987.2, 31], [62...\n",
       "35  TWH172_2  [[0, 55], [1053993.6, 1], [3943987.2, 31], [70..."
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"beh.json\", \"r\") as f:\n",
    "    all_beh_data = json.load(f)[\"beh\"]\n",
    "\n",
    "# Load behavioral data organized by session\n",
    "beh_data = pd.DataFrame(all_beh_data[\"data\"])\n",
    "beh_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context</th>\n",
       "      <th>stim_sequence</th>\n",
       "      <th>reward_sequence</th>\n",
       "      <th>response_sequence</th>\n",
       "      <th>is_novel_variant</th>\n",
       "      <th>novel_stim_dir</th>\n",
       "      <th>novel_block_image</th>\n",
       "      <th>remapping</th>\n",
       "      <th>stim_to_replace</th>\n",
       "      <th>replace_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...</td>\n",
       "      <td>[2, 4, 1, 2, 4, 4, 4, 3, 1, 4, 4, 3, 4, 3, 2, ...</td>\n",
       "      <td>[25, 5, 5, 25, 5, 5, 5, 25, 5, 5, 5, 25, 5, 25...</td>\n",
       "      <td>[0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...</td>\n",
       "      <td>[1, 2, 4, 4, 3, 2, 3, 1, 4, 4, 4, 2, 3, 1, 2, ...</td>\n",
       "      <td>[5, 25, 5, 5, 25, 25, 25, 5, 5, 5, 5, 25, 25, ...</td>\n",
       "      <td>[1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...</td>\n",
       "      <td>[1, 3, 3, 4, 2, 2, 2, 4, 4, 1, 1, 2, 1, 3, 2, ...</td>\n",
       "      <td>[5, 25, 25, 5, 25, 25, 25, 5, 5, 5, 5, 25, 5, ...</td>\n",
       "      <td>[1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...</td>\n",
       "      <td>[2, 2, 3, 3, 1, 2, 2, 3, 2, 4, 4, 2, 2, 3, 4, ...</td>\n",
       "      <td>[25, 25, 25, 25, 5, 25, 25, 25, 25, 5, 5, 25, ...</td>\n",
       "      <td>[0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, ...</td>\n",
       "      <td>[2, 1, 2, 3, 2, 2, 4, 3, 3, 4, 2, 4, 4, 2, 3, ...</td>\n",
       "      <td>[25, 5, 25, 25, 25, 25, 5, 25, 25, 5, 25, 5, 5...</td>\n",
       "      <td>[0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...</td>\n",
       "      <td>[1, 2, 3, 3, 4, 2, 3, 3, 1, 1, 2, 4, 2, 3, 1, ...</td>\n",
       "      <td>[5, 25, 25, 25, 5, 25, 25, 25, 5, 5, 25, 5, 25...</td>\n",
       "      <td>[1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, ...</td>\n",
       "      <td>[1, 3, 2, 4, 4, 3, 2, 3, 1, 4, 4, 4, 2, 3, 1, ...</td>\n",
       "      <td>[5, 25, 25, 5, 5, 25, 25, 25, 5, 5, 5, 5, 25, ...</td>\n",
       "      <td>[1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, ...</td>\n",
       "      <td>[2, 4, 2, 1, 2, 3, 2, 2, 4, 3, 3, 4, 2, 4, 4, ...</td>\n",
       "      <td>[25, 5, 25, 5, 25, 25, 25, 25, 5, 25, 25, 5, 2...</td>\n",
       "      <td>[0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...</td>\n",
       "      <td>[1, 2, 3, 3, 4, 2, 3, 3, 1, 1, 2, 4, 2, 3, 1, ...</td>\n",
       "      <td>[5, 25, 25, 25, 5, 25, 25, 25, 5, 5, 25, 5, 25...</td>\n",
       "      <td>[1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, ...</td>\n",
       "      <td>[1, 3, 2, 4, 4, 3, 2, 3, 1, 4, 4, 4, 2, 3, 1, ...</td>\n",
       "      <td>[5, 25, 25, 5, 5, 25, 25, 25, 5, 5, 5, 5, 25, ...</td>\n",
       "      <td>[1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...</td>\n",
       "      <td>[1, 1, 4, 3, 1, 3, 2, 1, 1, 1, 1, 3, 4, 3, 3, ...</td>\n",
       "      <td>[5, 5, 5, 25, 5, 25, 25, 5, 5, 5, 5, 25, 5, 25...</td>\n",
       "      <td>[1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, ...</td>\n",
       "      <td>True</td>\n",
       "      <td>C:\\svnwork\\neuro1\\code\\psychophysics\\abstracti...</td>\n",
       "      <td>[[], [], img_14.bmp, img_7.bmp, img_4.bmp, img...</td>\n",
       "      <td>[False, False, False, False, False, False, Fal...</td>\n",
       "      <td>[False, False, False, False, False, False, Tru...</td>\n",
       "      <td>[[], [], [], [], [], [], [], [], [], [], [], [...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...</td>\n",
       "      <td>[1, 3, 4, 2, 3, 3, 1, 1, 2, 4, 2, 3, 1, 4, 2, ...</td>\n",
       "      <td>[5, 25, 5, 25, 25, 25, 5, 5, 25, 5, 25, 25, 5,...</td>\n",
       "      <td>[1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, ...</td>\n",
       "      <td>[1, 3, 4, 2, 3, 2, 4, 4, 2, 3, 3, 3, 4, 2, 2, ...</td>\n",
       "      <td>[5, 25, 5, 25, 25, 25, 5, 5, 25, 25, 25, 5, 5,...</td>\n",
       "      <td>[1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, ...</td>\n",
       "      <td>[1, 2, 1, 2, 3, 2, 2, 4, 3, 3, 4, 2, 4, 4, 2, ...</td>\n",
       "      <td>[5, 25, 5, 25, 25, 25, 25, 5, 25, 25, 5, 25, 5...</td>\n",
       "      <td>[1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...</td>\n",
       "      <td>[1, 4, 1, 3, 3, 3, 3, 1, 4, 1, 2, 4, 4, 2, 2, ...</td>\n",
       "      <td>[5, 5, 5, 25, 25, 25, 25, 5, 5, 5, 25, 5, 5, 2...</td>\n",
       "      <td>[1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>True</td>\n",
       "      <td>C:\\svnwork\\neuro1\\code\\psychophysics\\abstracti...</td>\n",
       "      <td>[[], [], img_14.bmp, img_13.bmp, img_12.bmp, i...</td>\n",
       "      <td>[False, False, False, False, False, False, Fal...</td>\n",
       "      <td>[False, False, False, False, False, False, Fal...</td>\n",
       "      <td>[[], [], [], [], [], [], [], [], [], [], [], [...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...</td>\n",
       "      <td>[2, 4, 3, 3, 1, 3, 1, 3, 3, 3, 4, 4, 4, 3, 4, ...</td>\n",
       "      <td>[25, 5, 25, 25, 5, 25, 5, 25, 25, 25, 5, 5, 5,...</td>\n",
       "      <td>[0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, ...</td>\n",
       "      <td>[2, 3, 3, 3, 1, 1, 4, 1, 1, 3, 4, 3, 1, 2, 2, ...</td>\n",
       "      <td>[25, 25, 25, 25, 5, 5, 5, 5, 5, 25, 5, 25, 5, ...</td>\n",
       "      <td>[0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...</td>\n",
       "      <td>[1, 1, 3, 3, 3, 4, 4, 4, 3, 4, 3, 1, 1, 4, 2, ...</td>\n",
       "      <td>[5, 5, 25, 25, 25, 5, 5, 5, 25, 5, 25, 5, 5, 5...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...</td>\n",
       "      <td>[1, 2, 3, 3, 4, 2, 3, 3, 1, 1, 2, 4, 2, 3, 1, ...</td>\n",
       "      <td>[5, 25, 25, 25, 5, 25, 25, 25, 5, 5, 25, 5, 25...</td>\n",
       "      <td>[1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, ...</td>\n",
       "      <td>[1, 3, 2, 4, 4, 3, 2, 3, 1, 4, 4, 4, 2, 3, 1, ...</td>\n",
       "      <td>[5, 25, 25, 5, 5, 25, 25, 25, 5, 5, 5, 5, 25, ...</td>\n",
       "      <td>[1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...</td>\n",
       "      <td>[1, 2, 3, 3, 4, 2, 3, 3, 1, 1, 2, 4, 2, 3, 1, ...</td>\n",
       "      <td>[5, 25, 25, 25, 5, 25, 25, 25, 5, 5, 25, 5, 25...</td>\n",
       "      <td>[1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...</td>\n",
       "      <td>[1, 3, 1, 1, 2, 4, 2, 3, 1, 4, 2, 3, 3, 4, 4, ...</td>\n",
       "      <td>[5, 25, 5, 5, 25, 5, 25, 25, 5, 5, 25, 25, 25,...</td>\n",
       "      <td>[1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...</td>\n",
       "      <td>[2, 4, 1, 1, 3, 1, 3, 3, 4, 2, 2, 3, 3, 3, 2, ...</td>\n",
       "      <td>[25, 5, 5, 5, 25, 5, 25, 25, 5, 25, 25, 25, 25...</td>\n",
       "      <td>[0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, ...</td>\n",
       "      <td>[2, 1, 2, 3, 2, 2, 4, 3, 3, 4, 2, 4, 4, 2, 3, ...</td>\n",
       "      <td>[25, 5, 25, 25, 25, 25, 5, 25, 25, 5, 25, 5, 5...</td>\n",
       "      <td>[0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...</td>\n",
       "      <td>[1, 2, 4, 4, 3, 2, 3, 1, 4, 4, 4, 2, 3, 1, 2, ...</td>\n",
       "      <td>[5, 25, 5, 5, 25, 25, 25, 5, 5, 5, 5, 25, 25, ...</td>\n",
       "      <td>[1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...</td>\n",
       "      <td>[1, 3, 3, 4, 2, 2, 2, 4, 4, 1, 1, 2, 1, 3, 2, ...</td>\n",
       "      <td>[5, 25, 25, 5, 25, 25, 25, 5, 5, 5, 5, 25, 5, ...</td>\n",
       "      <td>[1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...</td>\n",
       "      <td>[1, 3, 1, 1, 2, 4, 2, 3, 1, 4, 2, 3, 3, 4, 4, ...</td>\n",
       "      <td>[5, 25, 5, 5, 25, 5, 25, 25, 5, 5, 25, 25, 25,...</td>\n",
       "      <td>[1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...</td>\n",
       "      <td>[2, 4, 1, 1, 3, 1, 3, 3, 4, 2, 2, 3, 3, 3, 2, ...</td>\n",
       "      <td>[25, 5, 5, 5, 25, 5, 25, 25, 5, 25, 25, 25, 25...</td>\n",
       "      <td>[0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, ...</td>\n",
       "      <td>[2, 4, 2, 1, 2, 3, 2, 2, 4, 3, 3, 4, 2, 4, 4, ...</td>\n",
       "      <td>[25, 5, 25, 5, 25, 25, 25, 25, 5, 25, 25, 5, 2...</td>\n",
       "      <td>[0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...</td>\n",
       "      <td>[1, 2, 1, 3, 1, 2, 3, 2, 2, 3, 2, 4, 4, 3, 2, ...</td>\n",
       "      <td>[5, 25, 5, 25, 5, 25, 25, 25, 25, 25, 25, 5, 5...</td>\n",
       "      <td>[1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...</td>\n",
       "      <td>[1, 2, 1, 3, 1, 2, 3, 2, 2, 3, 2, 4, 4, 3, 2, ...</td>\n",
       "      <td>[5, 25, 5, 25, 5, 25, 25, 25, 25, 25, 25, 5, 5...</td>\n",
       "      <td>[1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, ...</td>\n",
       "      <td>[2, 4, 4, 4, 3, 1, 2, 1, 1, 4, 2, 2, 2, 2, 3, ...</td>\n",
       "      <td>[25, 5, 5, 5, 25, 5, 25, 5, 5, 5, 25, 25, 25, ...</td>\n",
       "      <td>[0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...</td>\n",
       "      <td>[1, 3, 4, 2, 3, 3, 1, 1, 2, 4, 2, 3, 1, 4, 2, ...</td>\n",
       "      <td>[5, 25, 5, 25, 25, 25, 5, 5, 25, 5, 25, 25, 5,...</td>\n",
       "      <td>[1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, ...</td>\n",
       "      <td>[1, 3, 4, 2, 3, 2, 4, 4, 2, 3, 3, 3, 4, 2, 2, ...</td>\n",
       "      <td>[5, 25, 5, 25, 25, 25, 5, 5, 25, 25, 25, 5, 5,...</td>\n",
       "      <td>[1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...</td>\n",
       "      <td>[1, 4, 1, 1, 3, 3, 3, 1, 2, 1, 4, 2, 3, 2, 3, ...</td>\n",
       "      <td>[5, 5, 5, 5, 25, 25, 25, 5, 25, 5, 5, 25, 25, ...</td>\n",
       "      <td>[1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...</td>\n",
       "      <td>[2, 2, 2, 4, 4, 1, 4, 1, 1, 4, 1, 2, 4, 1, 2, ...</td>\n",
       "      <td>[25, 25, 25, 5, 5, 5, 5, 5, 5, 5, 5, 25, 5, 5,...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              context  \\\n",
       "0   [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...   \n",
       "1   [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...   \n",
       "2   [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...   \n",
       "3   [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...   \n",
       "4   [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, ...   \n",
       "5   [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...   \n",
       "6   [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, ...   \n",
       "7   [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, ...   \n",
       "8   [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...   \n",
       "9   [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, ...   \n",
       "10  [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...   \n",
       "11  [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...   \n",
       "12  [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, ...   \n",
       "13  [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, ...   \n",
       "14  [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...   \n",
       "15  [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...   \n",
       "16  [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, ...   \n",
       "17  [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...   \n",
       "18  [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...   \n",
       "19  [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, ...   \n",
       "20  [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...   \n",
       "21  [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...   \n",
       "22  [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...   \n",
       "23  [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, ...   \n",
       "24  [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...   \n",
       "25  [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...   \n",
       "26  [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...   \n",
       "27  [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...   \n",
       "28  [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, ...   \n",
       "29  [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...   \n",
       "30  [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...   \n",
       "31  [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, ...   \n",
       "32  [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...   \n",
       "33  [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, ...   \n",
       "34  [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...   \n",
       "35  [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...   \n",
       "\n",
       "                                        stim_sequence  \\\n",
       "0   [2, 4, 1, 2, 4, 4, 4, 3, 1, 4, 4, 3, 4, 3, 2, ...   \n",
       "1   [1, 2, 4, 4, 3, 2, 3, 1, 4, 4, 4, 2, 3, 1, 2, ...   \n",
       "2   [1, 3, 3, 4, 2, 2, 2, 4, 4, 1, 1, 2, 1, 3, 2, ...   \n",
       "3   [2, 2, 3, 3, 1, 2, 2, 3, 2, 4, 4, 2, 2, 3, 4, ...   \n",
       "4   [2, 1, 2, 3, 2, 2, 4, 3, 3, 4, 2, 4, 4, 2, 3, ...   \n",
       "5   [1, 2, 3, 3, 4, 2, 3, 3, 1, 1, 2, 4, 2, 3, 1, ...   \n",
       "6   [1, 3, 2, 4, 4, 3, 2, 3, 1, 4, 4, 4, 2, 3, 1, ...   \n",
       "7   [2, 4, 2, 1, 2, 3, 2, 2, 4, 3, 3, 4, 2, 4, 4, ...   \n",
       "8   [1, 2, 3, 3, 4, 2, 3, 3, 1, 1, 2, 4, 2, 3, 1, ...   \n",
       "9   [1, 3, 2, 4, 4, 3, 2, 3, 1, 4, 4, 4, 2, 3, 1, ...   \n",
       "10  [1, 1, 4, 3, 1, 3, 2, 1, 1, 1, 1, 3, 4, 3, 3, ...   \n",
       "11  [1, 3, 4, 2, 3, 3, 1, 1, 2, 4, 2, 3, 1, 4, 2, ...   \n",
       "12  [1, 3, 4, 2, 3, 2, 4, 4, 2, 3, 3, 3, 4, 2, 2, ...   \n",
       "13  [1, 2, 1, 2, 3, 2, 2, 4, 3, 3, 4, 2, 4, 4, 2, ...   \n",
       "14  [1, 4, 1, 3, 3, 3, 3, 1, 4, 1, 2, 4, 4, 2, 2, ...   \n",
       "15  [2, 4, 3, 3, 1, 3, 1, 3, 3, 3, 4, 4, 4, 3, 4, ...   \n",
       "16  [2, 3, 3, 3, 1, 1, 4, 1, 1, 3, 4, 3, 1, 2, 2, ...   \n",
       "17  [1, 1, 3, 3, 3, 4, 4, 4, 3, 4, 3, 1, 1, 4, 2, ...   \n",
       "18  [1, 2, 3, 3, 4, 2, 3, 3, 1, 1, 2, 4, 2, 3, 1, ...   \n",
       "19  [1, 3, 2, 4, 4, 3, 2, 3, 1, 4, 4, 4, 2, 3, 1, ...   \n",
       "20  [1, 2, 3, 3, 4, 2, 3, 3, 1, 1, 2, 4, 2, 3, 1, ...   \n",
       "21  [1, 3, 1, 1, 2, 4, 2, 3, 1, 4, 2, 3, 3, 4, 4, ...   \n",
       "22  [2, 4, 1, 1, 3, 1, 3, 3, 4, 2, 2, 3, 3, 3, 2, ...   \n",
       "23  [2, 1, 2, 3, 2, 2, 4, 3, 3, 4, 2, 4, 4, 2, 3, ...   \n",
       "24  [1, 2, 4, 4, 3, 2, 3, 1, 4, 4, 4, 2, 3, 1, 2, ...   \n",
       "25  [1, 3, 3, 4, 2, 2, 2, 4, 4, 1, 1, 2, 1, 3, 2, ...   \n",
       "26  [1, 3, 1, 1, 2, 4, 2, 3, 1, 4, 2, 3, 3, 4, 4, ...   \n",
       "27  [2, 4, 1, 1, 3, 1, 3, 3, 4, 2, 2, 3, 3, 3, 2, ...   \n",
       "28  [2, 4, 2, 1, 2, 3, 2, 2, 4, 3, 3, 4, 2, 4, 4, ...   \n",
       "29  [1, 2, 1, 3, 1, 2, 3, 2, 2, 3, 2, 4, 4, 3, 2, ...   \n",
       "30  [1, 2, 1, 3, 1, 2, 3, 2, 2, 3, 2, 4, 4, 3, 2, ...   \n",
       "31  [2, 4, 4, 4, 3, 1, 2, 1, 1, 4, 2, 2, 2, 2, 3, ...   \n",
       "32  [1, 3, 4, 2, 3, 3, 1, 1, 2, 4, 2, 3, 1, 4, 2, ...   \n",
       "33  [1, 3, 4, 2, 3, 2, 4, 4, 2, 3, 3, 3, 4, 2, 2, ...   \n",
       "34  [1, 4, 1, 1, 3, 3, 3, 1, 2, 1, 4, 2, 3, 2, 3, ...   \n",
       "35  [2, 2, 2, 4, 4, 1, 4, 1, 1, 4, 1, 2, 4, 1, 2, ...   \n",
       "\n",
       "                                      reward_sequence  \\\n",
       "0   [25, 5, 5, 25, 5, 5, 5, 25, 5, 5, 5, 25, 5, 25...   \n",
       "1   [5, 25, 5, 5, 25, 25, 25, 5, 5, 5, 5, 25, 25, ...   \n",
       "2   [5, 25, 25, 5, 25, 25, 25, 5, 5, 5, 5, 25, 5, ...   \n",
       "3   [25, 25, 25, 25, 5, 25, 25, 25, 25, 5, 5, 25, ...   \n",
       "4   [25, 5, 25, 25, 25, 25, 5, 25, 25, 5, 25, 5, 5...   \n",
       "5   [5, 25, 25, 25, 5, 25, 25, 25, 5, 5, 25, 5, 25...   \n",
       "6   [5, 25, 25, 5, 5, 25, 25, 25, 5, 5, 5, 5, 25, ...   \n",
       "7   [25, 5, 25, 5, 25, 25, 25, 25, 5, 25, 25, 5, 2...   \n",
       "8   [5, 25, 25, 25, 5, 25, 25, 25, 5, 5, 25, 5, 25...   \n",
       "9   [5, 25, 25, 5, 5, 25, 25, 25, 5, 5, 5, 5, 25, ...   \n",
       "10  [5, 5, 5, 25, 5, 25, 25, 5, 5, 5, 5, 25, 5, 25...   \n",
       "11  [5, 25, 5, 25, 25, 25, 5, 5, 25, 5, 25, 25, 5,...   \n",
       "12  [5, 25, 5, 25, 25, 25, 5, 5, 25, 25, 25, 5, 5,...   \n",
       "13  [5, 25, 5, 25, 25, 25, 25, 5, 25, 25, 5, 25, 5...   \n",
       "14  [5, 5, 5, 25, 25, 25, 25, 5, 5, 5, 25, 5, 5, 2...   \n",
       "15  [25, 5, 25, 25, 5, 25, 5, 25, 25, 25, 5, 5, 5,...   \n",
       "16  [25, 25, 25, 25, 5, 5, 5, 5, 5, 25, 5, 25, 5, ...   \n",
       "17  [5, 5, 25, 25, 25, 5, 5, 5, 25, 5, 25, 5, 5, 5...   \n",
       "18  [5, 25, 25, 25, 5, 25, 25, 25, 5, 5, 25, 5, 25...   \n",
       "19  [5, 25, 25, 5, 5, 25, 25, 25, 5, 5, 5, 5, 25, ...   \n",
       "20  [5, 25, 25, 25, 5, 25, 25, 25, 5, 5, 25, 5, 25...   \n",
       "21  [5, 25, 5, 5, 25, 5, 25, 25, 5, 5, 25, 25, 25,...   \n",
       "22  [25, 5, 5, 5, 25, 5, 25, 25, 5, 25, 25, 25, 25...   \n",
       "23  [25, 5, 25, 25, 25, 25, 5, 25, 25, 5, 25, 5, 5...   \n",
       "24  [5, 25, 5, 5, 25, 25, 25, 5, 5, 5, 5, 25, 25, ...   \n",
       "25  [5, 25, 25, 5, 25, 25, 25, 5, 5, 5, 5, 25, 5, ...   \n",
       "26  [5, 25, 5, 5, 25, 5, 25, 25, 5, 5, 25, 25, 25,...   \n",
       "27  [25, 5, 5, 5, 25, 5, 25, 25, 5, 25, 25, 25, 25...   \n",
       "28  [25, 5, 25, 5, 25, 25, 25, 25, 5, 25, 25, 5, 2...   \n",
       "29  [5, 25, 5, 25, 5, 25, 25, 25, 25, 25, 25, 5, 5...   \n",
       "30  [5, 25, 5, 25, 5, 25, 25, 25, 25, 25, 25, 5, 5...   \n",
       "31  [25, 5, 5, 5, 25, 5, 25, 5, 5, 5, 25, 25, 25, ...   \n",
       "32  [5, 25, 5, 25, 25, 25, 5, 5, 25, 5, 25, 25, 5,...   \n",
       "33  [5, 25, 5, 25, 25, 25, 5, 5, 25, 25, 25, 5, 5,...   \n",
       "34  [5, 5, 5, 5, 25, 25, 25, 5, 25, 5, 5, 25, 25, ...   \n",
       "35  [25, 25, 25, 5, 5, 5, 5, 5, 5, 5, 5, 25, 5, 5,...   \n",
       "\n",
       "                                    response_sequence is_novel_variant  \\\n",
       "0   [0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, ...              NaN   \n",
       "1   [1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, ...              NaN   \n",
       "2   [1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, ...              NaN   \n",
       "3   [0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, ...              NaN   \n",
       "4   [0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, ...              NaN   \n",
       "5   [1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, ...              NaN   \n",
       "6   [1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, ...              NaN   \n",
       "7   [0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, ...              NaN   \n",
       "8   [1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, ...              NaN   \n",
       "9   [1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, ...              NaN   \n",
       "10  [1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, ...             True   \n",
       "11  [1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, ...              NaN   \n",
       "12  [1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, ...              NaN   \n",
       "13  [1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, ...              NaN   \n",
       "14  [1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, ...             True   \n",
       "15  [0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, ...              NaN   \n",
       "16  [0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, ...              NaN   \n",
       "17  [1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, ...              NaN   \n",
       "18  [1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, ...              NaN   \n",
       "19  [1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, ...              NaN   \n",
       "20  [1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, ...              NaN   \n",
       "21  [1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, ...              NaN   \n",
       "22  [0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, ...              NaN   \n",
       "23  [0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, ...              NaN   \n",
       "24  [1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, ...              NaN   \n",
       "25  [1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, ...              NaN   \n",
       "26  [1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, ...              NaN   \n",
       "27  [0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, ...              NaN   \n",
       "28  [0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, ...              NaN   \n",
       "29  [1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, ...              NaN   \n",
       "30  [1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, ...              NaN   \n",
       "31  [0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, ...              NaN   \n",
       "32  [1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, ...              NaN   \n",
       "33  [1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, ...              NaN   \n",
       "34  [1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, ...              NaN   \n",
       "35  [0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, ...              NaN   \n",
       "\n",
       "                                       novel_stim_dir  \\\n",
       "0                                                 NaN   \n",
       "1                                                 NaN   \n",
       "2                                                 NaN   \n",
       "3                                                 NaN   \n",
       "4                                                 NaN   \n",
       "5                                                 NaN   \n",
       "6                                                 NaN   \n",
       "7                                                 NaN   \n",
       "8                                                 NaN   \n",
       "9                                                 NaN   \n",
       "10  C:\\svnwork\\neuro1\\code\\psychophysics\\abstracti...   \n",
       "11                                                NaN   \n",
       "12                                                NaN   \n",
       "13                                                NaN   \n",
       "14  C:\\svnwork\\neuro1\\code\\psychophysics\\abstracti...   \n",
       "15                                                NaN   \n",
       "16                                                NaN   \n",
       "17                                                NaN   \n",
       "18                                                NaN   \n",
       "19                                                NaN   \n",
       "20                                                NaN   \n",
       "21                                                NaN   \n",
       "22                                                NaN   \n",
       "23                                                NaN   \n",
       "24                                                NaN   \n",
       "25                                                NaN   \n",
       "26                                                NaN   \n",
       "27                                                NaN   \n",
       "28                                                NaN   \n",
       "29                                                NaN   \n",
       "30                                                NaN   \n",
       "31                                                NaN   \n",
       "32                                                NaN   \n",
       "33                                                NaN   \n",
       "34                                                NaN   \n",
       "35                                                NaN   \n",
       "\n",
       "                                    novel_block_image  \\\n",
       "0                                                 NaN   \n",
       "1                                                 NaN   \n",
       "2                                                 NaN   \n",
       "3                                                 NaN   \n",
       "4                                                 NaN   \n",
       "5                                                 NaN   \n",
       "6                                                 NaN   \n",
       "7                                                 NaN   \n",
       "8                                                 NaN   \n",
       "9                                                 NaN   \n",
       "10  [[], [], img_14.bmp, img_7.bmp, img_4.bmp, img...   \n",
       "11                                                NaN   \n",
       "12                                                NaN   \n",
       "13                                                NaN   \n",
       "14  [[], [], img_14.bmp, img_13.bmp, img_12.bmp, i...   \n",
       "15                                                NaN   \n",
       "16                                                NaN   \n",
       "17                                                NaN   \n",
       "18                                                NaN   \n",
       "19                                                NaN   \n",
       "20                                                NaN   \n",
       "21                                                NaN   \n",
       "22                                                NaN   \n",
       "23                                                NaN   \n",
       "24                                                NaN   \n",
       "25                                                NaN   \n",
       "26                                                NaN   \n",
       "27                                                NaN   \n",
       "28                                                NaN   \n",
       "29                                                NaN   \n",
       "30                                                NaN   \n",
       "31                                                NaN   \n",
       "32                                                NaN   \n",
       "33                                                NaN   \n",
       "34                                                NaN   \n",
       "35                                                NaN   \n",
       "\n",
       "                                            remapping  \\\n",
       "0                                                 NaN   \n",
       "1                                                 NaN   \n",
       "2                                                 NaN   \n",
       "3                                                 NaN   \n",
       "4                                                 NaN   \n",
       "5                                                 NaN   \n",
       "6                                                 NaN   \n",
       "7                                                 NaN   \n",
       "8                                                 NaN   \n",
       "9                                                 NaN   \n",
       "10  [False, False, False, False, False, False, Fal...   \n",
       "11                                                NaN   \n",
       "12                                                NaN   \n",
       "13                                                NaN   \n",
       "14  [False, False, False, False, False, False, Fal...   \n",
       "15                                                NaN   \n",
       "16                                                NaN   \n",
       "17                                                NaN   \n",
       "18                                                NaN   \n",
       "19                                                NaN   \n",
       "20                                                NaN   \n",
       "21                                                NaN   \n",
       "22                                                NaN   \n",
       "23                                                NaN   \n",
       "24                                                NaN   \n",
       "25                                                NaN   \n",
       "26                                                NaN   \n",
       "27                                                NaN   \n",
       "28                                                NaN   \n",
       "29                                                NaN   \n",
       "30                                                NaN   \n",
       "31                                                NaN   \n",
       "32                                                NaN   \n",
       "33                                                NaN   \n",
       "34                                                NaN   \n",
       "35                                                NaN   \n",
       "\n",
       "                                      stim_to_replace  \\\n",
       "0                                                 NaN   \n",
       "1                                                 NaN   \n",
       "2                                                 NaN   \n",
       "3                                                 NaN   \n",
       "4                                                 NaN   \n",
       "5                                                 NaN   \n",
       "6                                                 NaN   \n",
       "7                                                 NaN   \n",
       "8                                                 NaN   \n",
       "9                                                 NaN   \n",
       "10  [False, False, False, False, False, False, Tru...   \n",
       "11                                                NaN   \n",
       "12                                                NaN   \n",
       "13                                                NaN   \n",
       "14  [False, False, False, False, False, False, Fal...   \n",
       "15                                                NaN   \n",
       "16                                                NaN   \n",
       "17                                                NaN   \n",
       "18                                                NaN   \n",
       "19                                                NaN   \n",
       "20                                                NaN   \n",
       "21                                                NaN   \n",
       "22                                                NaN   \n",
       "23                                                NaN   \n",
       "24                                                NaN   \n",
       "25                                                NaN   \n",
       "26                                                NaN   \n",
       "27                                                NaN   \n",
       "28                                                NaN   \n",
       "29                                                NaN   \n",
       "30                                                NaN   \n",
       "31                                                NaN   \n",
       "32                                                NaN   \n",
       "33                                                NaN   \n",
       "34                                                NaN   \n",
       "35                                                NaN   \n",
       "\n",
       "                                         replace_name  \n",
       "0                                                 NaN  \n",
       "1                                                 NaN  \n",
       "2                                                 NaN  \n",
       "3                                                 NaN  \n",
       "4                                                 NaN  \n",
       "5                                                 NaN  \n",
       "6                                                 NaN  \n",
       "7                                                 NaN  \n",
       "8                                                 NaN  \n",
       "9                                                 NaN  \n",
       "10  [[], [], [], [], [], [], [], [], [], [], [], [...  \n",
       "11                                                NaN  \n",
       "12                                                NaN  \n",
       "13                                                NaN  \n",
       "14  [[], [], [], [], [], [], [], [], [], [], [], [...  \n",
       "15                                                NaN  \n",
       "16                                                NaN  \n",
       "17                                                NaN  \n",
       "18                                                NaN  \n",
       "19                                                NaN  \n",
       "20                                                NaN  \n",
       "21                                                NaN  \n",
       "22                                                NaN  \n",
       "23                                                NaN  \n",
       "24                                                NaN  \n",
       "25                                                NaN  \n",
       "26                                                NaN  \n",
       "27                                                NaN  \n",
       "28                                                NaN  \n",
       "29                                                NaN  \n",
       "30                                                NaN  \n",
       "31                                                NaN  \n",
       "32                                                NaN  \n",
       "33                                                NaN  \n",
       "34                                                NaN  \n",
       "35                                                NaN  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Task information for given session\n",
    "task_data = pd.DataFrame(all_beh_data[\"task_info\"])\n",
    "task_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(task_data[\"context\"].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ True,  True,  True,  True,  True,  True,  True,  True,  True],\n",
       "        [ True,  True, False, False,  True,  True,  True,  True, False],\n",
       "        [False, False,  True,  True,  True, False,  True,  True,  True],\n",
       "        [ True,  True, False, False,  True,  True,  True, False,  True],\n",
       "        [ True, False,  True,  True,  True, False,  True,  True,  True]]),\n",
       " array([[False,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True],\n",
       "        [ True, False, False, False, False, False,  True, False, False,\n",
       "         False],\n",
       "        [ True, False,  True, False, False,  True,  True,  True, False,\n",
       "          True],\n",
       "        [ True, False,  True,  True,  True, False,  True,  True,  True,\n",
       "         False],\n",
       "        [ True,  True, False,  True,  True,  True, False,  True,  True,\n",
       "          True]]),\n",
       " array([[ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True],\n",
       "        [False,  True,  True,  True,  True,  True,  True, False,  True,\n",
       "          True,  True, False,  True,  True,  True],\n",
       "        [ True,  True,  True, False,  True,  True,  True, False,  True,\n",
       "          True,  True, False,  True,  True,  True],\n",
       "        [ True,  True,  True, False,  True,  True,  True, False,  True,\n",
       "          True,  True, False,  True,  True,  True],\n",
       "        [ True,  True,  True, False,  True,  True,  True, False,  True,\n",
       "          True,  True, False,  True,  True,  True]]),\n",
       " array([[ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True],\n",
       "        [False, False,  True, False,  True,  True,  True, False,  True,\n",
       "          True,  True, False, False,  True,  True],\n",
       "        [ True,  True,  True, False,  True,  True,  True, False, False,\n",
       "          True,  True, False, False,  True,  True],\n",
       "        [ True,  True,  True, False,  True,  True,  True, False,  True,\n",
       "          True,  True, False,  True,  True,  True],\n",
       "        [ True,  True,  True, False, False,  True,  True, False, False,\n",
       "         False,  True, False, False,  True,  True]]),\n",
       " array([[ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True],\n",
       "        [False, False,  True, False,  True,  True,  True, False,  True,\n",
       "          True,  True, False,  True,  True,  True],\n",
       "        [ True,  True,  True, False,  True,  True,  True, False,  True,\n",
       "          True,  True, False,  True,  True,  True],\n",
       "        [ True,  True, False, False,  True,  True,  True, False,  True,\n",
       "          True,  True, False,  True,  True,  True],\n",
       "        [False,  True,  True, False,  True,  True,  True, False,  True,\n",
       "          True,  True, False,  True, False,  True]]),\n",
       " array([[ True,  True,  True,  True,  True,  True,  True,  True,  True],\n",
       "        [ True, False, False, False,  True, False,  True,  True,  True],\n",
       "        [False, False, False,  True, False, False, False, False,  True],\n",
       "        [ True, False, False, False, False,  True, False, False, False],\n",
       "        [ True, False,  True, False, False, False, False,  True,  True]]),\n",
       " array([[ True,  True,  True, False,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True],\n",
       "        [ True,  True,  True, False,  True, False,  True, False,  True,\n",
       "         False,  True, False,  True,  True,  True],\n",
       "        [False,  True,  True, False, False,  True, False, False, False,\n",
       "         False,  True, False, False,  True,  True],\n",
       "        [ True, False,  True,  True, False,  True,  True,  True,  True,\n",
       "          True,  True, False, False, False,  True],\n",
       "        [ True,  True,  True, False,  True,  True,  True,  True,  True,\n",
       "         False,  True, False, False,  True,  True]]),\n",
       " array([[ True,  True,  True, False,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True],\n",
       "        [False,  True,  True, False,  True,  True,  True, False,  True,\n",
       "          True,  True, False,  True,  True,  True],\n",
       "        [ True,  True,  True, False,  True,  True,  True, False,  True,\n",
       "          True,  True, False,  True,  True,  True],\n",
       "        [ True,  True,  True, False,  True,  True,  True, False,  True,\n",
       "         False,  True, False,  True, False,  True],\n",
       "        [False,  True,  True, False,  True,  True,  True, False,  True,\n",
       "          True,  True, False,  True,  True,  True]]),\n",
       " array([[ True,  True,  True,  True,  True,  True,  True,  True,  True],\n",
       "        [False,  True,  True, False, False, False, False, False, False],\n",
       "        [ True, False,  True, False,  True, False,  True,  True,  True],\n",
       "        [ True,  True,  True, False,  True,  True,  True, False,  True],\n",
       "        [ True, False,  True,  True,  True, False,  True,  True,  True]]),\n",
       " array([[ True,  True,  True,  True,  True,  True,  True, False,  True,\n",
       "          True, False, False,  True,  True,  True],\n",
       "        [ True, False, False, False,  True, False,  True, False,  True,\n",
       "          True,  True, False,  True, False,  True],\n",
       "        [False,  True,  True, False,  True,  True,  True, False, False,\n",
       "          True,  True, False,  True,  True,  True],\n",
       "        [ True,  True,  True, False, False, False,  True,  True, False,\n",
       "         False,  True, False,  True, False,  True],\n",
       "        [False,  True, False, False, False,  True,  True, False,  True,\n",
       "          True,  True, False,  True,  True,  True]]),\n",
       " array([[ True, False,  True,  True,  True, False,  True,  True,  True,\n",
       "          True,  True, False,  True,  True,  True],\n",
       "        [False, False,  True, False, False,  True,  True, False,  True,\n",
       "          True,  True,  True,  True,  True, False],\n",
       "        [ True,  True, False, False,  True,  True, False, False,  True,\n",
       "         False,  True, False,  True,  True,  True],\n",
       "        [False,  True, False, False, False,  True,  True, False,  True,\n",
       "          True,  True, False,  True,  True,  True],\n",
       "        [ True, False, False, False,  True,  True,  True, False,  True,\n",
       "          True,  True, False,  True,  True,  True]]),\n",
       " array([[ True,  True,  True,  True, False,  True,  True, False,  True],\n",
       "        [ True, False,  True, False, False, False,  True,  True, False],\n",
       "        [ True,  True, False, False, False, False, False,  True, False],\n",
       "        [ True,  True, False, False,  True,  True, False,  True, False],\n",
       "        [False,  True, False,  True, False, False,  True, False,  True]]),\n",
       " array([[ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True],\n",
       "        [ True,  True,  True, False,  True,  True,  True, False,  True,\n",
       "          True,  True, False,  True,  True,  True],\n",
       "        [ True,  True,  True, False,  True,  True,  True, False,  True,\n",
       "          True,  True, False,  True,  True,  True],\n",
       "        [ True,  True,  True, False,  True,  True,  True, False,  True,\n",
       "          True,  True, False,  True,  True,  True],\n",
       "        [ True,  True,  True, False,  True,  True,  True, False,  True,\n",
       "          True,  True, False,  True,  True,  True]]),\n",
       " array([[ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True],\n",
       "        [ True, False,  True, False,  True,  True,  True, False,  True,\n",
       "          True,  True, False,  True,  True,  True],\n",
       "        [ True,  True,  True, False,  True,  True,  True, False,  True,\n",
       "          True,  True, False,  True,  True,  True],\n",
       "        [ True,  True,  True, False,  True,  True,  True, False,  True,\n",
       "          True,  True, False,  True,  True,  True],\n",
       "        [ True,  True,  True, False,  True,  True,  True, False,  True,\n",
       "          True,  True, False,  True,  True,  True]]),\n",
       " array([[ True,  True,  True,  True, False,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True],\n",
       "        [ True,  True,  True, False,  True,  True,  True, False,  True,\n",
       "          True,  True, False,  True,  True, False],\n",
       "        [ True,  True,  True, False,  True,  True,  True, False,  True,\n",
       "          True, False, False,  True,  True, False],\n",
       "        [False,  True,  True, False,  True,  True, False, False,  True,\n",
       "          True, False, False,  True,  True,  True],\n",
       "        [False,  True,  True, False,  True,  True, False, False,  True,\n",
       "          True, False, False,  True,  True, False]]),\n",
       " array([[ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True],\n",
       "        [False, False, False,  True, False,  True,  True, False,  True,\n",
       "          True,  True],\n",
       "        [ True,  True,  True, False,  True,  True,  True, False,  True,\n",
       "          True,  True],\n",
       "        [ True,  True,  True, False,  True,  True, False, False,  True,\n",
       "          True,  True],\n",
       "        [ True,  True,  True, False,  True,  True,  True, False,  True,\n",
       "          True,  True]]),\n",
       " array([[ True,  True,  True,  True,  True,  True,  True,  True,  True],\n",
       "        [ True, False, False, False, False,  True,  True, False,  True],\n",
       "        [ True, False,  True, False, False, False, False,  True, False],\n",
       "        [False,  True,  True, False, False,  True,  True, False, False],\n",
       "        [ True, False, False, False, False, False,  True,  True,  True]]),\n",
       " array([[ True,  True,  True,  True, False, False,  True,  True,  True,\n",
       "          True,  True,  True, False,  True,  True],\n",
       "        [False,  True,  True, False, False,  True,  True, False,  True,\n",
       "         False,  True, False,  True, False,  True],\n",
       "        [ True,  True,  True,  True, False,  True,  True, False, False,\n",
       "          True, False,  True, False, False,  True],\n",
       "        [False,  True, False, False,  True,  True,  True, False,  True,\n",
       "          True,  True, False,  True,  True,  True],\n",
       "        [ True,  True,  True, False,  True,  True,  True, False, False,\n",
       "          True,  True, False,  True,  True,  True]]),\n",
       " array([[ True, False,  True,  True, False,  True,  True,  True,  True],\n",
       "        [False,  True, False, False, False, False, False, False,  True],\n",
       "        [False, False, False,  True, False,  True, False,  True, False],\n",
       "        [False,  True, False, False, False,  True,  True, False,  True],\n",
       "        [False,  True, False, False,  True,  True, False,  True, False]]),\n",
       " array([[ True,  True,  True, False,  True, False,  True,  True,  True,\n",
       "          True, False,  True,  True,  True,  True],\n",
       "        [ True, False, False, False, False, False,  True, False,  True,\n",
       "         False,  True, False, False, False,  True],\n",
       "        [ True,  True,  True, False, False,  True,  True, False, False,\n",
       "          True,  True, False,  True,  True,  True],\n",
       "        [ True, False,  True,  True,  True, False, False,  True, False,\n",
       "          True, False, False, False, False,  True],\n",
       "        [False,  True,  True, False,  True,  True, False, False, False,\n",
       "          True, False,  True, False, False,  True]]),\n",
       " array([[ True,  True,  True,  True,  True,  True,  True,  True,  True],\n",
       "        [ True,  True,  True, False,  True,  True,  True, False, False],\n",
       "        [ True, False,  True,  True,  True,  True,  True,  True,  True],\n",
       "        [ True,  True,  True, False,  True, False,  True, False,  True],\n",
       "        [ True, False, False,  True,  True,  True,  True,  True, False]]),\n",
       " array([[ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True],\n",
       "        [False, False,  True, False, False, False,  True, False,  True,\n",
       "         False],\n",
       "        [False,  True,  True,  True, False, False,  True,  True, False,\n",
       "          True],\n",
       "        [ True, False,  True,  True,  True, False,  True,  True,  True,\n",
       "         False],\n",
       "        [ True,  True, False,  True,  True,  True, False, False,  True,\n",
       "          True]]),\n",
       " array([[ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True],\n",
       "        [False, False, False, False, False,  True, False, False,  True,\n",
       "          True,  True, False,  True,  True,  True],\n",
       "        [ True,  True,  True, False,  True,  True,  True, False,  True,\n",
       "          True,  True, False,  True,  True,  True],\n",
       "        [ True,  True,  True, False,  True,  True,  True, False,  True,\n",
       "          True,  True, False,  True,  True,  True],\n",
       "        [ True,  True,  True, False,  True,  True,  True, False,  True,\n",
       "          True,  True,  True,  True,  True,  True]]),\n",
       " array([[ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         False,  True, False,  True,  True, False],\n",
       "        [False, False, False, False, False,  True,  True, False, False,\n",
       "         False,  True, False,  True,  True,  True],\n",
       "        [ True,  True,  True, False,  True,  True,  True, False, False,\n",
       "          True,  True, False,  True,  True,  True],\n",
       "        [ True,  True, False, False,  True,  True,  True, False,  True,\n",
       "         False,  True, False,  True, False,  True],\n",
       "        [ True,  True,  True, False,  True,  True,  True, False,  True,\n",
       "          True,  True, False,  True,  True,  True]]),\n",
       " array([[ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True],\n",
       "        [ True, False,  True, False, False,  True,  True, False, False,\n",
       "          True],\n",
       "        [False,  True,  True, False, False, False,  True,  True, False,\n",
       "          True],\n",
       "        [ True, False, False, False, False, False, False, False,  True,\n",
       "         False],\n",
       "        [ True,  True, False,  True,  True,  True, False,  True,  True,\n",
       "          True]]),\n",
       " array([[ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True],\n",
       "        [False,  True,  True,  True, False, False,  True, False,  True,\n",
       "          True,  True, False,  True,  True,  True],\n",
       "        [ True,  True,  True, False,  True,  True,  True, False,  True,\n",
       "          True,  True, False,  True,  True, False],\n",
       "        [ True,  True,  True, False,  True,  True,  True, False,  True,\n",
       "          True,  True, False,  True,  True,  True],\n",
       "        [ True,  True,  True, False,  True,  True,  True, False,  True,\n",
       "          True,  True, False,  True,  True,  True]]),\n",
       " array([[ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True],\n",
       "        [False,  True,  True, False,  True,  True,  True, False,  True,\n",
       "          True],\n",
       "        [False,  True,  True,  True, False,  True,  True,  True, False,\n",
       "          True],\n",
       "        [ True, False,  True,  True,  True, False,  True,  True,  True,\n",
       "         False],\n",
       "        [ True,  True, False,  True,  True,  True, False,  True,  True,\n",
       "          True]]),\n",
       " array([[ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True],\n",
       "        [False,  True,  True, False,  True,  True,  True, False,  True,\n",
       "          True,  True, False,  True,  True,  True],\n",
       "        [ True,  True,  True, False,  True,  True,  True, False, False,\n",
       "          True,  True, False,  True,  True,  True],\n",
       "        [ True,  True,  True, False,  True,  True,  True, False,  True,\n",
       "          True,  True, False,  True,  True,  True],\n",
       "        [ True,  True,  True, False,  True,  True,  True, False,  True,\n",
       "          True,  True, False,  True,  True,  True]]),\n",
       " array([[ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True],\n",
       "        [False, False,  True, False,  True,  True,  True, False,  True,\n",
       "          True,  True, False,  True,  True,  True],\n",
       "        [ True,  True,  True, False,  True,  True,  True, False,  True,\n",
       "          True,  True, False,  True,  True,  True],\n",
       "        [False,  True,  True, False,  True,  True,  True, False,  True,\n",
       "          True,  True, False,  True,  True,  True],\n",
       "        [ True,  True,  True, False,  True,  True,  True, False,  True,\n",
       "          True,  True, False,  True,  True,  True]]),\n",
       " array([[False,  True,  True,  True,  True,  True,  True,  True,  True],\n",
       "        [ True,  True, False, False, False,  True, False, False,  True],\n",
       "        [False, False,  True,  True,  True, False,  True,  True,  True],\n",
       "        [ True,  True,  True, False,  True,  True,  True, False,  True],\n",
       "        [ True, False,  True,  True,  True, False,  True,  True,  True]]),\n",
       " array([[ True,  True,  True,  True,  True,  True,  True,  True,  True],\n",
       "        [False,  True,  True, False, False,  True,  True, False,  True],\n",
       "        [ True, False,  True,  True,  True, False, False,  True,  True],\n",
       "        [ True,  True,  True, False,  True,  True,  True, False,  True],\n",
       "        [ True, False,  True,  True,  True, False,  True,  True,  True]]),\n",
       " array([[ True, False,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True, False,  True],\n",
       "        [False,  True,  True, False, False, False, False,  True,  True,\n",
       "         False, False, False, False, False, False],\n",
       "        [ True,  True,  True,  True, False,  True,  True, False,  True,\n",
       "          True, False, False,  True,  True,  True],\n",
       "        [ True,  True,  True, False,  True,  True,  True, False,  True,\n",
       "          True,  True, False,  True,  True,  True],\n",
       "        [ True,  True,  True, False,  True,  True,  True, False,  True,\n",
       "          True,  True, False,  True,  True,  True]]),\n",
       " array([[ True,  True,  True,  True, False,  True,  True, False,  True],\n",
       "        [ True, False, False, False, False,  True, False, False, False],\n",
       "        [ True, False, False,  True, False, False,  True,  True,  True],\n",
       "        [False,  True,  True, False, False, False, False, False,  True],\n",
       "        [ True,  True, False, False, False, False,  True, False, False]]),\n",
       " array([[ True,  True,  True,  True, False,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True, False],\n",
       "        [False,  True,  True, False, False,  True,  True, False, False,\n",
       "         False, False, False,  True,  True,  True],\n",
       "        [ True, False, False,  True, False,  True,  True, False, False,\n",
       "         False, False, False,  True,  True,  True],\n",
       "        [False,  True,  True, False, False,  True,  True,  True, False,\n",
       "         False, False, False, False, False,  True],\n",
       "        [False, False,  True,  True,  True,  True,  True, False, False,\n",
       "          True, False, False, False,  True, False]]),\n",
       " array([[ True,  True,  True,  True,  True,  True,  True,  True,  True],\n",
       "        [ True, False,  True, False,  True,  True,  True, False,  True],\n",
       "        [ True, False, False, False, False, False,  True,  True,  True],\n",
       "        [ True,  True,  True,  True,  True,  True,  True, False,  True],\n",
       "        [ True, False,  True,  True,  True, False,  True,  True, False]]),\n",
       " array([[ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         False,  True,  True,  True,  True,  True],\n",
       "        [ True,  True,  True, False,  True,  True,  True, False,  True,\n",
       "          True,  True, False,  True,  True,  True],\n",
       "        [ True,  True,  True, False,  True,  True,  True, False,  True,\n",
       "          True, False, False,  True,  True,  True],\n",
       "        [ True,  True,  True, False,  True,  True,  True, False,  True,\n",
       "          True,  True, False,  True,  True,  True],\n",
       "        [False,  True,  True, False,  True,  True,  True, False, False,\n",
       "         False,  True, False, False,  True, False]])]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_block_num(context : list[int]) -> np.array:\n",
    "    \"\"\"\n",
    "    Define blocks of trials where contexts are alternated by finding where the\n",
    "    difference between adjacent context values is non-zero.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    context : list[int]\n",
    "        Latent contexts (1 or 2) for each stimulus in the trial.     \n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    np.array\n",
    "        Array of block numbers for each stimulus.\n",
    "    \"\"\"\n",
    "    transitions = np.where(np.abs(np.diff(context)) > 0)[0] + 1\n",
    "    block_idx = np.array([[0, *transitions], [*transitions, len(context)]])\n",
    "    block_nums = np.full(len(context), np.nan)\n",
    "    for i in range(block_idx.shape[1]):\n",
    "        block_nums[block_idx[0, i] : block_idx[1, i]] = i \n",
    "    return block_nums\n",
    "\n",
    "def get_instance_num(stim : np.array, block : np.array) -> np.array:\n",
    "    \"\"\"\n",
    "    Get the instance number for the image in each trial block.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    stim : np.array\n",
    "        Stimulus identities for each trial.\n",
    "    block : np.array\n",
    "        Array of block numbers for each stimulus.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    np.array\n",
    "        Array of instance numbers for each stimulus image. \n",
    "    \"\"\"\n",
    "    instance_nums = np.full(len(stim), np.nan)\n",
    "    for block_num in np.unique(block):\n",
    "        instance_dict = {}\n",
    "        block_idx = np.where(block == block_num)[0]\n",
    "        for idx in block_idx:\n",
    "            if stim[idx] not in instance_dict:\n",
    "                # Reset count for new stimulus\n",
    "                instance_dict[stim[idx]] = 1\n",
    "            else:\n",
    "                instance_dict[stim[idx]] += 1\n",
    "            instance_nums[idx] = instance_dict[stim[idx]]\n",
    "    return instance_nums\n",
    "\n",
    "def get_session_accuracy(\n",
    "    beh_data : pd.DataFrame,\n",
    "    task_data : pd.DataFrame\n",
    ") -> list[np.array]:\n",
    "    \"\"\"\n",
    "    Method for computing session-level accuracy on inference trials (trials in \n",
    "    which given stimulus is encountered for the first time after a context \n",
    "    switch).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    beh_data : pd.DataFrame\n",
    "        Behavioral data for all sessions.\n",
    "    task_data : pd.DataFrame\n",
    "        Task information for each session.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    list[np.array]\n",
    "        Returns list of arrays of binary values to represent correct vs. \n",
    "        incorrect answer. Each array has 5 rows (last trial from previous block\n",
    "        + 4 stimuli types) and [# blocks - 1] columns (since the first block is\n",
    "        excluded).\n",
    "    \"\"\"\n",
    "    prop_correct = []\n",
    "    for i in range(len(task_data)):\n",
    "        # Get block number\n",
    "        context = task_data[\"context\"].iloc[i]\n",
    "        block_nums = get_block_num(context)\n",
    "        gt = task_data[\"response_sequence\"].iloc[i]\n",
    "        stim_seq = task_data[\"stim_sequence\"].iloc[i]\n",
    "\n",
    "        # Find correct answers\n",
    "        events_code = np.array(beh_data[\"events\"].iloc[i])[:, 1]\n",
    "        response = np.where(np.isin(events_code, [31, 36]), events_code, np.nan)\n",
    "        response[response == 36] = 0\n",
    "        response[response == 31] = 1\n",
    "        response = response[~np.isnan(response)]\n",
    "        is_correct = (response == gt)\n",
    "\n",
    "        # Get instance number for image in each block\n",
    "        instance_nums = get_instance_num(np.array(stim_seq), block_nums)\n",
    "        is_correct_first = is_correct[instance_nums == 1]\n",
    "        first_instance_idx = np.where(instance_nums == 1)[0]\n",
    "        block_first_instance = block_nums[first_instance_idx]\n",
    "\n",
    "        # Get accuracy of all first instances; pad with NaN if lengths mismatched\n",
    "        idx = [\n",
    "            np.where(block_first_instance == block)[0]\n",
    "            for block in np.unique(block_first_instance)\n",
    "        ]\n",
    "        temp = [is_correct_first[i] for i in idx]\n",
    "        max_len = max(len(instances) for instances in temp)\n",
    "        temp = [\n",
    "            np.pad(instances, (0, max_len - len(instances)), constant_values=np.nan)\n",
    "            for instances in temp\n",
    "        ]\n",
    "        is_correct_first = np.concatenate(temp)\n",
    "\n",
    "        # Reshape to stack accuracy across blocks\n",
    "        is_correct_first = is_correct_first.reshape(\n",
    "            len(np.unique(stim_seq)), int(np.max(block_nums).T) + 1\n",
    "        )\n",
    "        \n",
    "        # Append last trial from previous block for each stimulus\n",
    "        last_trials_idx = [\n",
    "            np.where(block_nums == block)[0][-1]\n",
    "            for block in np.unique(block_nums)\n",
    "        ]\n",
    "        is_correct_last = is_correct[last_trials_idx]\n",
    "\n",
    "        # Exclude first block\n",
    "        prop_correct.append(np.vstack([is_correct_last, is_correct_first])[:, 1:])\n",
    "    return prop_correct\n",
    "\n",
    "prop_correct = get_session_accuracy(beh_data, task_data)\n",
    "prop_correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'baseline': array([0.03125, 0.03125, 0.03125, 0.03125, 0.1875 , 0.03125, 0.03125,\n",
       "        0.1875 , 0.03125, 0.1875 , 0.1875 , 0.03125, 0.     , 0.     ,\n",
       "        0.1875 , 0.03125, 0.03125, 0.1875 , 0.8125 , 0.03125, 0.     ,\n",
       "        0.1875 , 0.03125, 0.03125, 0.03125, 0.03125, 0.1875 , 0.03125,\n",
       "        0.1875 , 0.1875 , 0.03125, 0.03125, 0.03125, 0.5    , 0.     ,\n",
       "        0.03125]),\n",
       " 'inference': array([0.1875 , 0.1875 , 0.     , 0.     , 0.03125, 0.5    , 0.     ,\n",
       "        0.     , 0.     , 0.1875 , 0.5    , 0.5    , 0.     , 0.     ,\n",
       "        0.     , 0.03125, 0.1875 , 0.03125, 0.8125 , 0.03125, 0.03125,\n",
       "        0.03125, 0.03125, 0.1875 , 0.1875 , 0.     , 0.03125, 0.     ,\n",
       "        0.     , 0.03125, 0.     , 0.     , 0.5    , 0.03125, 0.03125,\n",
       "        0.     ]),\n",
       " 'inf_perf': array([0.6, 0.6, 1. , 1. , 0.8, 0.4, 1. , 1. , 1. , 0.6, 0.4, 0.4, 1. ,\n",
       "        1. , 1. , 0.8, 0.6, 0.8, 0.2, 0.8, 0.8, 0.8, 0.8, 0.6, 0.6, 1. ,\n",
       "        0.8, 1. , 1. , 0.8, 1. , 1. , 0.4, 0.8, 0.8, 1. ])}"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def test_inference_trials(\n",
    "    beh_data : pd.DataFrame,\n",
    "    task_data : pd.DataFrame\n",
    ") -> dict:\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    beh_data : pd.DataFrame\n",
    "    task_data : pd.DataFrame\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        Dictionary with statistical significance for baseline/inference trials\n",
    "        and proportion of correct responses on inference trials.\n",
    "    \"\"\"\n",
    "    # Get session-level accuracy for each trial\n",
    "    prop_correct = get_session_accuracy(beh_data, task_data)\n",
    "\n",
    "    baseline = np.full(len(prop_correct), np.nan)\n",
    "    inference = np.full(len(prop_correct), np.nan)\n",
    "    inf_perf = np.full(len(prop_correct), np.nan)\n",
    "\n",
    "    for i, X in enumerate(prop_correct):\n",
    "        # First inference trial in third column\n",
    "        inf_trials = X[:, 2]\n",
    "        valid_trials = np.sum(~np.isnan(inf_trials))\n",
    "\n",
    "        # Check significance of behavior against chance (0.5)\n",
    "        baseline[i] = 1 - binom.cdf(np.sum(X[:, 0]), len(X[:, 0]), 0.5)\n",
    "        inference[i] = 1 - binom.cdf(np.nansum(inf_trials), valid_trials, 0.5)\n",
    "        inf_perf[i] = np.nansum(inf_trials) / valid_trials\n",
    "\n",
    "    # TO DO: why are indices selected this way?\n",
    "    return {\"baseline\" : baseline, \"inference\": inference, \"inf_perf\" : inf_perf}\n",
    "\n",
    "test_inference_trials(beh_data, task_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'absent': ['P61CS_1',\n",
       "  'P62CS_1',\n",
       "  'P63CS_1',\n",
       "  'P67CS_1',\n",
       "  'P71CS_1',\n",
       "  'P76CS_1',\n",
       "  'P78CS_1',\n",
       "  'TWH165_1'],\n",
       " 'present': ['P62CS_4',\n",
       "  'P63CS_3',\n",
       "  'P67CS_4',\n",
       "  'P71CS_2',\n",
       "  'P74CS_1',\n",
       "  'P79CS_1',\n",
       "  'P79CS_3',\n",
       "  'TWH162_1',\n",
       "  'TWH165_2'],\n",
       " 'absent_idx': [0,\n",
       "  1,\n",
       "  2,\n",
       "  3,\n",
       "  4,\n",
       "  5,\n",
       "  6,\n",
       "  7,\n",
       "  8,\n",
       "  9,\n",
       "  10,\n",
       "  11,\n",
       "  12,\n",
       "  13,\n",
       "  14,\n",
       "  15,\n",
       "  16,\n",
       "  17,\n",
       "  18,\n",
       "  19,\n",
       "  20,\n",
       "  21,\n",
       "  22,\n",
       "  23,\n",
       "  24,\n",
       "  25,\n",
       "  26,\n",
       "  27,\n",
       "  28,\n",
       "  29,\n",
       "  30,\n",
       "  31,\n",
       "  32,\n",
       "  33,\n",
       "  34,\n",
       "  35,\n",
       "  36,\n",
       "  37,\n",
       "  38,\n",
       "  39,\n",
       "  40,\n",
       "  41,\n",
       "  42,\n",
       "  43,\n",
       "  44,\n",
       "  45,\n",
       "  46,\n",
       "  47,\n",
       "  48,\n",
       "  49,\n",
       "  50,\n",
       "  51,\n",
       "  52,\n",
       "  53,\n",
       "  54,\n",
       "  55,\n",
       "  56,\n",
       "  57,\n",
       "  58,\n",
       "  59,\n",
       "  60,\n",
       "  61,\n",
       "  62,\n",
       "  63,\n",
       "  64,\n",
       "  65,\n",
       "  66,\n",
       "  67,\n",
       "  68,\n",
       "  69,\n",
       "  70,\n",
       "  71,\n",
       "  72,\n",
       "  73,\n",
       "  74,\n",
       "  75,\n",
       "  76,\n",
       "  77,\n",
       "  78,\n",
       "  79,\n",
       "  80,\n",
       "  81,\n",
       "  82,\n",
       "  83,\n",
       "  84,\n",
       "  85,\n",
       "  86,\n",
       "  87,\n",
       "  88,\n",
       "  89,\n",
       "  90,\n",
       "  91,\n",
       "  92,\n",
       "  93,\n",
       "  94,\n",
       "  95,\n",
       "  96,\n",
       "  97,\n",
       "  98,\n",
       "  99,\n",
       "  100,\n",
       "  101,\n",
       "  102,\n",
       "  103,\n",
       "  104,\n",
       "  105,\n",
       "  106,\n",
       "  107,\n",
       "  108,\n",
       "  269,\n",
       "  270,\n",
       "  271,\n",
       "  272,\n",
       "  273,\n",
       "  274,\n",
       "  275,\n",
       "  276,\n",
       "  277,\n",
       "  278,\n",
       "  279,\n",
       "  280,\n",
       "  281,\n",
       "  282,\n",
       "  283,\n",
       "  284,\n",
       "  285,\n",
       "  286,\n",
       "  287,\n",
       "  288,\n",
       "  289,\n",
       "  290,\n",
       "  291,\n",
       "  292,\n",
       "  293,\n",
       "  294,\n",
       "  295,\n",
       "  296,\n",
       "  297,\n",
       "  298,\n",
       "  299,\n",
       "  300,\n",
       "  301,\n",
       "  302,\n",
       "  303,\n",
       "  304,\n",
       "  305,\n",
       "  306,\n",
       "  307,\n",
       "  308,\n",
       "  309,\n",
       "  310,\n",
       "  311,\n",
       "  312,\n",
       "  313,\n",
       "  314,\n",
       "  315,\n",
       "  316,\n",
       "  317,\n",
       "  318,\n",
       "  319,\n",
       "  320,\n",
       "  321,\n",
       "  322,\n",
       "  323,\n",
       "  324,\n",
       "  325,\n",
       "  326,\n",
       "  327,\n",
       "  328,\n",
       "  329,\n",
       "  330,\n",
       "  331,\n",
       "  332,\n",
       "  333,\n",
       "  334,\n",
       "  335,\n",
       "  336,\n",
       "  337,\n",
       "  338,\n",
       "  339,\n",
       "  340,\n",
       "  341,\n",
       "  342,\n",
       "  343,\n",
       "  344,\n",
       "  345,\n",
       "  346,\n",
       "  347,\n",
       "  348,\n",
       "  349,\n",
       "  350,\n",
       "  351,\n",
       "  352,\n",
       "  353,\n",
       "  354,\n",
       "  355,\n",
       "  356,\n",
       "  357,\n",
       "  358,\n",
       "  359,\n",
       "  360,\n",
       "  361,\n",
       "  362,\n",
       "  363,\n",
       "  364,\n",
       "  365,\n",
       "  702,\n",
       "  703,\n",
       "  704,\n",
       "  705,\n",
       "  706,\n",
       "  707,\n",
       "  708,\n",
       "  709,\n",
       "  710,\n",
       "  711,\n",
       "  712,\n",
       "  713,\n",
       "  714,\n",
       "  715,\n",
       "  716,\n",
       "  717,\n",
       "  718,\n",
       "  719,\n",
       "  720,\n",
       "  721,\n",
       "  722,\n",
       "  723,\n",
       "  724,\n",
       "  725,\n",
       "  726,\n",
       "  727,\n",
       "  728,\n",
       "  729,\n",
       "  730,\n",
       "  731,\n",
       "  732,\n",
       "  733,\n",
       "  734,\n",
       "  735,\n",
       "  736,\n",
       "  737,\n",
       "  738,\n",
       "  739,\n",
       "  740,\n",
       "  741,\n",
       "  742,\n",
       "  743,\n",
       "  744,\n",
       "  745,\n",
       "  746,\n",
       "  747,\n",
       "  748,\n",
       "  749,\n",
       "  750,\n",
       "  751,\n",
       "  752,\n",
       "  753,\n",
       "  754,\n",
       "  755,\n",
       "  756,\n",
       "  757,\n",
       "  758,\n",
       "  759,\n",
       "  760,\n",
       "  761,\n",
       "  762,\n",
       "  763,\n",
       "  764,\n",
       "  765,\n",
       "  766,\n",
       "  767,\n",
       "  768,\n",
       "  769,\n",
       "  770,\n",
       "  771,\n",
       "  772,\n",
       "  773,\n",
       "  774,\n",
       "  775,\n",
       "  776,\n",
       "  777,\n",
       "  778,\n",
       "  779,\n",
       "  780,\n",
       "  781,\n",
       "  782,\n",
       "  783,\n",
       "  784,\n",
       "  785,\n",
       "  786,\n",
       "  787,\n",
       "  788,\n",
       "  789,\n",
       "  790,\n",
       "  791,\n",
       "  792,\n",
       "  793,\n",
       "  794,\n",
       "  795,\n",
       "  796,\n",
       "  797,\n",
       "  798,\n",
       "  799,\n",
       "  800,\n",
       "  801,\n",
       "  802,\n",
       "  803,\n",
       "  804,\n",
       "  805,\n",
       "  806,\n",
       "  807,\n",
       "  808,\n",
       "  809,\n",
       "  810,\n",
       "  811,\n",
       "  812,\n",
       "  813,\n",
       "  814,\n",
       "  815,\n",
       "  816,\n",
       "  817,\n",
       "  818,\n",
       "  819,\n",
       "  820,\n",
       "  821,\n",
       "  822,\n",
       "  823,\n",
       "  824,\n",
       "  825,\n",
       "  1211,\n",
       "  1212,\n",
       "  1213,\n",
       "  1214,\n",
       "  1215,\n",
       "  1216,\n",
       "  1217,\n",
       "  1218,\n",
       "  1219,\n",
       "  1220,\n",
       "  1221,\n",
       "  1222,\n",
       "  1223,\n",
       "  1224,\n",
       "  1225,\n",
       "  1226,\n",
       "  1227,\n",
       "  1228,\n",
       "  1229,\n",
       "  1230,\n",
       "  1231,\n",
       "  1232,\n",
       "  1233,\n",
       "  1234,\n",
       "  1235,\n",
       "  1236,\n",
       "  1237,\n",
       "  1238,\n",
       "  1239,\n",
       "  1240,\n",
       "  1241,\n",
       "  1242,\n",
       "  1243,\n",
       "  1244,\n",
       "  1245,\n",
       "  1246,\n",
       "  1247,\n",
       "  1248,\n",
       "  1249,\n",
       "  1250,\n",
       "  1251,\n",
       "  1252,\n",
       "  1253,\n",
       "  1254,\n",
       "  1255,\n",
       "  1256,\n",
       "  1257,\n",
       "  1258,\n",
       "  1259,\n",
       "  1260,\n",
       "  1261,\n",
       "  1262,\n",
       "  1263,\n",
       "  1264,\n",
       "  1265,\n",
       "  1266,\n",
       "  1267,\n",
       "  1268,\n",
       "  1269,\n",
       "  1270,\n",
       "  1271,\n",
       "  1272,\n",
       "  1273,\n",
       "  1274,\n",
       "  1275,\n",
       "  1698,\n",
       "  1699,\n",
       "  1700,\n",
       "  1701,\n",
       "  1702,\n",
       "  1703,\n",
       "  1704,\n",
       "  1705,\n",
       "  1706,\n",
       "  1707,\n",
       "  1708,\n",
       "  1709,\n",
       "  1710,\n",
       "  1711,\n",
       "  1712,\n",
       "  1713,\n",
       "  1714,\n",
       "  1715,\n",
       "  1716,\n",
       "  1717,\n",
       "  1718,\n",
       "  1719,\n",
       "  1720,\n",
       "  1721,\n",
       "  1722,\n",
       "  1723,\n",
       "  1724,\n",
       "  1725,\n",
       "  1726,\n",
       "  1727,\n",
       "  1728,\n",
       "  1729,\n",
       "  1730,\n",
       "  1731,\n",
       "  1732,\n",
       "  1733,\n",
       "  1734,\n",
       "  1735,\n",
       "  1736,\n",
       "  1737,\n",
       "  1738,\n",
       "  1739,\n",
       "  1740,\n",
       "  1741,\n",
       "  1742,\n",
       "  1743,\n",
       "  1744,\n",
       "  1745,\n",
       "  1746,\n",
       "  1747,\n",
       "  1748,\n",
       "  1749,\n",
       "  1750,\n",
       "  1751,\n",
       "  1752,\n",
       "  1753,\n",
       "  1754,\n",
       "  1755,\n",
       "  1756,\n",
       "  1757,\n",
       "  1758,\n",
       "  1759,\n",
       "  1760,\n",
       "  1761,\n",
       "  1762,\n",
       "  1763,\n",
       "  1764,\n",
       "  1765,\n",
       "  1766,\n",
       "  1767,\n",
       "  1768,\n",
       "  1769,\n",
       "  1770,\n",
       "  1771,\n",
       "  1772,\n",
       "  1773,\n",
       "  1774,\n",
       "  1775,\n",
       "  1776,\n",
       "  1777,\n",
       "  1778,\n",
       "  1779,\n",
       "  1780,\n",
       "  1781,\n",
       "  1782,\n",
       "  1783,\n",
       "  1784,\n",
       "  1785,\n",
       "  1786,\n",
       "  1787,\n",
       "  1788,\n",
       "  1789,\n",
       "  1790,\n",
       "  1791,\n",
       "  1792,\n",
       "  1793,\n",
       "  1794,\n",
       "  1795,\n",
       "  1796,\n",
       "  1797,\n",
       "  1798,\n",
       "  1799,\n",
       "  1800,\n",
       "  1801,\n",
       "  1802,\n",
       "  1803,\n",
       "  1804,\n",
       "  1805,\n",
       "  1806,\n",
       "  1807,\n",
       "  1808,\n",
       "  1809,\n",
       "  1810,\n",
       "  1811,\n",
       "  1812,\n",
       "  1813,\n",
       "  1814,\n",
       "  1815,\n",
       "  1816,\n",
       "  1817,\n",
       "  1818,\n",
       "  1819,\n",
       "  1820,\n",
       "  1821,\n",
       "  1822,\n",
       "  1823,\n",
       "  1824,\n",
       "  1825,\n",
       "  1826,\n",
       "  1827,\n",
       "  1828,\n",
       "  1829,\n",
       "  1830,\n",
       "  1831,\n",
       "  1832,\n",
       "  1833,\n",
       "  1834,\n",
       "  1835,\n",
       "  1836,\n",
       "  1837,\n",
       "  1838,\n",
       "  1839,\n",
       "  1840,\n",
       "  1841,\n",
       "  1842,\n",
       "  1843,\n",
       "  1844,\n",
       "  1845,\n",
       "  1846,\n",
       "  1847,\n",
       "  1848,\n",
       "  1849,\n",
       "  1850,\n",
       "  1851,\n",
       "  1852,\n",
       "  1853,\n",
       "  1854,\n",
       "  1855,\n",
       "  1856,\n",
       "  1857,\n",
       "  1858,\n",
       "  1859,\n",
       "  1860,\n",
       "  1861,\n",
       "  1862,\n",
       "  1863,\n",
       "  1864,\n",
       "  1865,\n",
       "  1866,\n",
       "  1867,\n",
       "  2594,\n",
       "  2595,\n",
       "  2596,\n",
       "  2597,\n",
       "  2598,\n",
       "  2599,\n",
       "  2600,\n",
       "  2601,\n",
       "  2602,\n",
       "  2603,\n",
       "  2604,\n",
       "  2605,\n",
       "  2606,\n",
       "  2607,\n",
       "  2608,\n",
       "  2609,\n",
       "  2610,\n",
       "  2611,\n",
       "  2612,\n",
       "  2613,\n",
       "  2614,\n",
       "  2615,\n",
       "  2616,\n",
       "  2617],\n",
       " 'present_idx': [230,\n",
       "  231,\n",
       "  232,\n",
       "  233,\n",
       "  234,\n",
       "  235,\n",
       "  236,\n",
       "  237,\n",
       "  238,\n",
       "  239,\n",
       "  240,\n",
       "  241,\n",
       "  242,\n",
       "  243,\n",
       "  244,\n",
       "  245,\n",
       "  246,\n",
       "  247,\n",
       "  248,\n",
       "  249,\n",
       "  250,\n",
       "  251,\n",
       "  252,\n",
       "  253,\n",
       "  254,\n",
       "  255,\n",
       "  256,\n",
       "  257,\n",
       "  258,\n",
       "  259,\n",
       "  260,\n",
       "  261,\n",
       "  262,\n",
       "  263,\n",
       "  264,\n",
       "  265,\n",
       "  266,\n",
       "  267,\n",
       "  268,\n",
       "  444,\n",
       "  445,\n",
       "  446,\n",
       "  447,\n",
       "  448,\n",
       "  449,\n",
       "  450,\n",
       "  451,\n",
       "  452,\n",
       "  453,\n",
       "  454,\n",
       "  455,\n",
       "  456,\n",
       "  457,\n",
       "  458,\n",
       "  459,\n",
       "  460,\n",
       "  461,\n",
       "  462,\n",
       "  463,\n",
       "  464,\n",
       "  465,\n",
       "  466,\n",
       "  467,\n",
       "  468,\n",
       "  469,\n",
       "  470,\n",
       "  471,\n",
       "  472,\n",
       "  473,\n",
       "  474,\n",
       "  475,\n",
       "  476,\n",
       "  477,\n",
       "  478,\n",
       "  479,\n",
       "  480,\n",
       "  481,\n",
       "  482,\n",
       "  483,\n",
       "  484,\n",
       "  485,\n",
       "  486,\n",
       "  487,\n",
       "  488,\n",
       "  489,\n",
       "  490,\n",
       "  491,\n",
       "  492,\n",
       "  493,\n",
       "  494,\n",
       "  495,\n",
       "  496,\n",
       "  497,\n",
       "  498,\n",
       "  499,\n",
       "  500,\n",
       "  501,\n",
       "  502,\n",
       "  503,\n",
       "  504,\n",
       "  505,\n",
       "  506,\n",
       "  507,\n",
       "  508,\n",
       "  509,\n",
       "  510,\n",
       "  511,\n",
       "  512,\n",
       "  513,\n",
       "  514,\n",
       "  515,\n",
       "  516,\n",
       "  517,\n",
       "  518,\n",
       "  519,\n",
       "  520,\n",
       "  521,\n",
       "  522,\n",
       "  523,\n",
       "  524,\n",
       "  525,\n",
       "  526,\n",
       "  527,\n",
       "  528,\n",
       "  529,\n",
       "  530,\n",
       "  531,\n",
       "  532,\n",
       "  533,\n",
       "  534,\n",
       "  535,\n",
       "  536,\n",
       "  1069,\n",
       "  1070,\n",
       "  1071,\n",
       "  1072,\n",
       "  1073,\n",
       "  1074,\n",
       "  1075,\n",
       "  1076,\n",
       "  1077,\n",
       "  1078,\n",
       "  1079,\n",
       "  1080,\n",
       "  1081,\n",
       "  1082,\n",
       "  1083,\n",
       "  1084,\n",
       "  1085,\n",
       "  1086,\n",
       "  1087,\n",
       "  1088,\n",
       "  1089,\n",
       "  1090,\n",
       "  1091,\n",
       "  1092,\n",
       "  1093,\n",
       "  1094,\n",
       "  1095,\n",
       "  1096,\n",
       "  1097,\n",
       "  1098,\n",
       "  1099,\n",
       "  1100,\n",
       "  1101,\n",
       "  1102,\n",
       "  1103,\n",
       "  1104,\n",
       "  1105,\n",
       "  1106,\n",
       "  1107,\n",
       "  1108,\n",
       "  1109,\n",
       "  1110,\n",
       "  1111,\n",
       "  1112,\n",
       "  1113,\n",
       "  1114,\n",
       "  1115,\n",
       "  1116,\n",
       "  1117,\n",
       "  1118,\n",
       "  1119,\n",
       "  1120,\n",
       "  1121,\n",
       "  1122,\n",
       "  1123,\n",
       "  1124,\n",
       "  1125,\n",
       "  1126,\n",
       "  1127,\n",
       "  1128,\n",
       "  1129,\n",
       "  1130,\n",
       "  1131,\n",
       "  1132,\n",
       "  1133,\n",
       "  1134,\n",
       "  1135,\n",
       "  1136,\n",
       "  1137,\n",
       "  1138,\n",
       "  1139,\n",
       "  1140,\n",
       "  1141,\n",
       "  1142,\n",
       "  1143,\n",
       "  1144,\n",
       "  1145,\n",
       "  1146,\n",
       "  1147,\n",
       "  1148,\n",
       "  1149,\n",
       "  1150,\n",
       "  1151,\n",
       "  1152,\n",
       "  1153,\n",
       "  1154,\n",
       "  1155,\n",
       "  1156,\n",
       "  1157,\n",
       "  1158,\n",
       "  1159,\n",
       "  1160,\n",
       "  1161,\n",
       "  1162,\n",
       "  1163,\n",
       "  1164,\n",
       "  1165,\n",
       "  1166,\n",
       "  1167,\n",
       "  1168,\n",
       "  1169,\n",
       "  1170,\n",
       "  1171,\n",
       "  1172,\n",
       "  1173,\n",
       "  1174,\n",
       "  1175,\n",
       "  1176,\n",
       "  1177,\n",
       "  1178,\n",
       "  1179,\n",
       "  1180,\n",
       "  1181,\n",
       "  1182,\n",
       "  1183,\n",
       "  1184,\n",
       "  1185,\n",
       "  1186,\n",
       "  1187,\n",
       "  1276,\n",
       "  1277,\n",
       "  1278,\n",
       "  1279,\n",
       "  1280,\n",
       "  1281,\n",
       "  1282,\n",
       "  1283,\n",
       "  1284,\n",
       "  1285,\n",
       "  1286,\n",
       "  1287,\n",
       "  1288,\n",
       "  1289,\n",
       "  1290,\n",
       "  1291,\n",
       "  1292,\n",
       "  1293,\n",
       "  1294,\n",
       "  1295,\n",
       "  1296,\n",
       "  1297,\n",
       "  1298,\n",
       "  1299,\n",
       "  1300,\n",
       "  1301,\n",
       "  1302,\n",
       "  1303,\n",
       "  1304,\n",
       "  1305,\n",
       "  1306,\n",
       "  1307,\n",
       "  1308,\n",
       "  1309,\n",
       "  1310,\n",
       "  1311,\n",
       "  1312,\n",
       "  1313,\n",
       "  1314,\n",
       "  1315,\n",
       "  1316,\n",
       "  1317,\n",
       "  1318,\n",
       "  1319,\n",
       "  1320,\n",
       "  1321,\n",
       "  1322,\n",
       "  1323,\n",
       "  1324,\n",
       "  1325,\n",
       "  1326,\n",
       "  1327,\n",
       "  1328,\n",
       "  1329,\n",
       "  1330,\n",
       "  1331,\n",
       "  1332,\n",
       "  1333,\n",
       "  1334,\n",
       "  1335,\n",
       "  1336,\n",
       "  1337,\n",
       "  1338,\n",
       "  1339,\n",
       "  1340,\n",
       "  1652,\n",
       "  1653,\n",
       "  1654,\n",
       "  1655,\n",
       "  1656,\n",
       "  1657,\n",
       "  1658,\n",
       "  1659,\n",
       "  1660,\n",
       "  1661,\n",
       "  1662,\n",
       "  1663,\n",
       "  1664,\n",
       "  1665,\n",
       "  1666,\n",
       "  1667,\n",
       "  1668,\n",
       "  1669,\n",
       "  1670,\n",
       "  1671,\n",
       "  1672,\n",
       "  1673,\n",
       "  1674,\n",
       "  1933,\n",
       "  1934,\n",
       "  1935,\n",
       "  1936,\n",
       "  1937,\n",
       "  1938,\n",
       "  1939,\n",
       "  1940,\n",
       "  1941,\n",
       "  1942,\n",
       "  1943,\n",
       "  1944,\n",
       "  1945,\n",
       "  1946,\n",
       "  1947,\n",
       "  1948,\n",
       "  1949,\n",
       "  1950,\n",
       "  1951,\n",
       "  1952,\n",
       "  1953,\n",
       "  1954,\n",
       "  1955,\n",
       "  1956,\n",
       "  1957,\n",
       "  1958,\n",
       "  1959,\n",
       "  1960,\n",
       "  1961,\n",
       "  1962,\n",
       "  1963,\n",
       "  1964,\n",
       "  1965,\n",
       "  1966,\n",
       "  1967,\n",
       "  1968,\n",
       "  1969,\n",
       "  1970,\n",
       "  1971,\n",
       "  1972,\n",
       "  1973,\n",
       "  1974,\n",
       "  1975,\n",
       "  1976,\n",
       "  1977,\n",
       "  1978,\n",
       "  1979,\n",
       "  1980,\n",
       "  1981,\n",
       "  1982,\n",
       "  1983,\n",
       "  1984,\n",
       "  1985,\n",
       "  1986,\n",
       "  1987,\n",
       "  1988,\n",
       "  1989,\n",
       "  1990,\n",
       "  1991,\n",
       "  1992,\n",
       "  1993,\n",
       "  1994,\n",
       "  1995,\n",
       "  1996,\n",
       "  1997,\n",
       "  1998,\n",
       "  1999,\n",
       "  2000,\n",
       "  2001,\n",
       "  2002,\n",
       "  2003,\n",
       "  2004,\n",
       "  2005,\n",
       "  2006,\n",
       "  2007,\n",
       "  2008,\n",
       "  2009,\n",
       "  2010,\n",
       "  2011,\n",
       "  2012,\n",
       "  2013,\n",
       "  2014,\n",
       "  2015,\n",
       "  2016,\n",
       "  2017,\n",
       "  2018,\n",
       "  2019,\n",
       "  2020,\n",
       "  2021,\n",
       "  2022,\n",
       "  2023,\n",
       "  2024,\n",
       "  2025,\n",
       "  2026,\n",
       "  2027,\n",
       "  2028,\n",
       "  2029,\n",
       "  2030,\n",
       "  2031,\n",
       "  2032,\n",
       "  2033,\n",
       "  2034,\n",
       "  2035,\n",
       "  2036,\n",
       "  2037,\n",
       "  2038,\n",
       "  2039,\n",
       "  2040,\n",
       "  2041,\n",
       "  2042,\n",
       "  2043,\n",
       "  2044,\n",
       "  2045,\n",
       "  2046,\n",
       "  2047,\n",
       "  2048,\n",
       "  2049,\n",
       "  2050,\n",
       "  2051,\n",
       "  2052,\n",
       "  2053,\n",
       "  2054,\n",
       "  2055,\n",
       "  2056,\n",
       "  2057,\n",
       "  2058,\n",
       "  2059,\n",
       "  2060,\n",
       "  2061,\n",
       "  2062,\n",
       "  2063,\n",
       "  2064,\n",
       "  2065,\n",
       "  2066,\n",
       "  2067,\n",
       "  2068,\n",
       "  2069,\n",
       "  2070,\n",
       "  2071,\n",
       "  2072,\n",
       "  2073,\n",
       "  2074,\n",
       "  2075,\n",
       "  2076,\n",
       "  2077,\n",
       "  2078,\n",
       "  2079,\n",
       "  2080,\n",
       "  2081,\n",
       "  2082,\n",
       "  2083,\n",
       "  2084,\n",
       "  2085,\n",
       "  2086,\n",
       "  2087,\n",
       "  2088,\n",
       "  2089,\n",
       "  2090,\n",
       "  2091,\n",
       "  2092,\n",
       "  2093,\n",
       "  2094,\n",
       "  2095,\n",
       "  2096,\n",
       "  2097,\n",
       "  2098,\n",
       "  2099,\n",
       "  2100,\n",
       "  2101,\n",
       "  2102,\n",
       "  2103,\n",
       "  2104,\n",
       "  2105,\n",
       "  2106,\n",
       "  2107,\n",
       "  2108,\n",
       "  2109,\n",
       "  2110,\n",
       "  2111,\n",
       "  2112,\n",
       "  2113,\n",
       "  2114,\n",
       "  2115,\n",
       "  2116,\n",
       "  2117,\n",
       "  2118,\n",
       "  2119,\n",
       "  2120,\n",
       "  2121,\n",
       "  2122,\n",
       "  2123,\n",
       "  2124,\n",
       "  2125,\n",
       "  2126,\n",
       "  2127,\n",
       "  2128,\n",
       "  2129,\n",
       "  2130,\n",
       "  2131,\n",
       "  2132,\n",
       "  2133,\n",
       "  2134,\n",
       "  2135,\n",
       "  2136,\n",
       "  2137,\n",
       "  2138,\n",
       "  2139,\n",
       "  2140,\n",
       "  2141,\n",
       "  2351,\n",
       "  2352,\n",
       "  2353,\n",
       "  2354,\n",
       "  2355,\n",
       "  2356,\n",
       "  2357,\n",
       "  2358,\n",
       "  2359,\n",
       "  2360,\n",
       "  2361,\n",
       "  2362,\n",
       "  2363,\n",
       "  2364,\n",
       "  2365,\n",
       "  2366,\n",
       "  2367,\n",
       "  2368,\n",
       "  2369,\n",
       "  2370,\n",
       "  2371,\n",
       "  2372,\n",
       "  2373,\n",
       "  2374,\n",
       "  2375,\n",
       "  2376,\n",
       "  2377,\n",
       "  2378,\n",
       "  2379,\n",
       "  2380,\n",
       "  2381,\n",
       "  2382,\n",
       "  2383,\n",
       "  2384,\n",
       "  2385,\n",
       "  2386,\n",
       "  2387,\n",
       "  2388,\n",
       "  2389,\n",
       "  2390,\n",
       "  2391,\n",
       "  2392,\n",
       "  2393,\n",
       "  2394,\n",
       "  2395,\n",
       "  2396,\n",
       "  2397,\n",
       "  2398,\n",
       "  2399,\n",
       "  2400,\n",
       "  2401,\n",
       "  2402,\n",
       "  2403,\n",
       "  2404,\n",
       "  2405,\n",
       "  2406,\n",
       "  2407,\n",
       "  2408,\n",
       "  2409,\n",
       "  2410,\n",
       "  2411,\n",
       "  2412,\n",
       "  2413,\n",
       "  2414,\n",
       "  2415,\n",
       "  2416,\n",
       "  2417,\n",
       "  2418,\n",
       "  2419,\n",
       "  2420,\n",
       "  2421,\n",
       "  2422,\n",
       "  2423,\n",
       "  2424,\n",
       "  2425,\n",
       "  2426,\n",
       "  2427,\n",
       "  2428,\n",
       "  2429,\n",
       "  2430,\n",
       "  2431,\n",
       "  2432,\n",
       "  2433,\n",
       "  2434,\n",
       "  2435,\n",
       "  2436,\n",
       "  2437,\n",
       "  2438,\n",
       "  2439,\n",
       "  2440,\n",
       "  2441,\n",
       "  2442,\n",
       "  2443,\n",
       "  2444,\n",
       "  2445,\n",
       "  2446,\n",
       "  2447,\n",
       "  2448,\n",
       "  2449,\n",
       "  2450,\n",
       "  2451,\n",
       "  2452,\n",
       "  2453,\n",
       "  2454,\n",
       "  2455,\n",
       "  2456,\n",
       "  2457,\n",
       "  2458,\n",
       "  2459,\n",
       "  2460,\n",
       "  2461,\n",
       "  2462,\n",
       "  2463,\n",
       "  2464,\n",
       "  2465,\n",
       "  2466,\n",
       "  2467,\n",
       "  2468,\n",
       "  2469,\n",
       "  2470,\n",
       "  2471,\n",
       "  2472,\n",
       "  2473,\n",
       "  2474,\n",
       "  2475,\n",
       "  2476,\n",
       "  2477,\n",
       "  2478,\n",
       "  2479,\n",
       "  2480,\n",
       "  2481,\n",
       "  2482,\n",
       "  2483,\n",
       "  2484,\n",
       "  2485,\n",
       "  2486,\n",
       "  2487,\n",
       "  2488,\n",
       "  2489,\n",
       "  2490,\n",
       "  2491,\n",
       "  2492,\n",
       "  2493,\n",
       "  2494,\n",
       "  2495,\n",
       "  2496,\n",
       "  2497,\n",
       "  2498,\n",
       "  2499,\n",
       "  2500,\n",
       "  2501,\n",
       "  2502,\n",
       "  2503,\n",
       "  2504,\n",
       "  2505,\n",
       "  2506,\n",
       "  2507,\n",
       "  2508,\n",
       "  2509,\n",
       "  2510,\n",
       "  2511,\n",
       "  2618,\n",
       "  2619,\n",
       "  2620,\n",
       "  2621,\n",
       "  2622,\n",
       "  2623,\n",
       "  2624,\n",
       "  2625,\n",
       "  2626,\n",
       "  2627,\n",
       "  2628,\n",
       "  2629,\n",
       "  2630,\n",
       "  2631,\n",
       "  2632,\n",
       "  2633,\n",
       "  2634,\n",
       "  2635,\n",
       "  2636,\n",
       "  2637,\n",
       "  2638,\n",
       "  2639,\n",
       "  2640,\n",
       "  2641],\n",
       " 'sessions': ['P61CS_1',\n",
       "  'P62CS_1',\n",
       "  'P62CS_2',\n",
       "  'P62CS_3',\n",
       "  'P62CS_4',\n",
       "  'P63CS_1',\n",
       "  'P63CS_2',\n",
       "  'P63CS_3',\n",
       "  'P65CS_1',\n",
       "  'P65CS_2',\n",
       "  'P65CS_3',\n",
       "  'P67CS_1',\n",
       "  'P67CS_2',\n",
       "  'P67CS_3',\n",
       "  'P67CS_4',\n",
       "  'P70CS_1',\n",
       "  'P71CS_1',\n",
       "  'P71CS_2',\n",
       "  'P73CS_1',\n",
       "  'P73CS_2',\n",
       "  'P73CS_3',\n",
       "  'P74CS_1',\n",
       "  'P74CS_2',\n",
       "  'P76CS_1',\n",
       "  'P78CS_1',\n",
       "  'P78CS_2',\n",
       "  'P79CS_1',\n",
       "  'P79CS_2',\n",
       "  'P79CS_3',\n",
       "  'TWH162_1',\n",
       "  'TWH163_1',\n",
       "  'TWH163_2',\n",
       "  'TWH165_1',\n",
       "  'TWH165_2',\n",
       "  'TWH172_1',\n",
       "  'TWH172_2']}"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def split_sessions(\n",
    "    neu_data : pd.DataFrame,\n",
    "    beh_data : pd.DataFrame,\n",
    "    task_data : pd.DataFrame,\n",
    "    p : float = 0.05\n",
    "):\n",
    "    \"\"\"\n",
    "    Wrapper for computing significance of session-level inference behavior.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    neu_data : pd.DataFrame\n",
    "        DataFrame with each row corresponding to all trial data for a single \n",
    "        neuron.\n",
    "    beh_data : pd.DataFrame\n",
    "        Behavioral data for all sessions.\n",
    "    task_data : pd.DataFrame\n",
    "        Task information for each session.\n",
    "    p : float\n",
    "        p-value for statistical significance.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        Dictionary of sessions grouped by inference presence/absence.\n",
    "    \"\"\"\n",
    "    session_names = beh_data[\"sessionID\"].to_list()\n",
    "    perf_dict = test_inference_trials(beh_data, task_data)\n",
    "\n",
    "    # Determine inference present/absent groups using significance\n",
    "    inf_absent = [\n",
    "        name for i, name in enumerate(session_names)\n",
    "        if perf_dict[\"inference\"][i] > p and perf_dict[\"baseline\"][i] < p\n",
    "    ]\n",
    "    inf_present = [\n",
    "        name for i, name in enumerate(session_names)\n",
    "        if perf_dict[\"inference\"][i] < p and perf_dict[\"baseline\"][i] > p\n",
    "    ]\n",
    "    \n",
    "    all_sessions = neu_data[\"sessionID\"]\n",
    "    return {\n",
    "        \"absent\" : inf_absent,\n",
    "        \"present\" : inf_present,\n",
    "        \"absent_idx\" : [i for i, name in enumerate(all_sessions) if name in inf_absent],\n",
    "        \"present_idx\" : [i for i, name in enumerate(all_sessions) if name in inf_present],\n",
    "        \"sessions\" : session_names\n",
    "    }\n",
    "    \n",
    "\n",
    "split_sessions(neu_data, beh_data, task_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binned spike counts\n",
    "\n",
    "Each row of the `neu_data` dataset corresponds to a single neuron. \n",
    "\n",
    "* `cellinfo`: index of brain region that the cell is in;\n",
    "* `sessionID`: unique identifier for each recording session, during which paricipants performed a serial reversal-learning task;\n",
    "* `array`: a subtable of data for each neuron that contains information for all trials in the session.\n",
    "\n",
    "TO DO: what is a trial?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>array</th>\n",
       "      <th>cellinfo</th>\n",
       "      <th>sessionID</th>\n",
       "      <th>n_trials</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[{'block_nr': 1, 'iscorrect': True, 'stim_id':...</td>\n",
       "      <td>2</td>\n",
       "      <td>P61CS_1</td>\n",
       "      <td>320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[{'block_nr': 1, 'iscorrect': True, 'stim_id':...</td>\n",
       "      <td>2</td>\n",
       "      <td>P61CS_1</td>\n",
       "      <td>320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[{'block_nr': 1, 'iscorrect': True, 'stim_id':...</td>\n",
       "      <td>2</td>\n",
       "      <td>P61CS_1</td>\n",
       "      <td>320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[{'block_nr': 1, 'iscorrect': True, 'stim_id':...</td>\n",
       "      <td>4</td>\n",
       "      <td>P61CS_1</td>\n",
       "      <td>320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[{'block_nr': 1, 'iscorrect': True, 'stim_id':...</td>\n",
       "      <td>4</td>\n",
       "      <td>P61CS_1</td>\n",
       "      <td>320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2689</th>\n",
       "      <td>[{'block_nr': 1, 'iscorrect': False, 'stim_id'...</td>\n",
       "      <td>3</td>\n",
       "      <td>TWH172_2</td>\n",
       "      <td>240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2690</th>\n",
       "      <td>[{'block_nr': 1, 'iscorrect': False, 'stim_id'...</td>\n",
       "      <td>3</td>\n",
       "      <td>TWH172_2</td>\n",
       "      <td>240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2691</th>\n",
       "      <td>[{'block_nr': 1, 'iscorrect': False, 'stim_id'...</td>\n",
       "      <td>3</td>\n",
       "      <td>TWH172_2</td>\n",
       "      <td>240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2692</th>\n",
       "      <td>[{'block_nr': 1, 'iscorrect': False, 'stim_id'...</td>\n",
       "      <td>3</td>\n",
       "      <td>TWH172_2</td>\n",
       "      <td>240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2693</th>\n",
       "      <td>[{'block_nr': 1, 'iscorrect': False, 'stim_id'...</td>\n",
       "      <td>3</td>\n",
       "      <td>TWH172_2</td>\n",
       "      <td>240</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2694 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  array  cellinfo sessionID  \\\n",
       "0     [{'block_nr': 1, 'iscorrect': True, 'stim_id':...         2   P61CS_1   \n",
       "1     [{'block_nr': 1, 'iscorrect': True, 'stim_id':...         2   P61CS_1   \n",
       "2     [{'block_nr': 1, 'iscorrect': True, 'stim_id':...         2   P61CS_1   \n",
       "3     [{'block_nr': 1, 'iscorrect': True, 'stim_id':...         4   P61CS_1   \n",
       "4     [{'block_nr': 1, 'iscorrect': True, 'stim_id':...         4   P61CS_1   \n",
       "...                                                 ...       ...       ...   \n",
       "2689  [{'block_nr': 1, 'iscorrect': False, 'stim_id'...         3  TWH172_2   \n",
       "2690  [{'block_nr': 1, 'iscorrect': False, 'stim_id'...         3  TWH172_2   \n",
       "2691  [{'block_nr': 1, 'iscorrect': False, 'stim_id'...         3  TWH172_2   \n",
       "2692  [{'block_nr': 1, 'iscorrect': False, 'stim_id'...         3  TWH172_2   \n",
       "2693  [{'block_nr': 1, 'iscorrect': False, 'stim_id'...         3  TWH172_2   \n",
       "\n",
       "      n_trials  \n",
       "0          320  \n",
       "1          320  \n",
       "2          320  \n",
       "3          320  \n",
       "4          320  \n",
       "...        ...  \n",
       "2689       240  \n",
       "2690       240  \n",
       "2691       240  \n",
       "2692       240  \n",
       "2693       240  \n",
       "\n",
       "[2694 rows x 4 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neu_data = pd.read_json(\"neu.json\")\n",
    "neu_data[\"n_trials\"] = neu_data[\"array\"].apply(lambda x : len(x))\n",
    "neu_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "n_trials\n",
       "240    2309\n",
       "260     119\n",
       "200     105\n",
       "180      65\n",
       "320      57\n",
       "280      39\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neu_data[\"n_trials\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cellinfo\n",
       "1     889\n",
       "3     494\n",
       "9     463\n",
       "2     310\n",
       "4     269\n",
       "12    269\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neu_data[\"cellinfo\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>block_nr</th>\n",
       "      <th>iscorrect</th>\n",
       "      <th>stim_id</th>\n",
       "      <th>context</th>\n",
       "      <th>reward</th>\n",
       "      <th>response</th>\n",
       "      <th>trial_nr</th>\n",
       "      <th>fr_stim</th>\n",
       "      <th>fr_base</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.909091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.909091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>10</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>3</td>\n",
       "      <td>0.909091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>10</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>10</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>1.818182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>10</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>1.818182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>10</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>3</td>\n",
       "      <td>0.909091</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>320 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     block_nr  iscorrect  stim_id  context  reward  response  trial_nr  \\\n",
       "0           1       True        2        2      25         0         1   \n",
       "1           1       True        4        2       5         0         2   \n",
       "2           1       True        1        2       5         1         3   \n",
       "3           1       True        2        2      25         0         4   \n",
       "4           1       True        4        2       5         0         5   \n",
       "..        ...        ...      ...      ...     ...       ...       ...   \n",
       "315        10       True        3        1       5         0        19   \n",
       "316        10       True        3        1       5         0        20   \n",
       "317        10       True        2        1      25         1        21   \n",
       "318        10       True        2        1      25         1        22   \n",
       "319        10       True        1        1      25         0        23   \n",
       "\n",
       "     fr_stim   fr_base  \n",
       "0          0  0.000000  \n",
       "1          0  0.000000  \n",
       "2          2  0.000000  \n",
       "3          1  0.909091  \n",
       "4          0  0.909091  \n",
       "..       ...       ...  \n",
       "315        3  0.909091  \n",
       "316        1  0.000000  \n",
       "317        1  1.818182  \n",
       "318        0  1.818182  \n",
       "319        3  0.909091  \n",
       "\n",
       "[320 rows x 9 columns]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_cell_array(\n",
    "    neu_data : pd.DataFrame,\n",
    "    cell_idx : int\n",
    " ) -> pd.DataFrame:\n",
    "    cell_array_dict = {}\n",
    "    for row_dict in neu_data[\"array\"][cell_idx]:\n",
    "        for key, value in row_dict.items():\n",
    "            if key not in cell_array_dict:\n",
    "                cell_array_dict[key] = [value]\n",
    "            else:\n",
    "                cell_array_dict[key].append(value)\n",
    "    cell_array_data = pd.DataFrame(cell_array_dict)\n",
    "    return cell_array_data\n",
    "\n",
    "cell_array_example = get_cell_array(neu_data=neu_data, cell_idx=0)\n",
    "cell_array_example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform geometric analysis on balanced dichotomies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Aggregate neurons by area\n",
    "\n",
    "Individual neuron data was combined across all participants to form a single \"pseudo-population.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution of neurons across brain areas:\n",
      "HPC: 494\n",
      "vmPFC: 889\n",
      "AMY: 269\n",
      "dACC: 310\n",
      "preSMA: 463\n",
      "VTC: 269\n"
     ]
    }
   ],
   "source": [
    "def define_cell_area_groups(neu_data : pd.DataFrame) -> dict:\n",
    "    area_order = ['HPC','vmPFC','AMY','dACC','preSMA','VTC']\n",
    "    idx_order = [3, 1, 4, 2, 9, 12]\n",
    "    cellinfo = neu_data.cellinfo.to_numpy()\n",
    "    cell_area_groups = {}\n",
    "    for i, area in enumerate(area_order):\n",
    "        idx = np.where(cellinfo == idx_order[i])[0]\n",
    "        cell_area_groups[area] = idx\n",
    "    return cell_area_groups\n",
    "\n",
    "cell_area_groups = define_cell_area_groups(neu_data)\n",
    "print(\"Distribution of neurons across brain areas:\")\n",
    "for key, value in cell_area_groups.items():\n",
    "    print(f\"{key}: {len(value)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Define metrics for assessment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Balanced dichotomies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_dichotomies() -> tuple[dict, np.array, np.array]:\n",
    "    \"\"\"\n",
    "    Define the set of all possible balanced dichotomies by all possible ways\n",
    "    that eight unique task conditions can be split into two groups of four \n",
    "    conditons each. There are (8 choose 4)/2 = 35 possible balanced dichotomies.\n",
    "    \n",
    "    Conditions are defined as follows [#: stimulus, response, outcome, context]:\n",
    "    - 1: C, left, 5, 1\n",
    "    - 2: D, right, 5, 1\n",
    "    - 3: A, left, 25, 1\n",
    "    - 4: B, right, 25, 1\n",
    "    - 5: D, left 5, 2\n",
    "    - 6: A, right, 5, 2\n",
    "    - 7: B, left, 25, 2\n",
    "    - 8: C, right, 25, 2\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        Dictionary of (index, name) pair for dichotomies with clear \n",
    "        interpretations with respect to task condition.\n",
    "    np.array\n",
    "        First class of dichotomies.\n",
    "    np.array\n",
    "        Second class of dichotomies.\n",
    "    \"\"\"\n",
    "    interpretations = {\n",
    "        0 : \"context\",\n",
    "        9 : \"outcome\",\n",
    "        11 : \"AB vs CD\",\n",
    "        20 : \"response\",\n",
    "        23 : \"AC vs BD\", \n",
    "        31 : \"AD vs BC\"\n",
    "    }\n",
    "    pos_set = np.array([\n",
    "        [1, 2, 3, 4], [1, 2, 3, 5], [1, 2, 3, 6], [1, 2, 3, 7], [1, 2, 3, 8],\n",
    "        [1, 2, 4, 5], [1, 2, 4, 6], [1, 2, 4, 7], [1, 2, 4, 8], [1, 2, 5, 6],\n",
    "        [1, 2, 5, 7], [1, 2, 5, 8], [1, 2, 6, 7], [1, 2, 6, 8], [1, 2, 7, 8],\n",
    "        [1, 3, 4, 5], [1, 3, 4, 6], [1, 3, 4, 7], [1, 3, 4, 8], [1, 3, 5, 6],\n",
    "        [1, 3, 5, 7], [1, 3, 5, 8], [1, 3, 6, 7], [1, 3, 6, 8], [1, 3, 7, 8],\n",
    "        [1, 4, 5, 6], [1, 4, 5, 7], [1, 4, 5, 8], [1, 4, 6, 7], [1, 4, 6, 8],\n",
    "        [1, 4, 7, 8], [1, 5, 6, 7], [1, 5, 6, 8], [1, 5, 7, 8], [1, 6, 7, 8]\n",
    "    ])\n",
    "    neg_set = np.array([\n",
    "        [5, 6, 7, 8], [4, 6, 7, 8], [4, 5, 7, 8], [4, 5, 6, 8], [4, 5, 6, 7],\n",
    "        [3, 6, 7, 8], [3, 5, 7, 8], [3, 5, 6, 8], [3, 5, 6, 7], [3, 4, 7, 8],\n",
    "        [3, 4, 6, 8], [3, 4, 6, 7], [3, 4, 5, 8], [3, 4, 5, 7], [3, 4, 5, 6],\n",
    "        [2, 6, 7, 8], [2, 5, 7, 8], [2, 5, 6, 8], [2, 5, 6, 7], [2, 4, 7, 8],\n",
    "        [2, 4, 6, 8], [2, 4, 6, 7], [2, 4, 5, 8], [2, 4, 5, 7], [2, 4, 5, 6],\n",
    "        [2, 3, 7, 8], [2, 3, 6, 8], [2, 3, 6, 7], [2, 3, 5, 8], [2, 3, 5, 7],\n",
    "        [2, 3, 5, 6], [2, 3, 4, 8], [2, 3, 4, 7], [2, 3, 4, 6], [2, 3, 4, 5]\n",
    "    ]) \n",
    "    return interpretations, pos_set - np.ones_like(pos_set), neg_set - np.ones_like(neg_set)\n",
    "\n",
    "def make_variable_groups(\n",
    "    cell_data : pd.DataFrame,\n",
    "    var_names : list[str]\n",
    "):\n",
    "    \"\"\"\n",
    "    Create groups of all possible combinations of values for the given \n",
    "    variables.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    cell_data : pd.DataFrame\n",
    "        Data for a single neuron, where each row represents one trial.\n",
    "    var_names : list[str]\n",
    "        List of DataFrame columns to consider.\n",
    "\n",
    "    Returns:\n",
    "    groups : pd.DataFrame\n",
    "        DataFrame where each row represents a trial and each column represents \n",
    "        membership in a group.\n",
    "    \"\"\"\n",
    "    unique_values = [sorted(cell_data[var].unique()) for var in var_names]\n",
    "    combinations = list(itertools.product(*unique_values))\n",
    "    group_names = [\n",
    "        \"_\".join([f\"{var}_{value}\" for var, value in zip(var_names, combo)])\n",
    "        for combo in combinations\n",
    "    ]\n",
    "    groups = pd.DataFrame(np.zeros(\n",
    "        (len(cell_data), len(combinations)), dtype=bool\n",
    "    ), columns=group_names)\n",
    "    for i, combo in enumerate(combinations):\n",
    "        # Set combination membership for all trials in a single column\n",
    "        condition = np.all([\n",
    "            cell_data[var] == value for var, value in zip(var_names, combo)\n",
    "        ], axis=0)\n",
    "        groups[group_names[i]] = condition\n",
    "    return groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context_1_reward_5_response_0</th>\n",
       "      <th>context_1_reward_5_response_1</th>\n",
       "      <th>context_1_reward_25_response_0</th>\n",
       "      <th>context_1_reward_25_response_1</th>\n",
       "      <th>context_2_reward_5_response_0</th>\n",
       "      <th>context_2_reward_5_response_1</th>\n",
       "      <th>context_2_reward_25_response_0</th>\n",
       "      <th>context_2_reward_25_response_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[2, 0, 5, 1, 2, 0, 1, 3, 2, 1, 3, 3, 4, 0, 1, ...</td>\n",
       "      <td>[0, 3, 2, 4, 0, 0, 3, 2, 0, 3, 0, 1, 0, 2, 4, ...</td>\n",
       "      <td>[0, 4, 3, 0, 5, 0, 4, 0, 1, 3, 2, 0, 1, 1, 0, ...</td>\n",
       "      <td>[0, 1, 2, 1, 5, 2, 1, 1, 3, 2, 2, 0, 1, 0, 2, ...</td>\n",
       "      <td>[0, 0, 1, 1, 0, 2, 1, 3, 1, 0, 4, 0, 0, 0, 0, ...</td>\n",
       "      <td>[2, 0, 1, 3, 1, 2, 0, 4, 0, 0, 1, 2, 1, 3, 3, ...</td>\n",
       "      <td>[0, 1, 1, 2, 1, 3, 2, 2, 0, 2, 3, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1, 7, 2, 3, 1, 1, 0, 1, 3, 0, 1, 2, 2, 3, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[4, 3, 2, 2, 7, 0, 6, 0, 5, 4, 1, 4, 3, 4, 3, ...</td>\n",
       "      <td>[3, 3, 3, 1, 5, 4, 4, 3, 3, 0, 6, 2, 5, 4, 3, ...</td>\n",
       "      <td>[0, 3, 5, 3, 6, 2, 3, 1, 3, 0, 2, 0, 10, 3, 4,...</td>\n",
       "      <td>[3, 1, 3, 2, 2, 4, 3, 6, 3, 2, 1, 0, 4, 2, 1, ...</td>\n",
       "      <td>[0, 1, 3, 1, 4, 2, 2, 4, 0, 1, 6, 0, 3, 0, 2, ...</td>\n",
       "      <td>[1, 3, 4, 1, 5, 3, 1, 2, 2, 2, 3, 2, 0, 1, 1, ...</td>\n",
       "      <td>[2, 1, 3, 3, 4, 3, 1, 1, 2, 2, 1, 3, 0, 0, 1, ...</td>\n",
       "      <td>[6, 1, 5, 1, 2, 1, 0, 1, 4, 0, 3, 2, 2, 6, 3, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 3, 1, 1, 0, 0, 1, 1, 1, 0, ...</td>\n",
       "      <td>[0, 0, 2, 1, 1, 0, 2, 0, 0, 0, 2, 0, 0, 0, 1, ...</td>\n",
       "      <td>[1, 0, 0, 0, 2, 1, 2, 1, 0, 0, 0, 0, 0, 0, 1, ...</td>\n",
       "      <td>[0, 1, 0, 0, 2, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 2, 0, 0, ...</td>\n",
       "      <td>[0, 1, 0, 3, 0, 0, 1, 1, 0, 1, 1, 0, 2, 0, 0, ...</td>\n",
       "      <td>[2, 0, 1, 0, 0, 0, 2, 0, 0, 0, 0, 0, 1, 0, 1, ...</td>\n",
       "      <td>[2, 1, 0, 1, 0, 0, 2, 0, 0, 1, 1, 3, 1, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[0, 0, 0, 0, 11, 11, 0, 0, 0, 0, 0, 0, 0, 0, 0...</td>\n",
       "      <td>[0, 0, 0, 6, 4, 19, 0, 0, 1, 1, 0, 0, 1, 0, 0,...</td>\n",
       "      <td>[0, 4, 15, 5, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1,...</td>\n",
       "      <td>[1, 0, 0, 6, 0, 4, 0, 0, 1, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, ...</td>\n",
       "      <td>[4, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, ...</td>\n",
       "      <td>[1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[4, 12, 7, 4, 17, 5, 5, 4, 5, 8, 12, 5, 7, 2, ...</td>\n",
       "      <td>[6, 3, 7, 5, 19, 3, 9, 14, 10, 10, 4, 10, 4, 8...</td>\n",
       "      <td>[6, 12, 3, 4, 4, 6, 3, 6, 7, 10, 4, 4, 9, 11, ...</td>\n",
       "      <td>[5, 8, 6, 4, 2, 8, 4, 2, 13, 3, 4, 0, 4, 6, 3,...</td>\n",
       "      <td>[0, 7, 5, 6, 7, 10, 5, 6, 13, 7, 2, 5, 5, 5, 6...</td>\n",
       "      <td>[0, 5, 3, 3, 9, 6, 4, 6, 6, 6, 6, 4, 11, 3, 1,...</td>\n",
       "      <td>[0, 15, 9, 5, 6, 8, 13, 7, 9, 6, 6, 6, 3, 9, 7...</td>\n",
       "      <td>[9, 4, 14, 3, 4, 9, 1, 1, 8, 2, 17, 10, 4, 5, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       context_1_reward_5_response_0  \\\n",
       "0  [2, 0, 5, 1, 2, 0, 1, 3, 2, 1, 3, 3, 4, 0, 1, ...   \n",
       "1  [4, 3, 2, 2, 7, 0, 6, 0, 5, 4, 1, 4, 3, 4, 3, ...   \n",
       "2  [0, 0, 0, 0, 0, 0, 3, 1, 1, 0, 0, 1, 1, 1, 0, ...   \n",
       "3  [0, 0, 0, 0, 11, 11, 0, 0, 0, 0, 0, 0, 0, 0, 0...   \n",
       "4  [4, 12, 7, 4, 17, 5, 5, 4, 5, 8, 12, 5, 7, 2, ...   \n",
       "\n",
       "                       context_1_reward_5_response_1  \\\n",
       "0  [0, 3, 2, 4, 0, 0, 3, 2, 0, 3, 0, 1, 0, 2, 4, ...   \n",
       "1  [3, 3, 3, 1, 5, 4, 4, 3, 3, 0, 6, 2, 5, 4, 3, ...   \n",
       "2  [0, 0, 2, 1, 1, 0, 2, 0, 0, 0, 2, 0, 0, 0, 1, ...   \n",
       "3  [0, 0, 0, 6, 4, 19, 0, 0, 1, 1, 0, 0, 1, 0, 0,...   \n",
       "4  [6, 3, 7, 5, 19, 3, 9, 14, 10, 10, 4, 10, 4, 8...   \n",
       "\n",
       "                      context_1_reward_25_response_0  \\\n",
       "0  [0, 4, 3, 0, 5, 0, 4, 0, 1, 3, 2, 0, 1, 1, 0, ...   \n",
       "1  [0, 3, 5, 3, 6, 2, 3, 1, 3, 0, 2, 0, 10, 3, 4,...   \n",
       "2  [1, 0, 0, 0, 2, 1, 2, 1, 0, 0, 0, 0, 0, 0, 1, ...   \n",
       "3  [0, 4, 15, 5, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1,...   \n",
       "4  [6, 12, 3, 4, 4, 6, 3, 6, 7, 10, 4, 4, 9, 11, ...   \n",
       "\n",
       "                      context_1_reward_25_response_1  \\\n",
       "0  [0, 1, 2, 1, 5, 2, 1, 1, 3, 2, 2, 0, 1, 0, 2, ...   \n",
       "1  [3, 1, 3, 2, 2, 4, 3, 6, 3, 2, 1, 0, 4, 2, 1, ...   \n",
       "2  [0, 1, 0, 0, 2, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, ...   \n",
       "3  [1, 0, 0, 6, 0, 4, 0, 0, 1, 0, 0, 0, 0, 0, 0, ...   \n",
       "4  [5, 8, 6, 4, 2, 8, 4, 2, 13, 3, 4, 0, 4, 6, 3,...   \n",
       "\n",
       "                       context_2_reward_5_response_0  \\\n",
       "0  [0, 0, 1, 1, 0, 2, 1, 3, 1, 0, 4, 0, 0, 0, 0, ...   \n",
       "1  [0, 1, 3, 1, 4, 2, 2, 4, 0, 1, 6, 0, 3, 0, 2, ...   \n",
       "2  [1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 2, 0, 0, ...   \n",
       "3  [1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, ...   \n",
       "4  [0, 7, 5, 6, 7, 10, 5, 6, 13, 7, 2, 5, 5, 5, 6...   \n",
       "\n",
       "                       context_2_reward_5_response_1  \\\n",
       "0  [2, 0, 1, 3, 1, 2, 0, 4, 0, 0, 1, 2, 1, 3, 3, ...   \n",
       "1  [1, 3, 4, 1, 5, 3, 1, 2, 2, 2, 3, 2, 0, 1, 1, ...   \n",
       "2  [0, 1, 0, 3, 0, 0, 1, 1, 0, 1, 1, 0, 2, 0, 0, ...   \n",
       "3  [4, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, ...   \n",
       "4  [0, 5, 3, 3, 9, 6, 4, 6, 6, 6, 6, 4, 11, 3, 1,...   \n",
       "\n",
       "                      context_2_reward_25_response_0  \\\n",
       "0  [0, 1, 1, 2, 1, 3, 2, 2, 0, 2, 3, 0, 0, 0, 0, ...   \n",
       "1  [2, 1, 3, 3, 4, 3, 1, 1, 2, 2, 1, 3, 0, 0, 1, ...   \n",
       "2  [2, 0, 1, 0, 0, 0, 2, 0, 0, 0, 0, 0, 1, 0, 1, ...   \n",
       "3  [1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, ...   \n",
       "4  [0, 15, 9, 5, 6, 8, 13, 7, 9, 6, 6, 6, 3, 9, 7...   \n",
       "\n",
       "                      context_2_reward_25_response_1  \n",
       "0  [1, 7, 2, 3, 1, 1, 0, 1, 3, 0, 1, 2, 2, 3, 0, ...  \n",
       "1  [6, 1, 5, 1, 2, 1, 0, 1, 4, 0, 3, 2, 2, 6, 3, ...  \n",
       "2  [2, 1, 0, 1, 0, 0, 2, 0, 0, 1, 1, 3, 1, 0, 0, ...  \n",
       "3  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, ...  \n",
       "4  [9, 4, 14, 3, 4, 9, 1, 1, 8, 2, 17, 10, 4, 5, ...  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def construct_regressors(\n",
    "    neu_data : pd.DataFrame,\n",
    "    thr : int,\n",
    "    select : list\n",
    "):\n",
    "    \"\"\"\n",
    "    Method for balancing neuron counts between inference absent (ia) and \n",
    "    inference present (ip) groups.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    neu_data : pd.DataFrame\n",
    "        DataFrame with each row correpsonding to all trial data for a single \n",
    "        neuron.\n",
    "    sample_thr : int\n",
    "        Minimum number of correct trials of each type to retain neurons.\n",
    "    select : list\n",
    "        Neuron indices to include.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        DataFrame of neurons that clear the trial count threshold. Each row\n",
    "        corresponds to a neuron, and each column corresponds to the average \n",
    "        firing rate for a combination of task variables.\n",
    "    \"\"\"\n",
    "    group_avgs = pd.DataFrame()\n",
    "    for i in select:\n",
    "        # Select only correct trials for given neuron\n",
    "        cell_data = get_cell_array(neu_data=neu_data, cell_idx=i)\n",
    "        valid_data = cell_data[cell_data[\"iscorrect\"] == True]\n",
    "        \n",
    "        # Make trial-level labels according to binary task variables\n",
    "        groups = make_variable_groups(\n",
    "            cell_data=valid_data,\n",
    "            var_names=[\"context\", \"reward\", \"response\"]\n",
    "        )     \n",
    "\n",
    "        firing_rate = valid_data[\"fr_stim\"].values\n",
    "        group_avg = []\n",
    "        for combo in groups.columns:\n",
    "            # Get boolean mask for inclusion in current group\n",
    "            group_firing_rate = firing_rate[groups[combo]]\n",
    "            # Check that neuron has enough samples of the current type\n",
    "            if len(group_firing_rate) > thr:\n",
    "                group_avg.append(group_firing_rate)\n",
    "            if combo not in group_avgs.columns:\n",
    "                group_avgs[combo] = None\n",
    "        # Only append data for neurons with enough trials in all types\n",
    "        if len(group_avg) == len(groups.columns):\n",
    "            group_avgs.loc[len(group_avgs)] = group_avg\n",
    "    return group_avgs\n",
    "\n",
    "group_avgs = construct_regressors(neu_data, thr=15, select=[i for i in range(100)])\n",
    "group_avgs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 ['1', '5', '0']\n",
      "1 ['1', '5', '1']\n",
      "2 ['1', '25', '0']\n",
      "3 ['1', '25', '1']\n",
      "4 ['2', '5', '0']\n",
      "5 ['2', '5', '1']\n",
      "6 ['2', '25', '0']\n",
      "7 ['2', '25', '1']\n"
     ]
    }
   ],
   "source": [
    "# Check that column indices match condition definitions\n",
    "for i, col in enumerate(group_avgs.columns):\n",
    "    vals = [val for val in col.split(\"_\") if val.isdigit()]\n",
    "    print(i, vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# original_columns = group_avgs.columns\n",
    "# for column in original_columns:\n",
    "#     group_avgs[f\"length_{column}\"] = group_avgs[column].apply(lambda x: x.shape[0])\n",
    "# group_avgs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CCGP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ccgp(\n",
    "    group_avgs,\n",
    "    n_iter : int = 5,\n",
    "    n_samples : int = 15,\n",
    "    for_boot : bool = False,\n",
    "    show_progress : bool = False\n",
    "):\n",
    "    \"\"\"\n",
    "    Method for performing CCGP analysis for a group fo cells.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    group_avgs : pd.DataFrame\n",
    "        Data for averaged neuron firing rates across all combinations of task\n",
    "        variables. Each row represents a single neuron, and columns correspond \n",
    "        to different groupings of task variables. The DataFrame is generated by\n",
    "        the `construct_regressors` method.\n",
    "    n_iter : int\n",
    "        Number of iterations of bootstrap re-sampling to perform.\n",
    "    n_samples : int\n",
    "        Number of trials of each condition to sample.\n",
    "    for_boot : bool\n",
    "        Boolean flag for turning on geometric null shuffling for constructing \n",
    "        null distribution.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    np.array\n",
    "        CCGP for every dichotomy (35 in standard geometric analysis with 3\n",
    "        binary variables). Array has shape (35, n_iter).\n",
    "    \"\"\"\n",
    "    def construct_holdouts(group, n_cond):\n",
    "        \"\"\"\n",
    "        Helper function to construct all possible two-condition holdouts. The\n",
    "        last element of each four-element group is the condition to be removed.\n",
    "        \"\"\"\n",
    "        combos = list(itertools.combinations(group, n_cond))\n",
    "        return np.array([\n",
    "            list(c) + list(set(group) - set(c))\n",
    "            for c in combos\n",
    "        ])\n",
    "\n",
    "    def swap_pairs(column):\n",
    "        \"\"\"\n",
    "        Helper function for constructing geometric null distribution by swapping\n",
    "        pairs of neuron responses in each task condition.\n",
    "        \"\"\"\n",
    "        perm_idx = np.random.permutation(len(column))\n",
    "        for i in range(0, len(column), 2):\n",
    "            if i+1 < len(column):  # Make sure we have a pair to swap\n",
    "                column.iloc[i], column.iloc[i+1] = column.iloc[perm_idx[i]], column.iloc[perm_idx[i+1]]\n",
    "        return column\n",
    "\n",
    "    _, pos_set, neg_set = define_dichotomies()\n",
    "    n_pairs = pos_set.shape[0]\n",
    "    n_cond = 3\n",
    "    dichot_perm = np.full((n_pairs, n_iter), np.nan)\n",
    "\n",
    "    for i, (g1, g2) in enumerate(zip(pos_set, neg_set)):\n",
    "        start_time = time.time()\n",
    "        # Construct 16 possible train/test splits\n",
    "        c1 = construct_holdouts(g1, n_cond)\n",
    "        c2 = construct_holdouts(g2, n_cond)\n",
    "        holdout_combinations = list(itertools.product(c1, c2))\n",
    "\n",
    "        # Construct null distribution\n",
    "        if for_boot:\n",
    "            group_avgs = group_avgs.apply(swap_pairs)\n",
    "\n",
    "        for j in range(n_iter):\n",
    "            perf_temp = []\n",
    "            for (c_pos, c_neg) in holdout_combinations:\n",
    "                # Select 6 total conditions for training and 2 for testing\n",
    "                train_idx = np.concatenate((c_pos[:n_cond], c_neg[:n_cond]))\n",
    "                test_idx = np.concatenate((c_pos[n_cond:], c_neg[n_cond:]))\n",
    "\n",
    "                # Sample trials for each condition\n",
    "                sampled_avgs, _ = F.sample_from_data(\n",
    "                    group_avgs,\n",
    "                    n_train=n_samples,\n",
    "                    n_test=0\n",
    "                )\n",
    "                train, train_labels, test, test_labels = F.prep_regressors(\n",
    "                    sampled_avgs, sampled_avgs, g1=train_idx, g2=test_idx\n",
    "                )\n",
    "\n",
    "                # Normalize (z-score) and remove nan features\n",
    "                scaler = StandardScaler()\n",
    "                train_scaled = scaler.fit_transform(train)\n",
    "                test_scaled = scaler.fit_transform(test)\n",
    "                idx_remove_train = np.where(np.isnan(train_scaled).sum(axis=0) > 0)[0]\n",
    "                idx_remove_test = np.where(np.isnan(test_scaled).sum(axis=0) > 0)[0]\n",
    "                idx_remove = np.union1d(idx_remove_train, idx_remove_test)\n",
    "                train_scaled = np.delete(train_scaled, idx_remove, axis=1)\n",
    "                test_scaled = np.delete(test_scaled, idx_remove, axis=1)\n",
    "\n",
    "                # Train decoder (SVM)\n",
    "                decoder = LogisticRegression().fit(train_scaled, train_labels)\n",
    "                y_hat = decoder.predict(test_scaled)\n",
    "                perf_temp.append(np.mean(y_hat == test_labels))\n",
    "            dichot_perm[i, j] = np.mean(perf_temp)\n",
    "        end_time = time.time()\n",
    "        if show_progress:\n",
    "            print(f\"CCGP computed for pair {i+1} of {n_pairs}. Time: {end_time - start_time:.6f} seconds.\")\n",
    "    return dichot_perm\n",
    "\n",
    "# print(group_avgs.columns)  \n",
    "# dichot_perm = ccgp(group_avgs, n_iter=1, show_progress=True)\n",
    "# dichot_perm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CCGP computed for pair 1 of 35. Time: 8.340351 seconds.\n",
      "CCGP computed for pair 2 of 35. Time: 5.496331 seconds.\n",
      "CCGP computed for pair 3 of 35. Time: 5.947267 seconds.\n",
      "CCGP computed for pair 4 of 35. Time: 5.097601 seconds.\n",
      "CCGP computed for pair 5 of 35. Time: 5.736694 seconds.\n",
      "CCGP computed for pair 6 of 35. Time: 4.838721 seconds.\n",
      "CCGP computed for pair 7 of 35. Time: 4.941342 seconds.\n",
      "CCGP computed for pair 8 of 35. Time: 7.947572 seconds.\n",
      "CCGP computed for pair 9 of 35. Time: 7.081437 seconds.\n",
      "CCGP computed for pair 10 of 35. Time: 6.123168 seconds.\n",
      "CCGP computed for pair 11 of 35. Time: 7.117636 seconds.\n",
      "CCGP computed for pair 12 of 35. Time: 5.089813 seconds.\n",
      "CCGP computed for pair 13 of 35. Time: 6.054278 seconds.\n",
      "CCGP computed for pair 14 of 35. Time: 5.507833 seconds.\n",
      "CCGP computed for pair 15 of 35. Time: 7.338533 seconds.\n",
      "CCGP computed for pair 16 of 35. Time: 5.807067 seconds.\n",
      "CCGP computed for pair 17 of 35. Time: 6.050510 seconds.\n",
      "CCGP computed for pair 18 of 35. Time: 4.980882 seconds.\n",
      "CCGP computed for pair 19 of 35. Time: 6.696271 seconds.\n",
      "CCGP computed for pair 20 of 35. Time: 5.400053 seconds.\n",
      "CCGP computed for pair 21 of 35. Time: 5.164531 seconds.\n",
      "CCGP computed for pair 22 of 35. Time: 5.707943 seconds.\n",
      "CCGP computed for pair 23 of 35. Time: 4.719394 seconds.\n",
      "CCGP computed for pair 24 of 35. Time: 4.676900 seconds.\n",
      "CCGP computed for pair 25 of 35. Time: 4.595555 seconds.\n",
      "CCGP computed for pair 26 of 35. Time: 4.330147 seconds.\n",
      "CCGP computed for pair 27 of 35. Time: 4.899395 seconds.\n",
      "CCGP computed for pair 28 of 35. Time: 4.892682 seconds.\n",
      "CCGP computed for pair 29 of 35. Time: 5.759706 seconds.\n",
      "CCGP computed for pair 30 of 35. Time: 5.715040 seconds.\n",
      "CCGP computed for pair 31 of 35. Time: 6.554222 seconds.\n",
      "CCGP computed for pair 32 of 35. Time: 6.329956 seconds.\n",
      "CCGP computed for pair 33 of 35. Time: 7.830558 seconds.\n",
      "CCGP computed for pair 34 of 35. Time: 6.245943 seconds.\n",
      "CCGP computed for pair 35 of 35. Time: 5.989603 seconds.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.750625  ],\n",
       "       [0.75117188],\n",
       "       [0.74992187],\n",
       "       [0.75015625],\n",
       "       [0.75085937],\n",
       "       [0.75242188],\n",
       "       [0.75140625],\n",
       "       [0.75359375],\n",
       "       [0.7534375 ],\n",
       "       [0.75320312],\n",
       "       [0.75710937],\n",
       "       [0.75789062],\n",
       "       [0.75445313],\n",
       "       [0.75859375],\n",
       "       [0.75460938],\n",
       "       [0.75242188],\n",
       "       [0.75453125],\n",
       "       [0.75828125],\n",
       "       [0.75492187],\n",
       "       [0.75265625],\n",
       "       [0.75929688],\n",
       "       [0.75382812],\n",
       "       [0.76664062],\n",
       "       [0.76320312],\n",
       "       [0.766875  ],\n",
       "       [0.75882812],\n",
       "       [0.7703125 ],\n",
       "       [0.76476563],\n",
       "       [0.7740625 ],\n",
       "       [0.770625  ],\n",
       "       [0.77695313],\n",
       "       [0.77859375],\n",
       "       [0.76601562],\n",
       "       [0.77171875],\n",
       "       [0.7703125 ]])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ccgp_boot = ccgp(group_avgs, n_iter=1, for_boot=True, show_progress=True)\n",
    "ccgp_boot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(group_avgs.iloc[0, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Shattering dimensionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context_1_reward_5_response_0</th>\n",
       "      <th>context_1_reward_5_response_1</th>\n",
       "      <th>context_1_reward_25_response_0</th>\n",
       "      <th>context_1_reward_25_response_1</th>\n",
       "      <th>context_2_reward_5_response_0</th>\n",
       "      <th>context_2_reward_5_response_1</th>\n",
       "      <th>context_2_reward_25_response_0</th>\n",
       "      <th>context_2_reward_25_response_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[2, 2, 2, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1]</td>\n",
       "      <td>[0, 0, 3, 0, 0, 3, 0, 0, 1, 1, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[1, 0, 2, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0]</td>\n",
       "      <td>[5, 5, 4, 4, 4, 5, 6, 5, 9, 5, 6, 5, 6, 7, 7]</td>\n",
       "      <td>[3, 0, 0, 2, 0, 3, 2, 3, 4, 2, 1, 1, 2, 1, 2]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1]</td>\n",
       "      <td>[0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1]</td>\n",
       "      <td>[3, 0, 7, 1, 0, 2, 2, 2, 4, 4, 0, 5, 0, 0, 4]</td>\n",
       "      <td>[3, 1, 2, 2, 2, 0, 0, 1, 1, 1, 2, 1, 3, 0, 2]</td>\n",
       "      <td>[3, 4, 6, 3, 2, 6, 18, 4, 7, 6, 2, 7, 5, 6, 9]</td>\n",
       "      <td>[0, 0, 0, 1, 0, 0, 0, 2, 0, 0, 2, 0, 0, 0, 1]</td>\n",
       "      <td>[1, 1, 1, 2, 1, 0, 0, 4, 1, 2, 2, 1, 4, 3, 0]</td>\n",
       "      <td>[1, 2, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[1, 1, 3, 3, 2, 0, 1, 5, 1, 0, 2, 3, 1, 0, 2]</td>\n",
       "      <td>[0, 2, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1]</td>\n",
       "      <td>[2, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1]</td>\n",
       "      <td>[10, 8, 6, 5, 1, 0, 2, 0, 3, 6, 0, 4, 5, 2, 1]</td>\n",
       "      <td>[0, 0, 2, 1, 3, 1, 0, 1, 0, 2, 0, 4, 3, 0, 1]</td>\n",
       "      <td>[2, 1, 5, 1, 4, 2, 4, 1, 1, 2, 4, 2, 6, 4, 2]</td>\n",
       "      <td>[4, 4, 1, 3, 4, 7, 3, 3, 5, 0, 0, 4, 2, 4, 6]</td>\n",
       "      <td>[4, 5, 2, 5, 5, 5, 1, 1, 4, 2, 6, 1, 5, 2, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[11, 13, 16, 9, 8, 2, 9, 1, 6, 4, 12, 3, 3, 5, 6]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 2, 0, 0, 0]</td>\n",
       "      <td>[0, 3, 1, 2, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 2]</td>\n",
       "      <td>[2, 3, 2, 0, 1, 3, 2, 2, 1, 2, 1, 2, 3, 3, 0]</td>\n",
       "      <td>[0, 1, 3, 0, 2, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0]</td>\n",
       "      <td>[1, 0, 1, 0, 1, 2, 1, 0, 1, 0, 0, 0, 2, 0, 2]</td>\n",
       "      <td>[0, 0, 2, 0, 0, 2, 1, 0, 1, 0, 0, 2, 1, 0, 1]</td>\n",
       "      <td>[0, 0, 0, 0, 1, 1, 2, 0, 1, 0, 0, 1, 1, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[1, 5, 6, 3, 3, 2, 0, 3, 4, 3, 1, 12, 12, 7, 8]</td>\n",
       "      <td>[3, 1, 1, 4, 4, 2, 3, 3, 3, 2, 4, 5, 3, 5, 7]</td>\n",
       "      <td>[0, 2, 2, 0, 2, 0, 3, 2, 1, 1, 1, 0, 0, 0, 1]</td>\n",
       "      <td>[5, 6, 4, 3, 3, 2, 1, 3, 3, 0, 5, 5, 5, 3, 3]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[5, 0, 1, 1, 0, 2, 2, 2, 0, 1, 2, 1, 2, 0, 0]</td>\n",
       "      <td>[2, 3, 0, 1, 2, 2, 0, 3, 0, 1, 5, 2, 0, 2, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>[2, 1, 2, 1, 4, 2, 0, 1, 1, 1, 0, 0, 0, 4, 3]</td>\n",
       "      <td>[1, 3, 7, 2, 6, 3, 12, 1, 8, 3, 0, 3, 1, 5, 12]</td>\n",
       "      <td>[0, 1, 1, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1]</td>\n",
       "      <td>[2, 10, 2, 1, 4, 1, 6, 2, 2, 5, 2, 5, 3, 2, 3]</td>\n",
       "      <td>[0, 0, 0, 1, 0, 1, 1, 2, 0, 0, 1, 0, 0, 1, 0]</td>\n",
       "      <td>[0, 0, 1, 0, 3, 0, 1, 2, 1, 0, 0, 1, 1, 0, 0]</td>\n",
       "      <td>[2, 2, 1, 1, 2, 0, 3, 3, 1, 4, 2, 0, 4, 0, 1]</td>\n",
       "      <td>[12, 14, 2, 5, 10, 5, 5, 9, 5, 12, 11, 4, 15, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>[2, 5, 3, 1, 2, 2, 8, 2, 2, 3, 2, 1, 3, 1, 0]</td>\n",
       "      <td>[3, 1, 0, 0, 2, 1, 1, 3, 3, 2, 1, 1, 1, 0, 1]</td>\n",
       "      <td>[0, 1, 2, 0, 0, 0, 3, 0, 2, 2, 1, 1, 1, 0, 0]</td>\n",
       "      <td>[4, 7, 11, 4, 5, 5, 8, 13, 3, 5, 8, 4, 6, 2, 6]</td>\n",
       "      <td>[0, 0, 2, 2, 1, 0, 1, 0, 0, 2, 1, 1, 5, 2, 2]</td>\n",
       "      <td>[4, 7, 10, 8, 11, 4, 6, 13, 8, 10, 9, 8, 7, 11...</td>\n",
       "      <td>[1, 0, 0, 0, 2, 1, 2, 0, 1, 3, 0, 1, 1, 1, 2]</td>\n",
       "      <td>[0, 3, 0, 3, 2, 0, 0, 2, 0, 3, 3, 2, 2, 3, 4]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>[1, 2, 1, 1, 1, 0, 1, 2, 0, 2, 1, 0, 0, 1, 1]</td>\n",
       "      <td>[7, 6, 7, 4, 4, 6, 9, 10, 8, 10, 7, 11, 7, 4, 8]</td>\n",
       "      <td>[3, 1, 1, 3, 2, 3, 1, 0, 1, 1, 1, 1, 1, 1, 0]</td>\n",
       "      <td>[5, 1, 1, 1, 4, 0, 2, 5, 0, 2, 2, 2, 3, 1, 1]</td>\n",
       "      <td>[1, 2, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 2, 0, 0]</td>\n",
       "      <td>[3, 10, 7, 3, 6, 5, 4, 8, 6, 6, 2, 5, 2, 3, 1]</td>\n",
       "      <td>[13, 22, 16, 7, 13, 8, 14, 8, 9, 18, 8, 10, 16...</td>\n",
       "      <td>[0, 4, 3, 2, 0, 3, 3, 8, 3, 7, 1, 3, 3, 7, 6]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>[10, 2, 9, 8, 4, 14, 9, 11, 9, 13, 4, 9, 3, 8, 7]</td>\n",
       "      <td>[2, 1, 1, 1, 2, 1, 1, 0, 1, 4, 0, 3, 1, 0, 3]</td>\n",
       "      <td>[3, 1, 7, 2, 4, 5, 5, 3, 1, 4, 5, 4, 3, 4, 7]</td>\n",
       "      <td>[4, 3, 1, 3, 4, 10, 7, 4, 10, 0, 8, 3, 4, 2, 2]</td>\n",
       "      <td>[4, 9, 6, 6, 7, 6, 7, 7, 2, 9, 6, 6, 7, 4, 4]</td>\n",
       "      <td>[2, 2, 0, 0, 0, 3, 0, 3, 0, 0, 1, 3, 1, 2, 6]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1]</td>\n",
       "      <td>[2, 1, 1, 0, 4, 0, 0, 2, 3, 1, 0, 0, 1, 0, 5]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>[4, 5, 6, 2, 4, 6, 7, 4, 6, 4, 5, 1, 2, 2, 4]</td>\n",
       "      <td>[0, 0, 1, 0, 0, 0, 1, 3, 0, 0, 0, 1, 0, 0, 0]</td>\n",
       "      <td>[0, 2, 1, 1, 1, 1, 2, 0, 1, 1, 0, 0, 1, 0, 1]</td>\n",
       "      <td>[0, 1, 1, 2, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 3]</td>\n",
       "      <td>[1, 2, 0, 3, 0, 0, 2, 0, 1, 3, 3, 2, 1, 1, 1]</td>\n",
       "      <td>[1, 0, 1, 0, 0, 0, 0, 3, 0, 1, 0, 0, 1, 0, 0]</td>\n",
       "      <td>[1, 3, 0, 5, 4, 4, 1, 2, 2, 1, 0, 1, 2, 2, 3]</td>\n",
       "      <td>[2, 5, 5, 0, 2, 4, 2, 4, 4, 2, 3, 3, 6, 3, 4]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        context_1_reward_5_response_0  \\\n",
       "0       [2, 2, 2, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1]   \n",
       "1       [0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1]   \n",
       "2       [1, 1, 3, 3, 2, 0, 1, 5, 1, 0, 2, 3, 1, 0, 2]   \n",
       "3   [11, 13, 16, 9, 8, 2, 9, 1, 6, 4, 12, 3, 3, 5, 6]   \n",
       "4       [0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0]   \n",
       "..                                                ...   \n",
       "95      [2, 1, 2, 1, 4, 2, 0, 1, 1, 1, 0, 0, 0, 4, 3]   \n",
       "96      [2, 5, 3, 1, 2, 2, 8, 2, 2, 3, 2, 1, 3, 1, 0]   \n",
       "97      [1, 2, 1, 1, 1, 0, 1, 2, 0, 2, 1, 0, 0, 1, 1]   \n",
       "98  [10, 2, 9, 8, 4, 14, 9, 11, 9, 13, 4, 9, 3, 8, 7]   \n",
       "99      [4, 5, 6, 2, 4, 6, 7, 4, 6, 4, 5, 1, 2, 2, 4]   \n",
       "\n",
       "                       context_1_reward_5_response_1  \\\n",
       "0      [0, 0, 3, 0, 0, 3, 0, 0, 1, 1, 0, 0, 0, 0, 0]   \n",
       "1      [0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1]   \n",
       "2      [0, 2, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1]   \n",
       "3      [0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 2, 0, 0, 0]   \n",
       "4    [1, 5, 6, 3, 3, 2, 0, 3, 4, 3, 1, 12, 12, 7, 8]   \n",
       "..                                               ...   \n",
       "95   [1, 3, 7, 2, 6, 3, 12, 1, 8, 3, 0, 3, 1, 5, 12]   \n",
       "96     [3, 1, 0, 0, 2, 1, 1, 3, 3, 2, 1, 1, 1, 0, 1]   \n",
       "97  [7, 6, 7, 4, 4, 6, 9, 10, 8, 10, 7, 11, 7, 4, 8]   \n",
       "98     [2, 1, 1, 1, 2, 1, 1, 0, 1, 4, 0, 3, 1, 0, 3]   \n",
       "99     [0, 0, 1, 0, 0, 0, 1, 3, 0, 0, 0, 1, 0, 0, 0]   \n",
       "\n",
       "                   context_1_reward_25_response_0  \\\n",
       "0   [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0]   \n",
       "1   [3, 0, 7, 1, 0, 2, 2, 2, 4, 4, 0, 5, 0, 0, 4]   \n",
       "2   [2, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1]   \n",
       "3   [0, 3, 1, 2, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 2]   \n",
       "4   [3, 1, 1, 4, 4, 2, 3, 3, 3, 2, 4, 5, 3, 5, 7]   \n",
       "..                                            ...   \n",
       "95  [0, 1, 1, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1]   \n",
       "96  [0, 1, 2, 0, 0, 0, 3, 0, 2, 2, 1, 1, 1, 0, 0]   \n",
       "97  [3, 1, 1, 3, 2, 3, 1, 0, 1, 1, 1, 1, 1, 1, 0]   \n",
       "98  [3, 1, 7, 2, 4, 5, 5, 3, 1, 4, 5, 4, 3, 4, 7]   \n",
       "99  [0, 2, 1, 1, 1, 1, 2, 0, 1, 1, 0, 0, 1, 0, 1]   \n",
       "\n",
       "                     context_1_reward_25_response_1  \\\n",
       "0     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]   \n",
       "1     [3, 1, 2, 2, 2, 0, 0, 1, 1, 1, 2, 1, 3, 0, 2]   \n",
       "2    [10, 8, 6, 5, 1, 0, 2, 0, 3, 6, 0, 4, 5, 2, 1]   \n",
       "3     [2, 3, 2, 0, 1, 3, 2, 2, 1, 2, 1, 2, 3, 3, 0]   \n",
       "4     [0, 2, 2, 0, 2, 0, 3, 2, 1, 1, 1, 0, 0, 0, 1]   \n",
       "..                                              ...   \n",
       "95   [2, 10, 2, 1, 4, 1, 6, 2, 2, 5, 2, 5, 3, 2, 3]   \n",
       "96  [4, 7, 11, 4, 5, 5, 8, 13, 3, 5, 8, 4, 6, 2, 6]   \n",
       "97    [5, 1, 1, 1, 4, 0, 2, 5, 0, 2, 2, 2, 3, 1, 1]   \n",
       "98  [4, 3, 1, 3, 4, 10, 7, 4, 10, 0, 8, 3, 4, 2, 2]   \n",
       "99    [0, 1, 1, 2, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 3]   \n",
       "\n",
       "                     context_2_reward_5_response_0  \\\n",
       "0    [1, 0, 2, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0]   \n",
       "1   [3, 4, 6, 3, 2, 6, 18, 4, 7, 6, 2, 7, 5, 6, 9]   \n",
       "2    [0, 0, 2, 1, 3, 1, 0, 1, 0, 2, 0, 4, 3, 0, 1]   \n",
       "3    [0, 1, 3, 0, 2, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0]   \n",
       "4    [5, 6, 4, 3, 3, 2, 1, 3, 3, 0, 5, 5, 5, 3, 3]   \n",
       "..                                             ...   \n",
       "95   [0, 0, 0, 1, 0, 1, 1, 2, 0, 0, 1, 0, 0, 1, 0]   \n",
       "96   [0, 0, 2, 2, 1, 0, 1, 0, 0, 2, 1, 1, 5, 2, 2]   \n",
       "97   [1, 2, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 2, 0, 0]   \n",
       "98   [4, 9, 6, 6, 7, 6, 7, 7, 2, 9, 6, 6, 7, 4, 4]   \n",
       "99   [1, 2, 0, 3, 0, 0, 2, 0, 1, 3, 3, 2, 1, 1, 1]   \n",
       "\n",
       "                        context_2_reward_5_response_1  \\\n",
       "0       [5, 5, 4, 4, 4, 5, 6, 5, 9, 5, 6, 5, 6, 7, 7]   \n",
       "1       [0, 0, 0, 1, 0, 0, 0, 2, 0, 0, 2, 0, 0, 0, 1]   \n",
       "2       [2, 1, 5, 1, 4, 2, 4, 1, 1, 2, 4, 2, 6, 4, 2]   \n",
       "3       [1, 0, 1, 0, 1, 2, 1, 0, 1, 0, 0, 0, 2, 0, 2]   \n",
       "4       [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]   \n",
       "..                                                ...   \n",
       "95      [0, 0, 1, 0, 3, 0, 1, 2, 1, 0, 0, 1, 1, 0, 0]   \n",
       "96  [4, 7, 10, 8, 11, 4, 6, 13, 8, 10, 9, 8, 7, 11...   \n",
       "97     [3, 10, 7, 3, 6, 5, 4, 8, 6, 6, 2, 5, 2, 3, 1]   \n",
       "98      [2, 2, 0, 0, 0, 3, 0, 3, 0, 0, 1, 3, 1, 2, 6]   \n",
       "99      [1, 0, 1, 0, 0, 0, 0, 3, 0, 1, 0, 0, 1, 0, 0]   \n",
       "\n",
       "                       context_2_reward_25_response_0  \\\n",
       "0       [3, 0, 0, 2, 0, 3, 2, 3, 4, 2, 1, 1, 2, 1, 2]   \n",
       "1       [1, 1, 1, 2, 1, 0, 0, 4, 1, 2, 2, 1, 4, 3, 0]   \n",
       "2       [4, 4, 1, 3, 4, 7, 3, 3, 5, 0, 0, 4, 2, 4, 6]   \n",
       "3       [0, 0, 2, 0, 0, 2, 1, 0, 1, 0, 0, 2, 1, 0, 1]   \n",
       "4       [5, 0, 1, 1, 0, 2, 2, 2, 0, 1, 2, 1, 2, 0, 0]   \n",
       "..                                                ...   \n",
       "95      [2, 2, 1, 1, 2, 0, 3, 3, 1, 4, 2, 0, 4, 0, 1]   \n",
       "96      [1, 0, 0, 0, 2, 1, 2, 0, 1, 3, 0, 1, 1, 1, 2]   \n",
       "97  [13, 22, 16, 7, 13, 8, 14, 8, 9, 18, 8, 10, 16...   \n",
       "98      [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1]   \n",
       "99      [1, 3, 0, 5, 4, 4, 1, 2, 2, 1, 0, 1, 2, 2, 3]   \n",
       "\n",
       "                       context_2_reward_25_response_1  \n",
       "0       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2]  \n",
       "1       [1, 2, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0]  \n",
       "2       [4, 5, 2, 5, 5, 5, 1, 1, 4, 2, 6, 1, 5, 2, 2]  \n",
       "3       [0, 0, 0, 0, 1, 1, 2, 0, 1, 0, 0, 1, 1, 0, 0]  \n",
       "4       [2, 3, 0, 1, 2, 2, 0, 3, 0, 1, 5, 2, 0, 2, 1]  \n",
       "..                                                ...  \n",
       "95  [12, 14, 2, 5, 10, 5, 5, 9, 5, 12, 11, 4, 15, ...  \n",
       "96      [0, 3, 0, 3, 2, 0, 0, 2, 0, 3, 3, 2, 2, 3, 4]  \n",
       "97      [0, 4, 3, 2, 0, 3, 3, 8, 3, 7, 1, 3, 3, 7, 6]  \n",
       "98      [2, 1, 1, 0, 4, 0, 0, 2, 3, 1, 0, 0, 1, 0, 5]  \n",
       "99      [2, 5, 5, 0, 2, 4, 2, 4, 4, 2, 3, 3, 6, 3, 4]  \n",
       "\n",
       "[100 rows x 8 columns]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def sample_from_data(\n",
    "    group_avgs : pd.DataFrame,\n",
    "    n_train : int,\n",
    "    n_test : int\n",
    ") -> tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    training = pd.DataFrame()\n",
    "    testing = pd.DataFrame()\n",
    "\n",
    "    for combo in group_avgs.columns:\n",
    "        cell_train = []\n",
    "        cell_test = []\n",
    "        for cell_data in group_avgs[combo].values:\n",
    "            train_idx = np.random.choice(len(cell_data), n_train, replace=False)\n",
    "            test_idx = np.random.choice(\n",
    "                len(np.delete(cell_data, train_idx)), n_test, replace=False\n",
    "            )\n",
    "            cell_train.append(cell_data[train_idx])\n",
    "            cell_test.append(cell_data[test_idx])\n",
    "        training[combo] = cell_train\n",
    "        testing[combo] = cell_test\n",
    "    return training, testing\n",
    "\n",
    "training, testing = sample_from_data(group_avgs, n_train=15, n_test=0)\n",
    "training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def sd(\n",
    "    group_avgs,\n",
    "    n_iter : int,\n",
    "    n_samples : int,\n",
    "    n_folds : int = 5,\n",
    "    show_progress : bool = False\n",
    "):\n",
    "    \"\"\"\n",
    "    Method for performing shattering dimensionality analysis for a group of \n",
    "    cells. Shattering dimensionality is defined as the average decoding accuracy\n",
    "    across all balanced dichotomies.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    group_avgs : pd.DataFrame\n",
    "        Data for averaged neuron firing rates across all combinations of task\n",
    "        variables. Each row represents a single neuron, and columns correspond \n",
    "        to different groupings of task variables. The DataFrame is generated by\n",
    "        the `construct_regressors` method.\n",
    "    n_iter : int\n",
    "        Number of iterations of bootstrap re-sampling to perform.\n",
    "    n_samples : int\n",
    "        Number of trials of each condition to sample.\n",
    "    n_folds : int\n",
    "        Number of folds to use in cross-validation.\n",
    "    show_progress : bool\n",
    "        Whether to print the training progress.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    np.array\n",
    "        TO DO\n",
    "    np.array\n",
    "\n",
    "    \"\"\"\n",
    "    _, pos_set, neg_set = define_dichotomies()\n",
    "    n_pairs = pos_set.shape[0]\n",
    "    n_folds = 5\n",
    "\n",
    "    # Matrices for storing performance metrics\n",
    "    perf = np.full((n_pairs, n_iter), np.nan)\n",
    "    boot = np.full((n_pairs, n_iter), np.nan)\n",
    "\n",
    "    # Iterate through all dichotomies\n",
    "    for i, (g1, g2) in enumerate(zip(pos_set, neg_set)):\n",
    "        # Resample to prevent trial-level bias\n",
    "        for j in range(n_iter):\n",
    "            training, testing = sample_from_data(\n",
    "                group_avgs,\n",
    "                n_train=n_samples,\n",
    "                n_test=0\n",
    "            )\n",
    "            train, train_labels, _, _ = prep_regressors(\n",
    "                training, testing, g1, g2\n",
    "            )\n",
    "            \n",
    "            # Normalize data and remove empty values\n",
    "            scaler = StandardScaler()\n",
    "            train_scaled = scaler.fit_transform(train)\n",
    "            train_scaled = train_scaled[:, ~np.isnan(train_scaled).any(axis=0)]\n",
    "\n",
    "            # Fit linear SVM\n",
    "            decoder = LogisticRegression(max_iter=1000, solver=\"liblinear\")\n",
    "            y_hat = cross_val_predict(decoder, train_scaled, train_labels, cv=n_folds)\n",
    "            perf[i, j] = accuracy_score(train_labels, y_hat)\n",
    "\n",
    "            # Compute null distribution\n",
    "            shuffled_labels = shuffle(train_labels)\n",
    "            y_hat_null = cross_val_predict(decoder, train_scaled, shuffled_labels, cv=n_folds)\n",
    "            boot[i, j] = accuracy_score(shuffled_labels, y_hat_null)\n",
    "        if show_progress:\n",
    "            print(f\"Finished dichotomy {i}: {g1}, {g2}\")\n",
    "    return perf.flatten(), boot.flatten()\n",
    "\n",
    "# perf, boot, n_cells = sd(group_avgs, 1, 15, show_progress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def swap_pairs(column):\n",
    "    \"\"\"\n",
    "    Helper function for constructing geometric null distribution by swapping\n",
    "    pairs of neuron responses in each task condition.\n",
    "    \"\"\"\n",
    "    perm_idx = np.random.permutation(len(column))\n",
    "    for i in range(0, len(column), 2):\n",
    "        if i+1 < len(column):  # Make sure we have a pair to swap\n",
    "            column.iloc[i], column.iloc[i+1] = column.iloc[perm_idx[i]], column.iloc[perm_idx[i+1]]\n",
    "    return column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Bonnie\\AppData\\Local\\Temp\\ipykernel_10904\\753584504.py:1: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  group_avgs.applymap(np.mean)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context_1_reward_5_response_0</th>\n",
       "      <th>context_1_reward_5_response_1</th>\n",
       "      <th>context_1_reward_25_response_0</th>\n",
       "      <th>context_1_reward_25_response_1</th>\n",
       "      <th>context_2_reward_5_response_0</th>\n",
       "      <th>context_2_reward_5_response_1</th>\n",
       "      <th>context_2_reward_25_response_0</th>\n",
       "      <th>context_2_reward_25_response_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.531250</td>\n",
       "      <td>0.562500</td>\n",
       "      <td>0.304348</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>5.571429</td>\n",
       "      <td>1.511628</td>\n",
       "      <td>0.129032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.277778</td>\n",
       "      <td>0.263158</td>\n",
       "      <td>2.176471</td>\n",
       "      <td>1.137931</td>\n",
       "      <td>5.800000</td>\n",
       "      <td>0.340426</td>\n",
       "      <td>1.348837</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.055556</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>0.478261</td>\n",
       "      <td>3.081081</td>\n",
       "      <td>1.194444</td>\n",
       "      <td>3.106383</td>\n",
       "      <td>2.744186</td>\n",
       "      <td>2.612903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.593750</td>\n",
       "      <td>0.394737</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>1.655172</td>\n",
       "      <td>0.361111</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>1.023256</td>\n",
       "      <td>0.741935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.218750</td>\n",
       "      <td>4.437500</td>\n",
       "      <td>3.652174</td>\n",
       "      <td>1.172414</td>\n",
       "      <td>3.266667</td>\n",
       "      <td>0.212766</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>1.967742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>1.250000</td>\n",
       "      <td>4.437500</td>\n",
       "      <td>0.352941</td>\n",
       "      <td>3.081081</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.619048</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>8.366667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>2.305556</td>\n",
       "      <td>1.473684</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>5.103448</td>\n",
       "      <td>1.133333</td>\n",
       "      <td>8.523810</td>\n",
       "      <td>1.348837</td>\n",
       "      <td>1.967742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.968750</td>\n",
       "      <td>7.250000</td>\n",
       "      <td>0.970588</td>\n",
       "      <td>1.724138</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>5.476190</td>\n",
       "      <td>12.360000</td>\n",
       "      <td>3.566667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>7.593750</td>\n",
       "      <td>1.710526</td>\n",
       "      <td>3.652174</td>\n",
       "      <td>4.482759</td>\n",
       "      <td>5.800000</td>\n",
       "      <td>1.571429</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>1.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>3.718750</td>\n",
       "      <td>0.562500</td>\n",
       "      <td>1.043478</td>\n",
       "      <td>0.864865</td>\n",
       "      <td>1.805556</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>2.709677</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    context_1_reward_5_response_0  context_1_reward_5_response_1  \\\n",
       "0                        0.531250                       0.562500   \n",
       "1                        0.277778                       0.263158   \n",
       "2                        2.055556                       0.687500   \n",
       "3                        7.593750                       0.394737   \n",
       "4                        0.218750                       4.437500   \n",
       "..                            ...                            ...   \n",
       "95                       1.250000                       4.437500   \n",
       "96                       2.305556                       1.473684   \n",
       "97                       0.968750                       7.250000   \n",
       "98                       7.593750                       1.710526   \n",
       "99                       3.718750                       0.562500   \n",
       "\n",
       "    context_1_reward_25_response_0  context_1_reward_25_response_1  \\\n",
       "0                         0.304348                        0.000000   \n",
       "1                         2.176471                        1.137931   \n",
       "2                         0.478261                        3.081081   \n",
       "3                         0.764706                        1.655172   \n",
       "4                         3.652174                        1.172414   \n",
       "..                             ...                             ...   \n",
       "95                        0.352941                        3.081081   \n",
       "96                        0.956522                        5.103448   \n",
       "97                        0.970588                        1.724138   \n",
       "98                        3.652174                        4.482759   \n",
       "99                        1.043478                        0.864865   \n",
       "\n",
       "    context_2_reward_5_response_0  context_2_reward_5_response_1  \\\n",
       "0                        0.500000                       5.571429   \n",
       "1                        5.800000                       0.340426   \n",
       "2                        1.194444                       3.106383   \n",
       "3                        0.361111                       0.571429   \n",
       "4                        3.266667                       0.212766   \n",
       "..                            ...                            ...   \n",
       "95                       0.466667                       0.619048   \n",
       "96                       1.133333                       8.523810   \n",
       "97                       0.733333                       5.476190   \n",
       "98                       5.800000                       1.571429   \n",
       "99                       1.805556                       0.428571   \n",
       "\n",
       "    context_2_reward_25_response_0  context_2_reward_25_response_1  \n",
       "0                         1.511628                        0.129032  \n",
       "1                         1.348837                        0.333333  \n",
       "2                         2.744186                        2.612903  \n",
       "3                         1.023256                        0.741935  \n",
       "4                         1.200000                        1.967742  \n",
       "..                             ...                             ...  \n",
       "95                        2.000000                        8.366667  \n",
       "96                        1.348837                        1.967742  \n",
       "97                       12.360000                        3.566667  \n",
       "98                        0.200000                        1.500000  \n",
       "99                        1.600000                        2.709677  \n",
       "\n",
       "[100 rows x 8 columns]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "group_avgs.applymap(np.mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_dist(v):\n",
    "    \"\"\"\n",
    "    Compute the average cosine distance between rows in a matrix.\n",
    "\n",
    "    Parameters:\n",
    "        v (ndarray): Matrix where each row is a vector.\n",
    "\n",
    "    Returns:\n",
    "        dist (float): The average cosine distance.\n",
    "    \"\"\"\n",
    "    v_normalized = np.array([row / np.linalg.norm(row) for row in v])\n",
    "    dist = np.mean(1 - pdist(v_normalized, 'cosine'))\n",
    "    return dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.99992231],\n",
       "       [0.99990361],\n",
       "       [0.9999547 ],\n",
       "       [0.99997749],\n",
       "       [0.99995591],\n",
       "       [0.99993172],\n",
       "       [0.9999335 ],\n",
       "       [0.99995469],\n",
       "       [0.99994065],\n",
       "       [0.99988637],\n",
       "       [0.9999961 ],\n",
       "       [0.99990433],\n",
       "       [0.999997  ],\n",
       "       [0.99997877],\n",
       "       [0.99997041],\n",
       "       [0.99993924],\n",
       "       [0.99997771],\n",
       "       [0.99997212],\n",
       "       [0.99996452],\n",
       "       [0.99998222],\n",
       "       [0.99997538],\n",
       "       [0.99996678],\n",
       "       [0.99993463],\n",
       "       [0.99997783],\n",
       "       [0.9999388 ],\n",
       "       [0.99996848],\n",
       "       [0.9999454 ],\n",
       "       [0.99996683],\n",
       "       [0.99993779],\n",
       "       [0.99996302],\n",
       "       [0.99995666],\n",
       "       [0.99997626],\n",
       "       [0.99997703],\n",
       "       [0.99994475],\n",
       "       [0.99998112]])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def ps(\n",
    "    group_avgs : pd.DataFrame,\n",
    "    n_iter : int = 1,\n",
    "    for_boot : bool = False,\n",
    "    show_progress : bool = False\n",
    "):\n",
    "    \"\"\"\n",
    "    Method for performing parallelism score analysis for a group of cells.\n",
    "    \"\"\"\n",
    "    _, pos_set, neg_set = F.define_dichotomies()\n",
    "    dist = [[None for _ in range(n_iter)] for _ in range(len(pos_set))]\n",
    "\n",
    "    # Iterate through all dichotomies\n",
    "    for i, (g1, g2) in enumerate(zip(pos_set, neg_set)):\n",
    "        g2 = list(itertools.permutations(g2))\n",
    "        for j in range(n_iter):\n",
    "            # Geometric null construction\n",
    "            if for_boot:\n",
    "                group_avgs = group_avgs.apply(swap_pairs)\n",
    "            \n",
    "            # Recompute mean after every geometric null rotation\n",
    "            mu = group_avgs.map(np.mean)\n",
    "            mu = mu.values\n",
    "            \n",
    "            # Compute parallelism over all possible pairings of dichotomy vectors\n",
    "            cosine_pairs = []\n",
    "            for perm in g2:\n",
    "                u = mu[:, g1]\n",
    "                v = mu[:, perm]\n",
    "                cosine_pairs.append(cosine_similarity(u, v))\n",
    "            dist[i][j] = np.max(cosine_pairs)\n",
    "        if show_progress:\n",
    "            print(f\"PS computed for dichotomy {i} of {len(pos_set)}.\")\n",
    "    return np.array(dist)\n",
    "\n",
    "ps(group_avgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Run geometric analyses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running analyses for inference absent trials over 15 samples...\n",
      "Running analyses for inference present trials over 15 samples...\n",
      "Analyses complete for area HPC. Time: 27.215128 seconds.\n",
      "Running analyses for inference absent trials over 15 samples...\n",
      "Running analyses for inference present trials over 15 samples...\n",
      "Analyses complete for area vmPFC. Time: 40.717999 seconds.\n",
      "Running analyses for inference absent trials over 15 samples...\n",
      "Running analyses for inference present trials over 15 samples...\n",
      "Analyses complete for area AMY. Time: 16.582142 seconds.\n",
      "Running analyses for inference absent trials over 15 samples...\n",
      "Running analyses for inference present trials over 15 samples...\n",
      "Analyses complete for area dACC. Time: 23.982195 seconds.\n",
      "Running analyses for inference absent trials over 15 samples...\n",
      "Running analyses for inference present trials over 15 samples...\n",
      "Analyses complete for area preSMA. Time: 28.551656 seconds.\n",
      "Running analyses for inference absent trials over 10 samples...\n",
      "Running analyses for inference present trials over 10 samples...\n",
      "Analyses complete for area VTC. Time: 10.699968 seconds.\n"
     ]
    }
   ],
   "source": [
    "def run_geometric_analysis(\n",
    "    metric : str,\n",
    "    neu_data : pd.DataFrame,\n",
    "    beh_data : pd.DataFrame,\n",
    "    task_data : pd.DataFrame,\n",
    "    n_resample : int = 5,\n",
    "    n_perm_inner : int = 1,\n",
    "    n_iter_boot : int = 1000,\n",
    "    n_samples : list[int] = [15, 15, 15, 15, 15, 10],\n",
    "    show_progress : bool = False\n",
    "):\n",
    "    # Step 1: Compute session-level inference performance\n",
    "    sess = F.split_sessions(neu_data, beh_data, task_data)\n",
    "    inf_absent, inf_present = sess[\"absent\"], sess[\"present\"]\n",
    "    absent_idx, present_idx = sess[\"absent_idx\"], sess[\"present_idx\"]\n",
    "    idx_sets = [absent_idx, present_idx]\n",
    "    session_names = sess[\"sessions\"]\n",
    "    all_sessions = neu_data[\"sessionID\"].to_list()\n",
    "\n",
    "    # Step 2: Aggregate neurons by area\n",
    "    cell_area_groups = F.define_cell_area_groups(neu_data)\n",
    "\n",
    "    # Step 3: Run geometric analyses\n",
    "    # Initialize containers to restore results for both conditions\n",
    "    # \n",
    "    data_ = [\n",
    "        [[] for _ in range(len(cell_area_groups))],\n",
    "        [[] for _ in range(len(cell_area_groups))]\n",
    "    ]\n",
    "    data_boot = [\n",
    "        [[] for _ in range(len(cell_area_groups))],\n",
    "        [[] for _ in range(len(cell_area_groups))]\n",
    "    ]\n",
    "\n",
    "    for i, (area_name, area_idx) in enumerate(cell_area_groups.items()):\n",
    "        start_time = time.time()\n",
    "        for j, idx_set in enumerate(idx_sets):\n",
    "            if show_progress:\n",
    "                curr_set = \"inference absent\" if j == 0 else \"inference present\"\n",
    "                print(f\"Running analyses for {curr_set} trials over {n_samples[i]} samples...\")\n",
    "            curr_idx = np.intersect1d(area_idx, idx_set)\n",
    "            for _ in range(n_resample):\n",
    "                group_avgs = construct_regressors(neu_data, n_samples[i], curr_idx)\n",
    "                if metric == \"sd\":\n",
    "                    t_1, t_2 = F.sd(group_avgs, n_iter_boot, n_samples[i], show_progress=show_progress)\n",
    "                elif metric == \"ccgp\":\n",
    "                    t_1 = F.ccgp(group_avgs, n_perm_inner, n_samples[i], show_progress=show_progress)\n",
    "                    t_2 = ccgp(group_avgs, n_iter_boot, n_samples[i], for_boot=True, show_progress=show_progress)\n",
    "                elif metric == \"ps\":\n",
    "                    t_1 = ps(group_avgs, n_perm_inner, show_progress=show_progress)\n",
    "                    t_2 = ps(group_avgs, n_iter_boot, for_boot=True, show_progress=show_progress)\n",
    "                data_[j][i].append(t_1)\n",
    "                data_[j][i].append(t_2)\n",
    "        end_time = time.time()\n",
    "        if show_progress:\n",
    "            print(f\"Analyses complete for area {area_name}. Time: {end_time - start_time:.6f} seconds.\")\n",
    "    return data_, data_boot\n",
    "\n",
    "# sd_, sd_boot = run_geometric_analysis(neu_data, beh_data, task_data, show_progress=True)\n",
    "ps_, ps_boot = run_geometric_analysis(\"ps\", neu_data, beh_data, task_data, show_progress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[array([0.51938202, 0.50646067, 0.49438202, 0.50926966, 0.5005618 ,\n",
       "         0.50730337, 0.51685393, 0.51207865, 0.50449438, 0.50365169,\n",
       "         0.50449438, 0.4997191 , 0.50421348, 0.51067416, 0.50393258,\n",
       "         0.51235955, 0.48820225, 0.49073034, 0.50561798, 0.48370787,\n",
       "         0.52303371, 0.50393258, 0.50561798, 0.4988764 , 0.50814607,\n",
       "         0.50646067, 0.49101124, 0.49550562, 0.51011236, 0.51264045,\n",
       "         0.49382022, 0.49859551, 0.52359551, 0.49213483, 0.51657303]),\n",
       "  array([0.50275229, 0.51123853, 0.49885321, 0.51261468, 0.4912844 ,\n",
       "         0.5059633 , 0.50619266, 0.50986239, 0.50206422, 0.5       ,\n",
       "         0.5       , 0.51238532, 0.50779817, 0.4912844 , 0.51077982,\n",
       "         0.5       , 0.50229358, 0.49059633, 0.48142202, 0.48211009,\n",
       "         0.50183486, 0.4940367 , 0.50275229, 0.50573394, 0.49793578,\n",
       "         0.49678899, 0.50733945, 0.5059633 , 0.5       , 0.49472477,\n",
       "         0.48899083, 0.49610092, 0.50504587, 0.50481651, 0.48027523]),\n",
       "  array([0.49652778, 0.50347222, 0.46944444, 0.50555556, 0.51319444,\n",
       "         0.4875    , 0.49722222, 0.51597222, 0.49444444, 0.52013889,\n",
       "         0.46666667, 0.53055556, 0.48263889, 0.49305556, 0.48958333,\n",
       "         0.49791667, 0.52291667, 0.50138889, 0.50763889, 0.50138889,\n",
       "         0.53125   , 0.50277778, 0.46666667, 0.49305556, 0.52013889,\n",
       "         0.53472222, 0.5375    , 0.52638889, 0.48055556, 0.52430556,\n",
       "         0.49305556, 0.49861111, 0.4875    , 0.51944444, 0.50902778]),\n",
       "  array([0.52715517, 0.52241379, 0.49655172, 0.51034483, 0.5262931 ,\n",
       "         0.4987069 , 0.51163793, 0.49956897, 0.47241379, 0.51681034,\n",
       "         0.51767241, 0.51594828, 0.50517241, 0.48534483, 0.51681034,\n",
       "         0.49784483, 0.49310345, 0.51034483, 0.49956897, 0.46896552,\n",
       "         0.49051724, 0.48189655, 0.48706897, 0.50387931, 0.50172414,\n",
       "         0.50344828, 0.5       , 0.47758621, 0.51034483, 0.48318966,\n",
       "         0.49568966, 0.49051724, 0.49784483, 0.50991379, 0.49913793]),\n",
       "  array([0.49494382, 0.48932584, 0.5252809 , 0.51179775, 0.51938202,\n",
       "         0.48792135, 0.50561798, 0.48539326, 0.50140449, 0.48848315,\n",
       "         0.4988764 , 0.47808989, 0.49073034, 0.48679775, 0.50280899,\n",
       "         0.48904494, 0.51039326, 0.50393258, 0.49634831, 0.5241573 ,\n",
       "         0.49129213, 0.49803371, 0.5       , 0.50955056, 0.4988764 ,\n",
       "         0.4997191 , 0.5002809 , 0.50730337, 0.49382022, 0.51067416,\n",
       "         0.50702247, 0.50280899, 0.4991573 , 0.4991573 , 0.5002809 ]),\n",
       "  array([0.49886364, 0.5125    , 0.46477273, 0.47727273, 0.49204545,\n",
       "         0.50795455, 0.48068182, 0.50909091, 0.49659091, 0.51477273,\n",
       "         0.4875    , 0.51022727, 0.52840909, 0.4875    , 0.50568182,\n",
       "         0.48409091, 0.51022727, 0.5       , 0.51136364, 0.48636364,\n",
       "         0.49318182, 0.48636364, 0.51136364, 0.49886364, 0.47613636,\n",
       "         0.47727273, 0.46818182, 0.48068182, 0.49204545, 0.50227273,\n",
       "         0.48863636, 0.47727273, 0.49772727, 0.47727273, 0.49545455])],\n",
       " [array([0.50722656, 0.50488281, 0.49824219, 0.48066406, 0.50214844,\n",
       "         0.49296875, 0.48828125, 0.50039062, 0.49550781, 0.49277344,\n",
       "         0.50644531, 0.49960938, 0.49609375, 0.49628906, 0.48632812,\n",
       "         0.49121094, 0.503125  , 0.49179688, 0.50039062, 0.49511719,\n",
       "         0.49082031, 0.50761719, 0.5046875 , 0.49589844, 0.49589844,\n",
       "         0.50429687, 0.49003906, 0.5046875 , 0.50195312, 0.5046875 ,\n",
       "         0.50976562, 0.49863281, 0.50507813, 0.51992187, 0.51425781]),\n",
       "  array([0.49506303, 0.49758403, 0.49254202, 0.51460084, 0.49432773,\n",
       "         0.50630252, 0.49821429, 0.49779412, 0.5052521 , 0.50976891,\n",
       "         0.50105042, 0.48529412, 0.50441176, 0.50483193, 0.50577731,\n",
       "         0.50084034, 0.4987395 , 0.5092437 , 0.50010504, 0.50105042,\n",
       "         0.49779412, 0.49905462, 0.50231092, 0.50136555, 0.49422269,\n",
       "         0.50220588, 0.49978992, 0.49380252, 0.48476891, 0.49443277,\n",
       "         0.49411765, 0.5032563 , 0.49590336, 0.49926471, 0.49464286]),\n",
       "  array([0.48977273, 0.50265152, 0.50643939, 0.48181818, 0.51136364,\n",
       "         0.47916667, 0.5094697 , 0.51628788, 0.50227273, 0.49469697,\n",
       "         0.50681818, 0.49886364, 0.50492424, 0.50984848, 0.5030303 ,\n",
       "         0.50416667, 0.49431818, 0.48825758, 0.48068182, 0.49204545,\n",
       "         0.50984848, 0.49090909, 0.49318182, 0.50492424, 0.50568182,\n",
       "         0.51590909, 0.48560606, 0.50681818, 0.49810606, 0.5030303 ,\n",
       "         0.51477273, 0.50530303, 0.5030303 , 0.5125    , 0.50492424]),\n",
       "  array([0.48645833, 0.4875    , 0.48697917, 0.51041667, 0.49166667,\n",
       "         0.4953125 , 0.5015625 , 0.49947917, 0.51145833, 0.48541667,\n",
       "         0.51927083, 0.48333333, 0.49635417, 0.4859375 , 0.51302083,\n",
       "         0.51302083, 0.509375  , 0.51822917, 0.49322917, 0.5140625 ,\n",
       "         0.5125    , 0.5265625 , 0.503125  , 0.50572917, 0.50625   ,\n",
       "         0.496875  , 0.48645833, 0.51770833, 0.4875    , 0.52083333,\n",
       "         0.51770833, 0.45885417, 0.49739583, 0.51510417, 0.50572917]),\n",
       "  array([0.49840909, 0.50227273, 0.50090909, 0.50295455, 0.51386364,\n",
       "         0.50204545, 0.49340909, 0.50886364, 0.49      , 0.51181818,\n",
       "         0.50045455, 0.50977273, 0.49522727, 0.48181818, 0.50704545,\n",
       "         0.51977273, 0.50113636, 0.51659091, 0.50636364, 0.49568182,\n",
       "         0.50045455, 0.49954545, 0.50704545, 0.52363636, 0.50090909,\n",
       "         0.49772727, 0.48477273, 0.4925    , 0.52340909, 0.51545455,\n",
       "         0.51522727, 0.49931818, 0.50136364, 0.48477273, 0.51227273]),\n",
       "  array([0.48621795, 0.49070513, 0.52115385, 0.4900641 , 0.49807692,\n",
       "         0.50352564, 0.51923077, 0.50160256, 0.50384615, 0.50865385,\n",
       "         0.48974359, 0.51378205, 0.50641026, 0.50064103, 0.52660256,\n",
       "         0.52275641, 0.51730769, 0.51987179, 0.5025641 , 0.50352564,\n",
       "         0.48814103, 0.49679487, 0.50224359, 0.48782051, 0.50320513,\n",
       "         0.49615385, 0.49647436, 0.50641026, 0.50320513, 0.51858974,\n",
       "         0.49903846, 0.51089744, 0.48974359, 0.5025641 , 0.51217949])]]"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def average_sample_data(sample_data : list):\n",
    "    # TO DO: returns a number for each dichotomy for each brain area etc.\n",
    "    avg_data = []\n",
    "    for session_type in sample_data:\n",
    "        type_data = []\n",
    "        for area_data in session_type:\n",
    "            type_data.append(np.mean(np.array(area_data), axis=0))\n",
    "        avg_data.append(type_data)\n",
    "    return avg_data\n",
    "\n",
    "avg_data = average_sample_data(sd_)\n",
    "avg_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_swarm(\n",
    "    ax, \n",
    "    metric : str,\n",
    "    data : list, \n",
    "    null_dist : list = None,\n",
    "    idx_special : list = [0, 9, 20, 23, 28],\n",
    "    idx_labels : list = [\"Context\", \"Outcome\", \"Response\", \"Stim pair\", \"Parity\"],\n",
    "    xlabels_special : list = [],\n",
    "    connection_map : list = None,\n",
    "    clrs_list : list = None\n",
    "):\n",
    "    \"\"\"\n",
    "    Swarm plot method for results of geometric analysis.\n",
    "    \"\"\"\n",
    "    if connection_map is None:\n",
    "        connection_map = [0, 1] * (len(data) // 2)\n",
    "    if clrs_list is None:\n",
    "        clrs_list = sns.color_palette(\"Set1\", len(idx_special))\n",
    "\n",
    "    # Plot null distribution as filled rectangles\n",
    "    if null_dist is not None:\n",
    "        offset = 0.35\n",
    "        for i, null_data in enumerate(null_dist):\n",
    "            lims = np.percentile(null_data, [5, 95])\n",
    "            ax.fill(\n",
    "                 [i - offset, i + offset, i + offset, i - offset],\n",
    "                 [lims[0], lims[0], lims[1], lims[1]], color=\"gray\", alpha=0.2\n",
    "            )\n",
    "    \n",
    "    # Set plot attributes based on metric\n",
    "    facecolors = \"white\" if metric == \"sd\" else \"gray\"\n",
    "    marker = \"^\" if metric == \"ps\" else \"o\"\n",
    "    linewidth = 2 if metric ==\"ps\" else 4\n",
    "\n",
    "    # Plot non-special points\n",
    "    to_plot = []\n",
    "    marker_size = 80\n",
    "    for i in range(len(data)):\n",
    "        if idx_special:\n",
    "            to_plot.append(data[i][idx_special])\n",
    "            data[i] = np.delete(data[i], idx_special)      \n",
    "        # TO DO: jitter?\n",
    "        ax.scatter(\n",
    "            np.full(len(data[i]), i), data[i],\n",
    "            s=marker_size, marker=marker,\n",
    "            edgecolors=\"gray\", facecolors=facecolors,\n",
    "            linewidth=linewidth, alpha=0.7\n",
    "        )\n",
    "    \n",
    "    # Plot special points and connections\n",
    "    for i in range(len(data)):\n",
    "        for j in range(len(idx_special)):\n",
    "            if i == 1:\n",
    "                ax.plot(\n",
    "                    [i-1, i], (to_plot[i-1][j], to_plot[i][j]),\n",
    "                    linewidth=2.5, color=clrs_list[j]\n",
    "                )\n",
    "            ax.scatter(\n",
    "                i, to_plot[i][j],\n",
    "                s=marker_size+40, marker=marker,\n",
    "                edgecolors=clrs_list[j], facecolors=facecolors,\n",
    "                linewidth=linewidth, \n",
    "                label=(idx_labels[j] if i == 1 else None)\n",
    "            )\n",
    "    # ax.legend(loc=\"center right\", bbox_to_anchor=(1, 1))\n",
    "    ax.set_xticks([0, 1])\n",
    "    ax.set_xticklabels(xlabels_special)\n",
    "    ax.legend()\n",
    "\n",
    "# TO DO: \"by something\"\n",
    "def construct_swarm_for_area(\n",
    "    title : str,\n",
    "    metric : str,\n",
    "    data,\n",
    "    null_dist,\n",
    "    y_min : float = 0.4,\n",
    "    y_max : float = 0.8\n",
    "):\n",
    "    \"\"\"\n",
    "    Make a swarm plot for inference present vs. absent \n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(figsize=(4, 4))\n",
    "    plot_swarm(\n",
    "        ax, metric=metric, \n",
    "        data=data, \n",
    "        null_dist=null_dist,\n",
    "        xlabels_special=[\"Absent\", \"Present\"]\n",
    "    )\n",
    "    if metric == \"sd\":\n",
    "        ylabel = \"Decoding accuracy (SD)\"\n",
    "    plt.title(title)\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.ylim([y_min, y_max])\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "# agg_sd_ = average_sample_data(sd_)\n",
    "# agg_sd_boot = average_sample_data(sd_boot)\n",
    "# construct_swarm_for_area(title=\"title\", metric=\"sd\", data=agg_sd_, null_dist=agg_sd_boot)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "invalid index to scalar variable.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[113], line 22\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, area_name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(cell_area_groups\u001b[38;5;241m.\u001b[39mkeys()):\n\u001b[0;32m     13\u001b[0m         construct_swarm_for_area(\n\u001b[0;32m     14\u001b[0m             title\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00marea_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     15\u001b[0m             metric\u001b[38;5;241m=\u001b[39mmetric,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     19\u001b[0m             y_max\u001b[38;5;241m=\u001b[39my_max\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m0.02\u001b[39m\n\u001b[0;32m     20\u001b[0m         )\n\u001b[1;32m---> 22\u001b[0m plot_all_swarm(neu_data, metric\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mps\u001b[39m\u001b[38;5;124m\"\u001b[39m, data\u001b[38;5;241m=\u001b[39mps_, null_dist\u001b[38;5;241m=\u001b[39mps_boot)\n",
      "Cell \u001b[1;32mIn[113], line 13\u001b[0m, in \u001b[0;36mplot_all_swarm\u001b[1;34m(neu_data, metric, data, null_dist)\u001b[0m\n\u001b[0;32m     11\u001b[0m cell_area_groups \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mdefine_cell_area_groups(neu_data)\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, area_name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(cell_area_groups\u001b[38;5;241m.\u001b[39mkeys()):\n\u001b[1;32m---> 13\u001b[0m     construct_swarm_for_area(\n\u001b[0;32m     14\u001b[0m         title\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00marea_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     15\u001b[0m         metric\u001b[38;5;241m=\u001b[39mmetric,\n\u001b[0;32m     16\u001b[0m         data\u001b[38;5;241m=\u001b[39m[data[\u001b[38;5;241m0\u001b[39m][i], data[\u001b[38;5;241m1\u001b[39m][i]],\n\u001b[0;32m     17\u001b[0m         null_dist\u001b[38;5;241m=\u001b[39m[null_dist[\u001b[38;5;241m0\u001b[39m][i], null_dist[\u001b[38;5;241m1\u001b[39m][i]],\n\u001b[0;32m     18\u001b[0m         y_min\u001b[38;5;241m=\u001b[39my_min\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m0.02\u001b[39m,\n\u001b[0;32m     19\u001b[0m         y_max\u001b[38;5;241m=\u001b[39my_max\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m0.02\u001b[39m\n\u001b[0;32m     20\u001b[0m     )\n",
      "Cell \u001b[1;32mIn[112], line 83\u001b[0m, in \u001b[0;36mconstruct_swarm_for_area\u001b[1;34m(title, metric, data, null_dist, y_min, y_max)\u001b[0m\n\u001b[0;32m     79\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     80\u001b[0m \u001b[38;5;124;03mMake a swarm plot for inference present vs. absent \u001b[39;00m\n\u001b[0;32m     81\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     82\u001b[0m fig, ax \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39msubplots(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m4\u001b[39m))\n\u001b[1;32m---> 83\u001b[0m plot_swarm(\n\u001b[0;32m     84\u001b[0m     ax, metric\u001b[38;5;241m=\u001b[39mmetric, \n\u001b[0;32m     85\u001b[0m     data\u001b[38;5;241m=\u001b[39mdata, \n\u001b[0;32m     86\u001b[0m     null_dist\u001b[38;5;241m=\u001b[39mnull_dist,\n\u001b[0;32m     87\u001b[0m     xlabels_special\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAbsent\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPresent\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m     88\u001b[0m )\n\u001b[0;32m     89\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m metric \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msd\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m     90\u001b[0m     ylabel \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDecoding accuracy (SD)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "Cell \u001b[1;32mIn[112], line 40\u001b[0m, in \u001b[0;36mplot_swarm\u001b[1;34m(ax, metric, data, null_dist, idx_special, idx_labels, xlabels_special, connection_map, clrs_list)\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(data)):\n\u001b[0;32m     39\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m idx_special:\n\u001b[1;32m---> 40\u001b[0m         to_plot\u001b[38;5;241m.\u001b[39mappend(data[i][idx_special])\n\u001b[0;32m     41\u001b[0m         data[i] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdelete(data[i], idx_special)      \n\u001b[0;32m     42\u001b[0m     \u001b[38;5;66;03m# TO DO: jitter?\u001b[39;00m\n",
      "\u001b[1;31mIndexError\u001b[0m: invalid index to scalar variable."
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAFfCAYAAABJKqdvAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAcmElEQVR4nO3db2zV5f3/8deRtqcW2yNS6QEpUJyhEDSBEgosXd2CpfUfbCTyRztmHJMZrcUsCnoDogktzDj3TYFuXbM/iQGVWsMNR6hDGkJPwZIWO4okSpFOOGIRPqcRKYVevxum5+fhnJZ29LNCr+cjOTd6netzer3H9tzZOZ+hxxhjBACwxi1DfQAAwP8W4QcAyxB+ALAM4QcAyxB+ALAM4QcAyxB+ALBM3FAfYCh0d3fr1KlTSk5OlsfjGerjAMB1M8aoo6ND48aN0y239P2e3srwnzp1Sunp6UN9DAAYdG1tbRo/fnyfe6wMf3JysqTv/wVKSUkZ4tMAwPULhUJKT08P960vVoa/5+OdlJQUwg9gWOnPx9d8uQsAliH8AGAZwg8AliH8AGAZwg8AliH8AGAZwg8AliH8AGAZwg8AliH8AGAZwg8AliH8AGAZwg8AliH8AGAZwg8AliH8AGAZwg8AliH8AGAZwg8AliH8AGAZwg8AliH8AGAZwg8AliH8AGAZwg8AliH8AGAZwg8AliH8AGAZwg8AliH8AGAZwg8AliH8AGAZwg8AliH8AGAZwg8AliH8AGAZ18O/ZcsWZWRkKDExUVlZWdq3b1+f+2tra5WVlaXExERNnjxZ5eXlve7dvn27PB6PFi1aNMinBoDhy9Xwv/322youLtYrr7yixsZG5eTkqKCgQCdPnoy5v7W1VQ8++KBycnLU2Niol19+WUVFRaqqqora+8UXX+h3v/udcnJy3BwBAIYdjzHGuPXi2dnZmjlzprZu3Rpemzp1qhYtWqSSkpKo/S+99JJ27typo0ePhtdWrVqlw4cPKxAIhNeuXLmi3NxcPfnkk9q3b5/Onz+v999/v9dzdHZ2qrOzM/xzKBRSenq6HMdRSkrKdU4JAEMvFArJ5/P1q2uuveO/dOmSDh06pLy8vIj1vLw81dXVxbwmEAhE7V+wYIEaGhrU1dUVXnv11Vd155136qmnnurXWUpKSuTz+cKP9PT0AU4DAMOHa+Fvb2/XlStXlJaWFrGelpamYDAY85pgMBhz/+XLl9Xe3i5J2r9/vyorK1VRUdHvs6xdu1aO44QfbW1tA5wGAIaPOLd/gcfjifjZGBO1dq39PesdHR164oknVFFRodTU1H6fwev1yuv1DuDUADB8uRb+1NRUjRgxIurd/ZkzZ6Le1ffw+/0x98fFxWn06NE6cuSITpw4oUceeST8fHd3tyQpLi5Ox44d09133z3IkwDA8OLaRz0JCQnKyspSTU1NxHpNTY3mzZsX85q5c+dG7d+9e7dmzZql+Ph4ZWZmqrm5WU1NTeHHo48+qp/+9Kdqamris3sA6AdXP+p54YUXVFhYqFmzZmnu3Ln685//rJMnT2rVqlWSvv/s/csvv9Q//vEPSd/fwVNWVqYXXnhBK1euVCAQUGVlpbZt2yZJSkxM1PTp0yN+x+233y5JUesAgNhcDf+SJUt09uxZvfrqqzp9+rSmT5+uDz74QBMnTpQknT59OuKe/oyMDH3wwQdavXq1Nm/erHHjxun//u//tHjxYjePCQBWcfU+/hvVQO53BYCbwQ1xHz8A4MZE+AHAMoQfACxD+AHAMoQfACxD+AHAMoQfACxD+AHAMoQfACxD+AHAMoQfACxD+AHAMoQfACxD+AHAMoQfACxD+AHAMoQfACxD+AHAMoQfACxD+AHAMoQfACxD+AHAMoQfACxD+AHAMoQfACxD+AHAMoQfACxD+AHAMoQfACxD+AHAMoQfACxD+AHAMoQfACxD+AHAMoQfACxD+AHAMoQfACxD+AHAMoQfACxD+AHAMoQfACxD+AHAMoQfACxD+AHAMoQfACzjevi3bNmijIwMJSYmKisrS/v27etzf21trbKyspSYmKjJkyervLw84vmKigrl5ORo1KhRGjVqlObPn6+DBw+6OQIADCuuhv/tt99WcXGxXnnlFTU2NionJ0cFBQU6efJkzP2tra168MEHlZOTo8bGRr388ssqKipSVVVVeM/evXu1bNkyffTRRwoEApowYYLy8vL05ZdfujkKAAwbHmOMcevFs7OzNXPmTG3dujW8NnXqVC1atEglJSVR+1966SXt3LlTR48eDa+tWrVKhw8fViAQiPk7rly5olGjRqmsrEy//OUvY+7p7OxUZ2dn+OdQKKT09HQ5jqOUlJT/djwAuGGEQiH5fL5+dc21d/yXLl3SoUOHlJeXF7Gel5enurq6mNcEAoGo/QsWLFBDQ4O6urpiXnPhwgV1dXXpjjvu6PUsJSUl8vl84Ud6evoApwGA4cO18Le3t+vKlStKS0uLWE9LS1MwGIx5TTAYjLn/8uXLam9vj3nNmjVrdNddd2n+/Pm9nmXt2rVyHCf8aGtrG+A0ADB8xLn9CzweT8TPxpiotWvtj7UuSZs2bdK2bdu0d+9eJSYm9vqaXq9XXq93IMcGgGHLtfCnpqZqxIgRUe/uz5w5E/Wuvoff74+5Py4uTqNHj45Yf/3117VhwwZ9+OGHuu+++wb38AAwjLn2UU9CQoKysrJUU1MTsV5TU6N58+bFvGbu3LlR+3fv3q1Zs2YpPj4+vPb73/9er732mnbt2qVZs2YN/uEBYDgzLtq+fbuJj483lZWVpqWlxRQXF5uRI0eaEydOGGOMWbNmjSksLAzvP378uElKSjKrV682LS0tprKy0sTHx5sdO3aE92zcuNEkJCSYHTt2mNOnT4cfHR0d/T6X4zhGknEcZ/CGBYAhNJCuuRp+Y4zZvHmzmThxoklISDAzZ840tbW14edWrFhhcnNzI/bv3bvXzJgxwyQkJJhJkyaZrVu3Rjw/ceJEIynqsW7dun6fifADGG4G0jVX7+O/UQ3kflcAuBncEPfxAwBuTIQfACxD+AHAMoQfACxD+AHAMoQfACxD+AHAMoQfACxD+AHAMoQfACxD+AHAMoQfACxD+AHAMoQfACxD+AHAMoQfACxD+AHAMoQfACxD+AHAMoQfACxD+AHAMoQfACxD+AHAMoQfACxD+AHAMoQfACxD+AHAMoQfACxD+AHAMoQfACxD+AHAMoQfACxD+AHAMoQfACxD+AHAMoQfACxD+AHAMoQfACxD+AHAMoQfACxD+AHAMoQfACxD+AHAMoQfACxD+AHAMq6Hf8uWLcrIyFBiYqKysrK0b9++PvfX1tYqKytLiYmJmjx5ssrLy6P2VFVVadq0afJ6vZo2bZqqq6vdOj4ADDuuhv/tt99WcXGxXnnlFTU2NionJ0cFBQU6efJkzP2tra168MEHlZOTo8bGRr388ssqKipSVVVVeE8gENCSJUtUWFiow4cPq7CwUI899pgOHDjg5igAMGx4jDHGrRfPzs7WzJkztXXr1vDa1KlTtWjRIpWUlETtf+mll7Rz504dPXo0vLZq1SodPnxYgUBAkrRkyRKFQiH985//DO/Jz8/XqFGjtG3btpjn6OzsVGdnZ/jnUCik9PR0OY6jlJSU654TAIZaKBSSz+frV9dce8d/6dIlHTp0SHl5eRHreXl5qquri3lNIBCI2r9gwQI1NDSoq6urzz29vaYklZSUyOfzhR/p6en/zUgAMCy4Fv729nZduXJFaWlpEetpaWkKBoMxrwkGgzH3X758We3t7X3u6e01JWnt2rVyHCf8aGtr+29GAoBhIc7tX+DxeCJ+NsZErV1r/9XrA31Nr9crr9fb7zMDwHDm2jv+1NRUjRgxIuqd+JkzZ6Lesffw+/0x98fFxWn06NF97untNQEAkVwLf0JCgrKyslRTUxOxXlNTo3nz5sW8Zu7cuVH7d+/erVmzZik+Pr7PPb29JgDgKsZF27dvN/Hx8aaystK0tLSY4uJiM3LkSHPixAljjDFr1qwxhYWF4f3Hjx83SUlJZvXq1aalpcVUVlaa+Ph4s2PHjvCe/fv3mxEjRpjS0lJz9OhRU1paauLi4kx9fX2/z+U4jpFkHMcZvGEBYAgNpGuuht8YYzZv3mwmTpxoEhISzMyZM01tbW34uRUrVpjc3NyI/Xv37jUzZswwCQkJZtKkSWbr1q1Rr/nuu++aKVOmmPj4eJOZmWmqqqoGdCbCD2C4GUjXXL2P/0Y1kPtdAeBmcEPcxw8AuDERfgCwDOEHAMsQfgCwDOEHAMsQfgCwDOEHAMsQfgCwDOEHAMsQfgCwDOEHAMsQfgCwDOEHAMsQfgCwDOEHAMsQfgCwDOEHAMsQfgCwDOEHAMsQfgCwDOEHAMsQfgCwDOEHAMsQfgCwDOEHAMsQfgCwDOEHAMsQfgCwDOEHAMsQfgCwDOEHAMsQfgCwDOEHAMsQfgCwDOEHAMsQfgCwDOEHAMsQfgCwDOEHAMsQfgCwDOEHAMsQfgCwDOEHAMsQfgCwDOEHAMu4Gv5z586psLBQPp9PPp9PhYWFOn/+fJ/XGGO0fv16jRs3Trfeeqvuv/9+HTlyJPz8N998o+eee05TpkxRUlKSJkyYoKKiIjmO4+YoADBsuBr+5cuXq6mpSbt27dKuXbvU1NSkwsLCPq/ZtGmT3njjDZWVlenjjz+W3+/XAw88oI6ODknSqVOndOrUKb3++utqbm7W3/72N+3atUtPPfWUm6MAwPBhXNLS0mIkmfr6+vBaIBAwksynn34a85ru7m7j9/tNaWlpeO3ixYvG5/OZ8vLyXn/XO++8YxISEkxXV1fM5y9evGgcxwk/2trajCTjOM5/OR0A3Fgcx+l311x7xx8IBOTz+ZSdnR1emzNnjnw+n+rq6mJe09raqmAwqLy8vPCa1+tVbm5ur9dIkuM4SklJUVxcXMznS0pKwh83+Xw+paen/5dTAcDNz7XwB4NBjRkzJmp9zJgxCgaDvV4jSWlpaRHraWlpvV5z9uxZvfbaa3r66ad7PcvatWvlOE740dbW1t8xAGDYGXD4169fL4/H0+ejoaFBkuTxeKKuN8bEXP+hq5/v7ZpQKKSHHnpI06ZN07p163p9Pa/Xq5SUlIgHANgq9mcjfXj22We1dOnSPvdMmjRJn3zyib766quo577++uuod/Q9/H6/pO/f+Y8dOza8fubMmahrOjo6lJ+fr9tuu03V1dWKj48f6CgAYKUBhz81NVWpqanX3Dd37lw5jqODBw9q9uzZkqQDBw7IcRzNmzcv5jUZGRny+/2qqanRjBkzJEmXLl1SbW2tNm7cGN4XCoW0YMECeb1e7dy5U4mJiQMdAwCs5dpn/FOnTlV+fr5Wrlyp+vp61dfXa+XKlXr44Yc1ZcqU8L7MzExVV1dL+v4jnuLiYm3YsEHV1dX697//rV/96ldKSkrS8uXLJX3/Tj8vL0/ffvutKisrFQqFFAwGFQwGdeXKFbfGAYBhY8Dv+AfirbfeUlFRUfgunUcffVRlZWURe44dOxbxf7568cUX9d133+mZZ57RuXPnlJ2drd27dys5OVmSdOjQIR04cECS9KMf/SjitVpbWzVp0iQXJwKAm5/HGGOG+hD/a6FQSD6fL3wbKADc7AbSNf6uHgCwDOEHAMsQfgCwDOEHAMsQfgCwDOEHAMsQfgCwDOEHAMsQfgCwDOEHAMsQfgCwDOEHAMsQfgCwDOEHAMsQfgCwDOEHAMsQfgCwDOEHAMsQfgCwDOEHAMsQfgCwDOEHAMsQfgCwDOEHAMsQfgCwDOEHAMsQfgCwDOEHAMsQfgCwDOEHAMsQfgCwDOEHAMsQfgCwDOEHAMsQfgCwDOEHAMsQfgCwDOEHAMsQfgCwDOEHAMsQfgCwDOEHAMsQfgCwDOEHAMsQfgCwjKvhP3funAoLC+Xz+eTz+VRYWKjz58/3eY0xRuvXr9e4ceN066236v7779eRI0d63VtQUCCPx6P3339/8AcAgGHI1fAvX75cTU1N2rVrl3bt2qWmpiYVFhb2ec2mTZv0xhtvqKysTB9//LH8fr8eeOABdXR0RO1988035fF43Do+AAxPxiUtLS1Gkqmvrw+vBQIBI8l8+umnMa/p7u42fr/flJaWhtcuXrxofD6fKS8vj9jb1NRkxo8fb06fPm0kmerq6l7PcvHiReM4TvjR1tZmJBnHca5vSAC4QTiO0++uufaOPxAIyOfzKTs7O7w2Z84c+Xw+1dXVxbymtbVVwWBQeXl54TWv16vc3NyIay5cuKBly5aprKxMfr//mmcpKSkJf9zk8/mUnp5+HZMBwM3NtfAHg0GNGTMman3MmDEKBoO9XiNJaWlpEetpaWkR16xevVrz5s3TwoUL+3WWtWvXynGc8KOtra2/YwDAsDPg8K9fv14ej6fPR0NDgyTF/PzdGHPNz+Wvfv6H1+zcuVN79uzRm2++2e8ze71epaSkRDwAwFZxA73g2Wef1dKlS/vcM2nSJH3yySf66quvop77+uuvo97R9+j52CYYDGrs2LHh9TNnzoSv2bNnjz7//HPdfvvtEdcuXrxYOTk52rt37wCmAQD7DDj8qampSk1Nvea+uXPnynEcHTx4ULNnz5YkHThwQI7jaN68eTGvycjIkN/vV01NjWbMmCFJunTpkmpra7Vx40ZJ0po1a/TrX/864rp7771Xf/jDH/TII48MdBwAsM6Aw99fU6dOVX5+vlauXKk//elPkqTf/OY3evjhhzVlypTwvszMTJWUlOjnP/+5PB6PiouLtWHDBt1zzz265557tGHDBiUlJWn58uWSvv9fBbG+0J0wYYIyMjLcGgcAhg3Xwi9Jb731loqKisJ36Tz66KMqKyuL2HPs2DE5jhP++cUXX9R3332nZ555RufOnVN2drZ2796t5ORkN48KANbwGGPMUB/ify0UCsnn88lxHL7oBTAsDKRr/F09AGAZwg8AliH8AGAZwg8AliH8AGAZwg8AliH8AGAZwg8AliH8AGAZwg8AliH8AGAZwg8AliH8AGAZwg8AliH8AGAZwg8AliH8AGAZwg8AliH8AGAZwg8AliH8AGAZwg8AliH8AGAZwg8AliH8AGAZwg8AliH8AGAZwg8AliH8AGAZwg8AliH8AGAZwg8AliH8AGCZuKE+wFAwxkiSQqHQEJ8EAAZHT896+tYXK8Pf0dEhSUpPTx/ikwDA4Oro6JDP5+tzj8f0578ehpnu7m6dOnVKycnJ8ng8Q32cPoVCIaWnp6utrU0pKSlDfZxBx3w3v+E+480ynzFGHR0dGjdunG65pe9P8a18x3/LLbdo/PjxQ32MAUlJSbmh/013vZjv5jfcZ7wZ5rvWO/0efLkLAJYh/ABgGcJ/g/N6vVq3bp28Xu9QH8UVzHfzG+4zDsf5rPxyFwBsxjt+ALAM4QcAyxB+ALAM4QcAyxB+ALAM4R9i586dU2FhoXw+n3w+nwoLC3X+/Pk+rzHGaP369Ro3bpxuvfVW3X///Tpy5EivewsKCuTxePT+++8P/gDX4MZ833zzjZ577jlNmTJFSUlJmjBhgoqKiuQ4jsvTfG/Lli3KyMhQYmKisrKytG/fvj7319bWKisrS4mJiZo8ebLKy8uj9lRVVWnatGnyer2aNm2aqqur3Tr+NQ32fBUVFcrJydGoUaM0atQozZ8/XwcPHnRzhD658efXY/v27fJ4PFq0aNEgn3qQGQyp/Px8M336dFNXV2fq6urM9OnTzcMPP9znNaWlpSY5OdlUVVWZ5uZms2TJEjN27FgTCoWi9r7xxhumoKDASDLV1dUuTdE7N+Zrbm42v/jFL8zOnTvNZ599Zv71r3+Ze+65xyxevNj1ebZv327i4+NNRUWFaWlpMc8//7wZOXKk+eKLL2LuP378uElKSjLPP/+8aWlpMRUVFSY+Pt7s2LEjvKeurs6MGDHCbNiwwRw9etRs2LDBxMXFmfr6etfnuZob8y1fvtxs3rzZNDY2mqNHj5onn3zS+Hw+85///Od/NVaYG/P1OHHihLnrrrtMTk6OWbhwocuTXB/CP4RaWlqMpIj/gAcCASPJfPrppzGv6e7uNn6/35SWlobXLl68aHw+nykvL4/Y29TUZMaPH29Onz49JOF3e74feuedd0xCQoLp6uoavAFimD17tlm1alXEWmZmplmzZk3M/S+++KLJzMyMWHv66afNnDlzwj8/9thjJj8/P2LPggULzNKlSwfp1P3nxnxXu3z5sklOTjZ///vfr//AA+TWfJcvXzY//vGPzV/+8hezYsWKGz78fNQzhAKBgHw+n7Kzs8Nrc+bMkc/nU11dXcxrWltbFQwGlZeXF17zer3Kzc2NuObChQtatmyZysrK5Pf73RuiD27OdzXHcZSSkqK4OPf+3sFLly7p0KFDEWeTpLy8vF7PFggEovYvWLBADQ0N6urq6nNPX/O6wa35rnbhwgV1dXXpjjvuGJyD95Ob87366qu688479dRTTw3+wV1A+IdQMBjUmDFjotbHjBmjYDDY6zWSlJaWFrGelpYWcc3q1as1b948LVy4cBBPPDBuzvdDZ8+e1Wuvvaann376Ok/ct/b2dl25cmVAZwsGgzH3X758We3t7X3u6e013eLWfFdbs2aN7rrrLs2fP39wDt5Pbs23f/9+VVZWqqKiwp2Du4Dwu2D9+vXyeDx9PhoaGiQp5j8PwBhzzX9OwNXP//CanTt3as+ePXrzzTcHZ6CrDPV8PxQKhfTQQw9p2rRpWrdu3XVM1X/9PVtf+69eH+hrusmN+Xps2rRJ27Zt03vvvafExMRBOO3ADeZ8HR0deuKJJ1RRUaHU1NTBP6xLrPz7+N327LPPaunSpX3umTRpkj755BN99dVXUc99/fXXUe8yevR8bBMMBjV27Njw+pkzZ8LX7NmzR59//rluv/32iGsXL16snJwc7d27dwDTRBvq+Xp0dHQoPz9ft912m6qrqxUfHz/QUQYkNTVVI0aMiHp3GOtsPfx+f8z9cXFxGj16dJ97entNt7g1X4/XX39dGzZs0Icffqj77rtvcA/fD27Md+TIEZ04cUKPPPJI+Pnu7m5JUlxcnI4dO6a77757kCcZBEP03QLM///y88CBA+G1+vr6fn35uXHjxvBaZ2dnxJefp0+fNs3NzREPSeaPf/yjOX78uLtD/YBb8xljjOM4Zs6cOSY3N9d8++237g1xldmzZ5vf/va3EWtTp07t88vBqVOnRqytWrUq6svdgoKCiD35+flD9uXuYM9njDGbNm0yKSkpJhAIDO6BB2iw5/vuu++i/rO2cOFC87Of/cw0Nzebzs5Odwa5ToR/iOXn55v77rvPBAIBEwgEzL333ht1u+OUKVPMe++9F/65tLTU+Hw+895775nm5mazbNmyXm/n7KEhvJ1zsOcLhUImOzvb3Hvvveazzz4zp0+fDj8uX77s6jw9twNWVlaalpYWU1xcbEaOHGlOnDhhjDFmzZo1prCwMLy/53bA1atXm5aWFlNZWRl1O+D+/fvNiBEjTGlpqTl69KgpLS0d8ts5B3O+jRs3moSEBLNjx46IP6uOjo5hMd/Vboa7egj/EDt79qx5/PHHTXJysklOTjaPP/64OXfuXMQeSeavf/1r+Ofu7m6zbt064/f7jdfrNT/5yU9Mc3Nzn79nqMLvxnwfffSRkRTz0dra6vpMmzdvNhMnTjQJCQlm5syZpra2NvzcihUrTG5ubsT+vXv3mhkzZpiEhAQzadIks3Xr1qjXfPfdd82UKVNMfHy8yczMNFVVVW6P0avBnm/ixIkx/6zWrVv3P5gmmht/fj90M4Sfv48fACzDXT0AYBnCDwCWIfwAYBnCDwCWIfwAYBnCDwCWIfwAYBnCDwCWIfwAYBnCDwCWIfwAYJn/B2bb34nI6ptxAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 400x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_all_swarm(\n",
    "    neu_data : pd.DataFrame,\n",
    "    metric : str,\n",
    "    data,\n",
    "    null_dist\n",
    "):\n",
    "    data = F.average_sample_data(data)\n",
    "    null_dist = F.average_sample_data(null_dist)\n",
    "    y_min = min([min(np.array(area_data).flatten()) for area_data in data])\n",
    "    y_max =  max([max(np.array(area_data).flatten()) for area_data in data])\n",
    "    cell_area_groups = F.define_cell_area_groups(neu_data)\n",
    "    for i, area_name in enumerate(cell_area_groups.keys()):\n",
    "        construct_swarm_for_area(\n",
    "            title=f\"{area_name}\",\n",
    "            metric=metric,\n",
    "            data=[data[0][i], data[1][i]],\n",
    "            null_dist=[null_dist[0][i], null_dist[1][i]],\n",
    "            y_min=y_min-0.02,\n",
    "            y_max=y_max+0.02\n",
    "        )\n",
    "\n",
    "plot_all_swarm(neu_data, metric=\"ps\", data=ps_, null_dist=ps_boot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[[], [], [], [], [], []], [[], [], [], [], [], []]]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ps_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neural-code",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
